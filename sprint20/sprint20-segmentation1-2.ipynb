{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/unet/model.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input = inputs, output = conv10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Found 4000 images belonging to 1 classes.\n",
      "Found 4000 images belonging to 1 classes.\n",
      "300/300 [==============================] - 148s 495ms/step - loss: 0.4994 - acc: 0.7714\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.49939, saving model to unet_membrane.hdf5\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.4240 - acc: 0.8216\n",
      "\n",
      "Epoch 00002: loss improved from 0.49939 to 0.42400, saving model to unet_membrane.hdf5\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.3818 - acc: 0.8445\n",
      "\n",
      "Epoch 00003: loss improved from 0.42400 to 0.38176, saving model to unet_membrane.hdf5\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.3418 - acc: 0.8656\n",
      "\n",
      "Epoch 00004: loss improved from 0.38176 to 0.34181, saving model to unet_membrane.hdf5\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 113s 375ms/step - loss: 0.3404 - acc: 0.8691\n",
      "\n",
      "Epoch 00005: loss improved from 0.34181 to 0.34045, saving model to unet_membrane.hdf5\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.3328 - acc: 0.8703\n",
      "\n",
      "Epoch 00006: loss improved from 0.34045 to 0.33282, saving model to unet_membrane.hdf5\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.3195 - acc: 0.8753\n",
      "\n",
      "Epoch 00007: loss improved from 0.33282 to 0.31953, saving model to unet_membrane.hdf5\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.3143 - acc: 0.8785\n",
      "\n",
      "Epoch 00008: loss improved from 0.31953 to 0.31435, saving model to unet_membrane.hdf5\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2947 - acc: 0.8871\n",
      "\n",
      "Epoch 00009: loss improved from 0.31435 to 0.29473, saving model to unet_membrane.hdf5\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.3305 - acc: 0.8718\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.29473\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2910 - acc: 0.8882\n",
      "\n",
      "Epoch 00011: loss improved from 0.29473 to 0.29097, saving model to unet_membrane.hdf5\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2887 - acc: 0.8918\n",
      "\n",
      "Epoch 00012: loss improved from 0.29097 to 0.28868, saving model to unet_membrane.hdf5\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2961 - acc: 0.8898\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.28868\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2751 - acc: 0.8962\n",
      "\n",
      "Epoch 00014: loss improved from 0.28868 to 0.27506, saving model to unet_membrane.hdf5\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2760 - acc: 0.8958\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.27506\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2706 - acc: 0.8972\n",
      "\n",
      "Epoch 00016: loss improved from 0.27506 to 0.27064, saving model to unet_membrane.hdf5\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2482 - acc: 0.9064\n",
      "\n",
      "Epoch 00017: loss improved from 0.27064 to 0.24824, saving model to unet_membrane.hdf5\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 113s 375ms/step - loss: 0.2915 - acc: 0.8913\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.24824\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2371 - acc: 0.9128\n",
      "\n",
      "Epoch 00019: loss improved from 0.24824 to 0.23707, saving model to unet_membrane.hdf5\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2506 - acc: 0.9052\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.23707\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 113s 375ms/step - loss: 0.2421 - acc: 0.9118\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.23707\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2350 - acc: 0.9129\n",
      "\n",
      "Epoch 00022: loss improved from 0.23707 to 0.23500, saving model to unet_membrane.hdf5\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2604 - acc: 0.9053\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.23500\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2579 - acc: 0.9027\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.23500\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2607 - acc: 0.9020\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.23500\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2494 - acc: 0.9029\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.23500\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2349 - acc: 0.9106\n",
      "\n",
      "Epoch 00027: loss improved from 0.23500 to 0.23494, saving model to unet_membrane.hdf5\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2472 - acc: 0.9025\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.23494\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2271 - acc: 0.9184\n",
      "\n",
      "Epoch 00029: loss improved from 0.23494 to 0.22710, saving model to unet_membrane.hdf5\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2440 - acc: 0.9097\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.22710\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2308 - acc: 0.9134\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.22710\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2271 - acc: 0.9171\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.22710\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2118 - acc: 0.9214\n",
      "\n",
      "Epoch 00033: loss improved from 0.22710 to 0.21180, saving model to unet_membrane.hdf5\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2211 - acc: 0.9200\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.21180\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2187 - acc: 0.9197\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.21180\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2370 - acc: 0.9130\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.21180\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2453 - acc: 0.9090\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.21180\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2476 - acc: 0.9028\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.21180\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1919 - acc: 0.9312\n",
      "\n",
      "Epoch 00039: loss improved from 0.21180 to 0.19186, saving model to unet_membrane.hdf5\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2284 - acc: 0.9143\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.19186\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2278 - acc: 0.9182\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.19186\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1898 - acc: 0.9303\n",
      "\n",
      "Epoch 00042: loss improved from 0.19186 to 0.18977, saving model to unet_membrane.hdf5\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2093 - acc: 0.9190\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.18977\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2412 - acc: 0.9056\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.18977\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1989 - acc: 0.9286\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.18977\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2168 - acc: 0.9194\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.18977\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2292 - acc: 0.9152\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.18977\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.1860 - acc: 0.9323\n",
      "\n",
      "Epoch 00048: loss improved from 0.18977 to 0.18599, saving model to unet_membrane.hdf5\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.1997 - acc: 0.9303\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.18599\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 113s 375ms/step - loss: 0.2622 - acc: 0.8986\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.18599\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2263 - acc: 0.9185\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.18599\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1921 - acc: 0.9296\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.18599\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 113s 375ms/step - loss: 0.2037 - acc: 0.9211\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.18599\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1777 - acc: 0.9361\n",
      "\n",
      "Epoch 00054: loss improved from 0.18599 to 0.17769, saving model to unet_membrane.hdf5\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1912 - acc: 0.9278\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.17769\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1793 - acc: 0.9319\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.17769\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2438 - acc: 0.9092\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.17769\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.1931 - acc: 0.9284\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.17769\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2413 - acc: 0.9064\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.17769\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.1965 - acc: 0.9319\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.17769\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.1820 - acc: 0.9337\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.17769\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.2266 - acc: 0.9136\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.17769\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1695 - acc: 0.9380\n",
      "\n",
      "Epoch 00063: loss improved from 0.17769 to 0.16947, saving model to unet_membrane.hdf5\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 113s 375ms/step - loss: 0.2313 - acc: 0.9111\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.16947\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.1837 - acc: 0.9327\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.16947\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 113s 375ms/step - loss: 0.1770 - acc: 0.9323\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.16947\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1932 - acc: 0.9246\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.16947\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1889 - acc: 0.9284\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.16947\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1862 - acc: 0.9350\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.16947\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1792 - acc: 0.9342\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.16947\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1895 - acc: 0.9305\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.16947\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.2028 - acc: 0.9237\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.16947\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2133 - acc: 0.9212\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.16947\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1892 - acc: 0.9302\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.16947\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2050 - acc: 0.9187\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.16947\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1912 - acc: 0.9295\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.16947\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1780 - acc: 0.9362\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.16947\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2021 - acc: 0.9254\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.16947\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1956 - acc: 0.9289\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.16947\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1756 - acc: 0.9401\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.16947\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1763 - acc: 0.9355\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.16947\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1781 - acc: 0.9317\n",
      "\n",
      "Epoch 00082: loss did not improve from 0.16947\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2004 - acc: 0.9267\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.16947\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1754 - acc: 0.9341\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.16947\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1445 - acc: 0.9483\n",
      "\n",
      "Epoch 00085: loss improved from 0.16947 to 0.14448, saving model to unet_membrane.hdf5\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 113s 375ms/step - loss: 0.2204 - acc: 0.9119\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.14448\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1786 - acc: 0.9326\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.14448\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.2083 - acc: 0.9168\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.14448\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1857 - acc: 0.9278\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.14448\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1836 - acc: 0.9323\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.14448\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1530 - acc: 0.9423\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.14448\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1798 - acc: 0.9354\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.14448\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1736 - acc: 0.9383\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.14448\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 112s 374ms/step - loss: 0.1952 - acc: 0.9244\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.14448\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 112s 375ms/step - loss: 0.1872 - acc: 0.9300\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.14448\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 113s 377ms/step - loss: 0.1718 - acc: 0.9406\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.14448\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.1525 - acc: 0.9429\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.14448\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 113s 378ms/step - loss: 0.1771 - acc: 0.9348\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.14448\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.1806 - acc: 0.9321\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.14448\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 113s 376ms/step - loss: 0.1797 - acc: 0.9285\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.14448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8421be5c88>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import *\n",
    "from data import *\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(2,'../input/train/','images','masks',data_gen_args,save_to_dir = None)\n",
    "\n",
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(myGene,steps_per_epoch=300,epochs=100,callbacks=[model_checkpoint])\n",
    "\n",
    "#testGene = testGenerator(\"data/membrane/test\")\n",
    "#results = model.predict_generator(testGene,30,verbose=1)\n",
    "#saveResult(\"data/membrane/test\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 256, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 128, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 147584      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 512)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 1024) 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 1024) 9438208     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 1024) 4096        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 1024) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 1024) 0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 512)  2097664     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 1024) 4096        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 1024) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 256)  524544      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           activation_6[0][0]               \n",
      "                                                                 conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 512)  2048        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 128 262272      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 256 0           activation_4[0][0]               \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 256 1024        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 256 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 128 295040      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 128 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 128 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 64) 32832       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           activation_2[0][0]               \n",
      "                                                                 conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 128 512         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 256, 256, 128 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 64) 73792       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256, 256, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 64) 36928       batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 64) 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 1)  65          activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 29,418,049\n",
      "Trainable params: 29,404,865\n",
      "Non-trainable params: 13,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir weight_and_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/unet\n"
     ]
    }
   ],
   "source": [
    "cd unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saving... at ./drive/My Drive/model.json\n",
      "Weight saving... at ./drive/My Drive/weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# モデルを保存\n",
    "print(\"Model saving... at ./drive/My Drive/model.json\")\n",
    "from keras.utils import plot_model\n",
    "model_json = model.to_json()\n",
    "with open(\"../weight_and_model/model\", mode='w') as f:\n",
    "    f.write(model_json)\n",
    "\n",
    "# 学習済みの重みを保存\n",
    "print(\"Weight saving... at ./drive/My Drive/weights.hdf5\")\n",
    "model.save_weights(\"../weight_and_model/weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = Image.open('../input/train/images/01b5362cce.png')\n",
    "img = img.convert('L')\n",
    "img = img.resize((256,256))\n",
    "img = np.array(img)\n",
    "img = img /255\n",
    "img = img.reshape(1,256,256,1)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_img = preprocessing.image.array_to_img(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7F8422FB6FD0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('../input/train/masks/01b5362cce.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGUAAABlEAAAAAAhh65QAAABBElEQVR4nO2WMQ7DMBDD7P7/z+ngpWndNN1ESQQyBM5C8M7IHFuOY8717M8VeVwdkkQuVFgaY/yowmKjwuux8K5C7eJehUlVFJnnV+bCL4yqVEWRqijiqkK+in2rsPFUYW+KaxU6Lypzfv+MgGcVOicV9oi5VmHzpkIeMd8qZKqiyIcKd/Gdq3CpiiIbFerie1ehUhVFqqLIVoV5HbtXYVIVRfxViHeYfxUiVVGkKopURZGqKJKgwvsLS6jCoyqKZKjQ7rCMKjRSVFjbklKFRY4KaVtyqpBIUuFsS1IVDjdUKCN2qwpDJmvAKNxUIYxYXhVCl8Qq+mSqqG9LZhV1/lLRHrEny5cU3fFdhHkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=I size=101x101 at 0x7F842293D8D0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、main.pyではBatchNormalizationを行っていないので追加し、upsamplingもtransposed_convlutionに変更して同様に学習させてみた\n",
    "BatchNormalizationを行うときは活性化関数を適用する前にBatchNormalizationを入れたいので、2DConvのときにactivationを指定しない\n",
    "精度はほとんど変わらなかった.若干見た目でカスタムしない方がいいように思えるのでよりよい方法を見つけたい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題2】コードリーディング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unetは収縮パスと拡張パスが重要である\n",
    "実現しているのはmodel.pyである\n",
    "kerasを使っていて\n",
    "\n",
    "\n",
    "収縮パスは\n",
    "\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "\n",
    "で二回の畳み込みを行い、\n",
    "\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "でpoolingを行うまでが1ブロックの流れ。\n",
    "\n",
    "拡張パスは\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "\n",
    "でupconvして\n",
    "\n",
    "merge6 = concatenate([drop4,up6], axis = 3)\n",
    "\n",
    "でスキップ接続とチャンネル方向に結合し、\n",
    "\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "の二回の畳み込みを行いblockが終了する.最後の層で\n",
    "\n",
    "conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "のようにsoftmaxした後出力する\n",
    "\n",
    "lossは'binary_crossentropy'でOptimizerはAdam, metricsはacccuracy\n",
    "\n",
    "原著論文では境界付近のlossが大きくなるように重みづけされているが今回は普通のbinary_crossentropyを使用している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
