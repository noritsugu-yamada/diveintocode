{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題1】公式Exampleを分担して実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Segmentation with tf.keras\n",
    "\n",
    "使用データはkaggleの中古車のセグメンテーション\n",
    "中古車の画像は撮影された背景によって見にくくなってしまう\n",
    "背景を別の色に塗りつぶして中古車を綺麗に見えるように自動化するのが目的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-netを使うので最初にpaperを見る\n",
    "\n",
    "ISBIセルトラッキングチャレンジ2015で勝利\n",
    "このアーキテクチャーは、特徴を抽出する縮小パスと、\n",
    "正確なローカライズを可能にする対称的な拡張パスから構成される\n",
    "非常に少数の画像からend-to-endで訓練\n",
    "高速であり、GPU環境では、512 x 512の画像のセグメンテーションに1秒かからない\n",
    "IOUは93%を達成\n",
    "\n",
    "収縮パスは畳み込みネットワークの典型的なアーキテクチャに従い２つの３×３畳み込みの繰り返し適用し、\n",
    "ダウンサンプリングのための（ＲｅＬＵ）ストライド２および２×２マックスプーリングが続き\n",
    "特徴チャンネルの数を２倍にする\n",
    "\n",
    "拡張パスの各ステップはフィーチャマップのアップサンプリングとそれに続くフィーチャチャネル数を半分にする2×2の畳み込み縮小パスからの対応する切り取り済みフィーチャマップとの連結、および2つの3×3で構成される\n",
    "\n",
    "クロッピングは、すべての畳み込みで境界ピクセルが失われるために必要\n",
    "クラスにマッピングするために１×１畳み込みが使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig1.png\" width=\"500\" height=\"300\">\n",
    "<img src=\"fig2.png\" width=\"300\" height=\"300\">\n",
    "<img src=\"fig3.png\" width=\"300\" height=\"300\">\n",
    "<img src=\"fig4.png\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題2】Iris（2値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "# データセットの読み込み\n",
    "dataset_path =\"df_vergicolor_and_virginica.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"target\"] == \"versicolor\")|(df[\"target\"] == \"virginica\")]\n",
    "y = df[\"target\"]\n",
    "X = df.loc[:, [\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='versicolor'] = 0\n",
    "y[y=='virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model生成\n",
    "input_data = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/200\n",
      "64/64 [==============================] - 2s 25ms/step - loss: 1.0392 - acc: 0.4375 - val_loss: 0.7082 - val_acc: 0.3750\n",
      "Epoch 2/200\n",
      "64/64 [==============================] - 0s 244us/step - loss: 0.5957 - acc: 0.6719 - val_loss: 0.5608 - val_acc: 0.7500\n",
      "Epoch 3/200\n",
      "64/64 [==============================] - 0s 488us/step - loss: 0.5288 - acc: 0.8281 - val_loss: 0.6581 - val_acc: 0.3750\n",
      "Epoch 4/200\n",
      "64/64 [==============================] - 0s 244us/step - loss: 0.5415 - acc: 0.6406 - val_loss: 0.4354 - val_acc: 0.8125\n",
      "Epoch 5/200\n",
      "64/64 [==============================] - 0s 244us/step - loss: 0.4042 - acc: 0.8594 - val_loss: 0.4280 - val_acc: 0.8125\n",
      "Epoch 6/200\n",
      "64/64 [==============================] - 0s 488us/step - loss: 0.3032 - acc: 0.9531 - val_loss: 0.3111 - val_acc: 0.8750\n",
      "Epoch 7/200\n",
      "64/64 [==============================] - 0s 423us/step - loss: 0.2443 - acc: 0.9531 - val_loss: 0.3744 - val_acc: 0.8125\n",
      "Epoch 8/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.2515 - acc: 0.8906 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 9/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.2082 - acc: 0.9531 - val_loss: 0.3305 - val_acc: 0.8125\n",
      "Epoch 10/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.2263 - acc: 0.9062 - val_loss: 0.3560 - val_acc: 0.8125\n",
      "Epoch 11/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.2679 - acc: 0.8906 - val_loss: 0.1048 - val_acc: 1.0000\n",
      "Epoch 12/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1427 - acc: 0.9375 - val_loss: 0.1245 - val_acc: 0.8750\n",
      "Epoch 13/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.1443 - acc: 0.9375 - val_loss: 0.0757 - val_acc: 1.0000\n",
      "Epoch 14/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1021 - acc: 0.9687 - val_loss: 0.1034 - val_acc: 0.9375\n",
      "Epoch 15/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1579 - acc: 0.9531 - val_loss: 0.1697 - val_acc: 0.9375\n",
      "Epoch 16/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.2106 - acc: 0.8750 - val_loss: 0.0694 - val_acc: 1.0000\n",
      "Epoch 17/200\n",
      "64/64 [==============================] - 0s 390us/step - loss: 0.1894 - acc: 0.9062 - val_loss: 0.0965 - val_acc: 0.9375\n",
      "Epoch 18/200\n",
      "64/64 [==============================] - 0s 390us/step - loss: 0.1267 - acc: 0.9688 - val_loss: 0.0591 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0870 - acc: 0.9844 - val_loss: 0.0702 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.1149 - acc: 0.9219 - val_loss: 0.1824 - val_acc: 0.8750\n",
      "Epoch 21/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.1310 - acc: 0.9375 - val_loss: 0.2215 - val_acc: 0.8750\n",
      "Epoch 22/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.2447 - acc: 0.9219 - val_loss: 0.1008 - val_acc: 0.9375\n",
      "Epoch 23/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1157 - acc: 0.9375 - val_loss: 0.1174 - val_acc: 0.9375\n",
      "Epoch 24/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.2438 - acc: 0.8906 - val_loss: 0.0548 - val_acc: 1.0000\n",
      "Epoch 25/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1689 - acc: 0.9219 - val_loss: 0.0693 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0926 - acc: 0.9687 - val_loss: 0.0668 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0966 - acc: 0.9687 - val_loss: 0.0612 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0920 - acc: 0.9531 - val_loss: 0.0729 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0896 - acc: 0.9375 - val_loss: 0.0571 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0951 - acc: 0.9687 - val_loss: 0.1299 - val_acc: 0.8750\n",
      "Epoch 31/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1501 - acc: 0.9062 - val_loss: 0.0883 - val_acc: 0.9375\n",
      "Epoch 32/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1235 - acc: 0.9375 - val_loss: 0.0874 - val_acc: 0.9375\n",
      "Epoch 33/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0475 - acc: 0.9687 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1116 - acc: 0.9375 - val_loss: 0.0304 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1969 - acc: 0.9219 - val_loss: 0.0522 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1770 - acc: 0.8906 - val_loss: 0.0981 - val_acc: 0.9375\n",
      "Epoch 37/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1399 - acc: 0.9531 - val_loss: 0.1594 - val_acc: 0.8750\n",
      "Epoch 38/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1583 - acc: 0.9219 - val_loss: 0.0406 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.1758 - acc: 0.9063 - val_loss: 0.0604 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0734 - acc: 0.9844 - val_loss: 0.0508 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0714 - acc: 0.9687 - val_loss: 0.0697 - val_acc: 0.9375\n",
      "Epoch 42/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0610 - acc: 0.9844 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0637 - acc: 0.9687 - val_loss: 0.0687 - val_acc: 0.9375\n",
      "Epoch 44/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0570 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0805 - acc: 0.9687 - val_loss: 0.1023 - val_acc: 0.9375\n",
      "Epoch 46/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0978 - acc: 0.9531 - val_loss: 0.0284 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0693 - acc: 0.9844 - val_loss: 0.1391 - val_acc: 0.9375\n",
      "Epoch 48/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1006 - acc: 0.9375 - val_loss: 0.0389 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0902 - acc: 0.9687 - val_loss: 0.0409 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0512 - acc: 0.9844 - val_loss: 0.0367 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0563 - acc: 0.9844 - val_loss: 0.0254 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0950 - acc: 0.9688 - val_loss: 0.1204 - val_acc: 0.9375\n",
      "Epoch 53/200\n",
      "64/64 [==============================] - 0s 405us/step - loss: 0.0870 - acc: 0.9375 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0867 - acc: 0.9531 - val_loss: 0.0328 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0551 - acc: 0.9844 - val_loss: 0.0521 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0458 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1524 - acc: 0.9375 - val_loss: 0.1202 - val_acc: 0.9375\n",
      "Epoch 58/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.2947 - acc: 0.8906 - val_loss: 0.2914 - val_acc: 0.8125\n",
      "Epoch 59/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.2023 - acc: 0.9219 - val_loss: 0.1137 - val_acc: 0.9375\n",
      "Epoch 60/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1457 - acc: 0.9219 - val_loss: 0.0693 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1992 - acc: 0.9375 - val_loss: 0.0824 - val_acc: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1682 - acc: 0.9375 - val_loss: 0.0749 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1492 - acc: 0.9375 - val_loss: 0.0550 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1129 - acc: 0.9375 - val_loss: 0.0457 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "64/64 [==============================] - 0s 359us/step - loss: 0.1210 - acc: 0.9531 - val_loss: 0.0426 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0716 - acc: 0.9687 - val_loss: 0.0865 - val_acc: 0.9375\n",
      "Epoch 67/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0542 - acc: 0.9844 - val_loss: 0.0468 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0669 - acc: 0.9531 - val_loss: 0.0941 - val_acc: 0.9375\n",
      "Epoch 69/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0766 - acc: 0.9531 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0654 - acc: 0.9687 - val_loss: 0.0702 - val_acc: 0.9375\n",
      "Epoch 71/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0564 - acc: 0.9844 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0492 - acc: 0.9844 - val_loss: 0.0381 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0453 - acc: 0.9844 - val_loss: 0.0397 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0512 - acc: 0.9687 - val_loss: 0.0310 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0773 - acc: 0.9531 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0490 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.1120 - acc: 0.9531 - val_loss: 0.1072 - val_acc: 0.9375\n",
      "Epoch 78/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0687 - acc: 0.9687 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0968 - acc: 0.9531 - val_loss: 0.0716 - val_acc: 0.9375\n",
      "Epoch 80/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0643 - acc: 0.9844 - val_loss: 0.0269 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0505 - acc: 0.9844 - val_loss: 0.0618 - val_acc: 0.9375\n",
      "Epoch 82/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0785 - acc: 0.9687 - val_loss: 0.0134 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1006 - acc: 0.9531 - val_loss: 0.0628 - val_acc: 0.9375\n",
      "Epoch 84/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0610 - acc: 0.9844 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0858 - acc: 0.9531 - val_loss: 0.0422 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0625 - acc: 0.9687 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0602 - acc: 0.9531 - val_loss: 0.0501 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0702 - acc: 0.9531 - val_loss: 0.0468 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0407 - acc: 0.9844 - val_loss: 0.0302 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0392 - acc: 0.9844 - val_loss: 0.0461 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0403 - acc: 0.9844 - val_loss: 0.0297 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0300 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0766 - acc: 0.9688 - val_loss: 0.1923 - val_acc: 0.9375\n",
      "Epoch 96/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1483 - acc: 0.9375 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0851 - acc: 0.9531 - val_loss: 0.0440 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1142 - acc: 0.9531 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0835 - acc: 0.9687 - val_loss: 0.0336 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1155 - acc: 0.9375 - val_loss: 0.0533 - val_acc: 0.9375\n",
      "Epoch 101/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1542 - acc: 0.9375 - val_loss: 0.0231 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1698 - acc: 0.9375 - val_loss: 0.0274 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.3287 - acc: 0.8750 - val_loss: 0.0677 - val_acc: 0.9375\n",
      "Epoch 104/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0564 - acc: 0.9844 - val_loss: 0.1116 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1128 - acc: 0.9531 - val_loss: 0.1174 - val_acc: 0.9375\n",
      "Epoch 106/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0988 - acc: 0.9531 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0700 - acc: 0.9687 - val_loss: 0.0264 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0402 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9375\n",
      "Epoch 109/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0548 - acc: 0.9844 - val_loss: 0.0168 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0683 - acc: 0.9687 - val_loss: 0.0316 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0450 - acc: 0.9844 - val_loss: 0.0284 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0376 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0379 - acc: 0.9844 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0357 - acc: 0.9687 - val_loss: 0.0405 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0554 - acc: 0.9687 - val_loss: 0.0146 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0384 - acc: 0.9844 - val_loss: 0.0448 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0423 - acc: 0.9688 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.1398 - acc: 0.9531 - val_loss: 0.2510 - val_acc: 0.8750\n",
      "Epoch 119/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.2594 - acc: 0.8906 - val_loss: 0.0102 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0770 - acc: 0.9531 - val_loss: 0.0661 - val_acc: 0.9375\n",
      "Epoch 121/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0504 - acc: 0.9687 - val_loss: 0.0172 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0404 - acc: 0.9844 - val_loss: 0.0425 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0449 - acc: 0.9844 - val_loss: 0.0160 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0589 - acc: 0.9687 - val_loss: 0.0628 - val_acc: 0.9375\n",
      "Epoch 125/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0670 - acc: 0.9375 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0454 - acc: 0.9844 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "64/64 [==============================] - 0s 389us/step - loss: 0.0451 - acc: 0.9844 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0778 - acc: 0.9688 - val_loss: 0.0371 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "64/64 [==============================] - 0s 421us/step - loss: 0.0665 - acc: 0.9687 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "64/64 [==============================] - 0s 390us/step - loss: 0.0635 - acc: 0.9844 - val_loss: 0.0092 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0497 - acc: 0.9687 - val_loss: 0.0456 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "64/64 [==============================] - 0s 514us/step - loss: 0.0812 - acc: 0.9531 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0888 - acc: 0.9687 - val_loss: 0.0497 - val_acc: 0.9375\n",
      "Epoch 134/200\n",
      "64/64 [==============================] - 0s 545us/step - loss: 0.0578 - acc: 0.9688 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1195 - acc: 0.9375 - val_loss: 0.0279 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.3590 - acc: 0.9062 - val_loss: 0.0493 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.2595 - acc: 0.8906 - val_loss: 0.0293 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.2507 - acc: 0.8906 - val_loss: 0.0787 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.2392 - acc: 0.8594 - val_loss: 0.1287 - val_acc: 0.9375\n",
      "Epoch 140/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1507 - acc: 0.9375 - val_loss: 0.0502 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "64/64 [==============================] - 0s 389us/step - loss: 0.0902 - acc: 0.9687 - val_loss: 0.0698 - val_acc: 0.9375\n",
      "Epoch 142/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0952 - acc: 0.9687 - val_loss: 0.0319 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0664 - acc: 0.9844 - val_loss: 0.0975 - val_acc: 0.9375\n",
      "Epoch 144/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0686 - acc: 0.9844 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0615 - acc: 0.9687 - val_loss: 0.0652 - val_acc: 0.9375\n",
      "Epoch 146/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0655 - acc: 0.9687 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0662 - acc: 0.9687 - val_loss: 0.0594 - val_acc: 0.9375\n",
      "Epoch 148/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.1100 - acc: 0.9219 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0344 - acc: 0.9844 - val_loss: 0.0479 - val_acc: 0.9375\n",
      "Epoch 150/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0374 - acc: 0.9844 - val_loss: 0.0589 - val_acc: 0.9375\n",
      "Epoch 152/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.0760 - acc: 0.9688 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0444 - acc: 0.9844 - val_loss: 0.0444 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0354 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.1009 - acc: 0.9531 - val_loss: 0.0691 - val_acc: 0.9375\n",
      "Epoch 156/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.1579 - acc: 0.9219 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.4711 - acc: 0.8906 - val_loss: 0.0388 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.2063 - acc: 0.9219 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1974 - acc: 0.9375 - val_loss: 0.0416 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.0703 - acc: 0.9844 - val_loss: 0.1261 - val_acc: 0.9375\n",
      "Epoch 161/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.0980 - acc: 0.9531 - val_loss: 0.0480 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.1563 - acc: 0.9375 - val_loss: 0.0352 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.1533 - acc: 0.9062 - val_loss: 0.0502 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.1371 - acc: 0.9375 - val_loss: 0.0655 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0960 - acc: 0.9531 - val_loss: 0.0921 - val_acc: 0.9375\n",
      "Epoch 166/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0902 - acc: 0.9687 - val_loss: 0.0422 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0595 - acc: 0.9687 - val_loss: 0.0440 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.0611 - acc: 0.9844 - val_loss: 0.0326 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.1092 - acc: 0.9531 - val_loss: 0.0130 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.1478 - acc: 0.9531 - val_loss: 0.0150 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.0662 - acc: 0.9687 - val_loss: 0.3324 - val_acc: 0.8750\n",
      "Epoch 172/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.1316 - acc: 0.9531 - val_loss: 0.0276 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.1496 - acc: 0.9375 - val_loss: 0.0309 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0975 - acc: 0.9531 - val_loss: 0.0986 - val_acc: 0.9375\n",
      "Epoch 175/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0757 - acc: 0.9687 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.0863 - acc: 0.9531 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0802 - acc: 0.9687 - val_loss: 0.0612 - val_acc: 0.9375\n",
      "Epoch 178/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0701 - acc: 0.9687 - val_loss: 0.0157 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.0529 - acc: 0.9844 - val_loss: 0.1180 - val_acc: 0.9375\n",
      "Epoch 180/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0818 - acc: 0.9375 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0453 - acc: 0.9844 - val_loss: 0.0652 - val_acc: 0.9375\n",
      "Epoch 182/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0572 - acc: 0.9687 - val_loss: 0.0295 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0398 - acc: 1.0000 - val_loss: 0.0323 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0384 - acc: 0.9844 - val_loss: 0.0190 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0366 - acc: 0.9844 - val_loss: 0.0845 - val_acc: 0.9375\n",
      "Epoch 188/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0389 - acc: 0.9844 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0496 - acc: 0.9844 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "64/64 [==============================] - 0s 359us/step - loss: 0.0888 - acc: 0.9687 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.1363 - acc: 0.9531 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0550 - acc: 0.9687 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0360 - acc: 0.9844 - val_loss: 0.0306 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0303 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0393 - acc: 0.9844 - val_loss: 0.0292 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0575 - acc: 0.9687 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0716 - acc: 0.9531 - val_loss: 0.0122 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.0389 - acc: 0.9844 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.0659 - acc: 0.9688 - val_loss: 0.0660 - val_acc: 0.9375\n",
      "Epoch 200/200\n",
      "64/64 [==============================] - 0s 312us/step - loss: 0.0851 - acc: 0.9688 - val_loss: 0.0069 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=200,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_proba [5.2465210e-03 9.9998271e-01 2.9633627e-03 9.9999928e-01 9.9982506e-01\n",
      " 9.9999321e-01 1.1255484e-01 9.9512744e-01 9.9999547e-01 9.9972719e-01\n",
      " 9.9994397e-01 9.9988592e-01 9.9998987e-01 5.1823951e-02 6.4446082e-05\n",
      " 3.2522026e-04 9.8249304e-01 1.5300071e-04 9.9887007e-01 5.6583958e-04]\n",
      "y_pred [0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 確率の出力\n",
    "y_pred_proba = model.predict(X_test)[:,0]\n",
    "\n",
    "# predictの出力\n",
    "y_pred = np.where(y_pred_proba>0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題3】Iris（多値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "X = df.iloc[:, 1:-1]\n",
    "y = df.iloc[:, -1]\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y[y==\"Iris-setosa\"] = 0\n",
    "y[y==\"Iris-versicolor\"] = 1\n",
    "y[y==\"Iris-virginica\"] = 2\n",
    "y = y.astype(np.int)# ndarray(n_samples, n_features)\n",
    "# onehotencoder\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "y_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size = 0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(4,))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/200\n",
      "96/96 [==============================] - 0s 3ms/step - loss: 1.0631 - acc: 0.5521 - val_loss: 0.5558 - val_acc: 0.9167\n",
      "Epoch 2/200\n",
      "96/96 [==============================] - 0s 520us/step - loss: 0.5128 - acc: 0.8021 - val_loss: 0.6173 - val_acc: 0.6250\n",
      "Epoch 3/200\n",
      "96/96 [==============================] - 0s 416us/step - loss: 0.3935 - acc: 0.7708 - val_loss: 0.3126 - val_acc: 0.9167\n",
      "Epoch 4/200\n",
      "96/96 [==============================] - 0s 415us/step - loss: 0.2542 - acc: 0.9271 - val_loss: 0.2553 - val_acc: 0.9583\n",
      "Epoch 5/200\n",
      "96/96 [==============================] - 0s 384us/step - loss: 0.1564 - acc: 0.9583 - val_loss: 0.2341 - val_acc: 0.8750\n",
      "Epoch 6/200\n",
      "96/96 [==============================] - 0s 395us/step - loss: 0.1413 - acc: 0.9583 - val_loss: 0.3756 - val_acc: 0.8333\n",
      "Epoch 7/200\n",
      "96/96 [==============================] - 0s 405us/step - loss: 0.1831 - acc: 0.9062 - val_loss: 0.3483 - val_acc: 0.8333\n",
      "Epoch 8/200\n",
      "96/96 [==============================] - 0s 364us/step - loss: 0.0970 - acc: 0.9687 - val_loss: 0.1789 - val_acc: 0.9167\n",
      "Epoch 9/200\n",
      "96/96 [==============================] - 0s 395us/step - loss: 0.1299 - acc: 0.9375 - val_loss: 0.3085 - val_acc: 0.9167\n",
      "Epoch 10/200\n",
      "96/96 [==============================] - 0s 364us/step - loss: 0.1360 - acc: 0.9479 - val_loss: 0.5085 - val_acc: 0.8333\n",
      "Epoch 11/200\n",
      "96/96 [==============================] - 0s 384us/step - loss: 0.0868 - acc: 0.9687 - val_loss: 0.3198 - val_acc: 0.9167\n",
      "Epoch 12/200\n",
      "96/96 [==============================] - 0s 405us/step - loss: 0.1211 - acc: 0.9687 - val_loss: 0.1922 - val_acc: 0.8750\n",
      "Epoch 13/200\n",
      "96/96 [==============================] - 0s 395us/step - loss: 0.0840 - acc: 0.9687 - val_loss: 0.2296 - val_acc: 0.9167\n",
      "Epoch 14/200\n",
      "96/96 [==============================] - 0s 384us/step - loss: 0.0767 - acc: 0.9687 - val_loss: 0.2554 - val_acc: 0.8333\n",
      "Epoch 15/200\n",
      "96/96 [==============================] - 0s 447us/step - loss: 0.1087 - acc: 0.9479 - val_loss: 0.3125 - val_acc: 0.8750\n",
      "Epoch 16/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0854 - acc: 0.9583 - val_loss: 0.2670 - val_acc: 0.9167\n",
      "Epoch 17/200\n",
      "96/96 [==============================] - 0s 405us/step - loss: 0.0497 - acc: 0.9792 - val_loss: 0.1784 - val_acc: 0.9167\n",
      "Epoch 18/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0654 - acc: 0.9687 - val_loss: 0.1764 - val_acc: 0.9167\n",
      "Epoch 19/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0595 - acc: 0.9687 - val_loss: 0.1767 - val_acc: 0.9167\n",
      "Epoch 20/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0757 - acc: 0.9687 - val_loss: 0.1910 - val_acc: 0.8333\n",
      "Epoch 21/200\n",
      "96/96 [==============================] - 0s 364us/step - loss: 0.0617 - acc: 0.9687 - val_loss: 0.2324 - val_acc: 0.8333\n",
      "Epoch 22/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.1075 - acc: 0.9479 - val_loss: 0.2895 - val_acc: 0.9167\n",
      "Epoch 23/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0577 - acc: 0.9687 - val_loss: 0.2163 - val_acc: 0.9167\n",
      "Epoch 24/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9583\n",
      "Epoch 25/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0482 - acc: 0.9792 - val_loss: 0.2453 - val_acc: 0.9167\n",
      "Epoch 26/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.1546 - acc: 0.9375 - val_loss: 0.2634 - val_acc: 0.9167\n",
      "Epoch 27/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.1063 - acc: 0.9479 - val_loss: 0.1748 - val_acc: 0.9167\n",
      "Epoch 28/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0406 - acc: 0.9896 - val_loss: 0.1574 - val_acc: 0.9583\n",
      "Epoch 29/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.1356 - acc: 0.9479 - val_loss: 0.1540 - val_acc: 0.9583\n",
      "Epoch 30/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.3113 - acc: 0.9062 - val_loss: 0.4376 - val_acc: 0.8750\n",
      "Epoch 31/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.1378 - acc: 0.9375 - val_loss: 0.2671 - val_acc: 0.9167\n",
      "Epoch 32/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.1003 - acc: 0.9583 - val_loss: 0.2012 - val_acc: 0.9167\n",
      "Epoch 33/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0608 - acc: 0.9896 - val_loss: 0.2013 - val_acc: 0.9167\n",
      "Epoch 34/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0739 - acc: 0.9687 - val_loss: 0.4700 - val_acc: 0.8750\n",
      "Epoch 35/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.1699 - acc: 0.9375 - val_loss: 0.2038 - val_acc: 0.9167\n",
      "Epoch 36/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0529 - acc: 0.9792 - val_loss: 0.1889 - val_acc: 0.9167\n",
      "Epoch 37/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0387 - acc: 0.9687 - val_loss: 0.1918 - val_acc: 0.9167\n",
      "Epoch 38/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0804 - acc: 0.9687 - val_loss: 0.3714 - val_acc: 0.9167\n",
      "Epoch 39/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.1860 - val_acc: 0.8750\n",
      "Epoch 40/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0662 - acc: 0.9687 - val_loss: 0.1929 - val_acc: 0.9167\n",
      "Epoch 41/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0336 - acc: 0.9896 - val_loss: 0.4429 - val_acc: 0.9167\n",
      "Epoch 42/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0915 - acc: 0.9479 - val_loss: 0.1962 - val_acc: 0.9167\n",
      "Epoch 43/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.2772 - val_acc: 0.9167\n",
      "Epoch 44/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0340 - acc: 0.9792 - val_loss: 0.1782 - val_acc: 0.9583\n",
      "Epoch 45/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.1481 - acc: 0.9375 - val_loss: 0.2697 - val_acc: 0.9167\n",
      "Epoch 46/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0458 - acc: 0.9896 - val_loss: 0.3735 - val_acc: 0.9167\n",
      "Epoch 47/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.2134 - acc: 0.9271 - val_loss: 0.3797 - val_acc: 0.8333\n",
      "Epoch 48/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.3007 - acc: 0.8646 - val_loss: 0.3462 - val_acc: 0.8750\n",
      "Epoch 49/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.2760 - acc: 0.8854 - val_loss: 0.2134 - val_acc: 0.9167\n",
      "Epoch 50/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.1663 - acc: 0.9167 - val_loss: 0.2705 - val_acc: 0.9167\n",
      "Epoch 51/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0744 - acc: 0.9792 - val_loss: 0.2036 - val_acc: 0.9167\n",
      "Epoch 52/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0461 - acc: 0.9792 - val_loss: 0.3697 - val_acc: 0.9167\n",
      "Epoch 53/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0586 - acc: 0.9896 - val_loss: 0.1945 - val_acc: 0.8750\n",
      "Epoch 54/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0756 - acc: 0.9687 - val_loss: 0.3000 - val_acc: 0.9167\n",
      "Epoch 55/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0483 - acc: 0.9896 - val_loss: 0.3602 - val_acc: 0.9167\n",
      "Epoch 56/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0752 - acc: 0.9687 - val_loss: 0.2407 - val_acc: 0.9167\n",
      "Epoch 57/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.1133 - acc: 0.9479 - val_loss: 0.2218 - val_acc: 0.8333\n",
      "Epoch 58/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.0681 - acc: 0.9687 - val_loss: 0.3387 - val_acc: 0.9167\n",
      "Epoch 59/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0602 - acc: 0.9687 - val_loss: 0.1972 - val_acc: 0.8750\n",
      "Epoch 60/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0503 - acc: 0.9792 - val_loss: 0.2602 - val_acc: 0.9167\n",
      "Epoch 61/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0368 - acc: 0.9792 - val_loss: 0.2543 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0730 - acc: 0.9583 - val_loss: 0.4862 - val_acc: 0.9167\n",
      "Epoch 63/200\n",
      "96/96 [==============================] - 0s 364us/step - loss: 0.1613 - acc: 0.9375 - val_loss: 0.2087 - val_acc: 0.8333\n",
      "Epoch 64/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0477 - acc: 0.9896 - val_loss: 0.4031 - val_acc: 0.9167\n",
      "Epoch 65/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0768 - acc: 0.9792 - val_loss: 0.1858 - val_acc: 0.9167\n",
      "Epoch 66/200\n",
      "96/96 [==============================] - 0s 333us/step - loss: 0.0585 - acc: 0.9792 - val_loss: 0.3605 - val_acc: 0.9167\n",
      "Epoch 67/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.1111 - acc: 0.9583 - val_loss: 0.2430 - val_acc: 0.8333\n",
      "Epoch 68/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.1248 - acc: 0.9375 - val_loss: 0.5606 - val_acc: 0.8333\n",
      "Epoch 69/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.1048 - acc: 0.9687 - val_loss: 0.2356 - val_acc: 0.8333\n",
      "Epoch 70/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0954 - acc: 0.9583 - val_loss: 0.3316 - val_acc: 0.9167\n",
      "Epoch 71/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0496 - acc: 0.9792 - val_loss: 0.1723 - val_acc: 0.9167\n",
      "Epoch 72/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0494 - acc: 0.9687 - val_loss: 0.1846 - val_acc: 0.9167\n",
      "Epoch 73/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0528 - acc: 0.9792 - val_loss: 0.2761 - val_acc: 0.9167\n",
      "Epoch 74/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.0453 - acc: 0.9896 - val_loss: 0.2766 - val_acc: 0.9167\n",
      "Epoch 75/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0415 - acc: 0.9792 - val_loss: 0.2352 - val_acc: 0.8333\n",
      "Epoch 76/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0394 - acc: 0.9896 - val_loss: 0.5076 - val_acc: 0.9167\n",
      "Epoch 77/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0773 - acc: 0.9792 - val_loss: 0.3480 - val_acc: 0.8750\n",
      "Epoch 78/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.1708 - acc: 0.9479 - val_loss: 0.6476 - val_acc: 0.8333\n",
      "Epoch 79/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0836 - acc: 0.9792 - val_loss: 0.1888 - val_acc: 0.8750\n",
      "Epoch 80/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0715 - acc: 0.9687 - val_loss: 0.3224 - val_acc: 0.9167\n",
      "Epoch 81/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0562 - acc: 0.9792 - val_loss: 0.1789 - val_acc: 0.9167\n",
      "Epoch 82/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0406 - acc: 0.9896 - val_loss: 0.2181 - val_acc: 0.9167\n",
      "Epoch 83/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0444 - acc: 0.9792 - val_loss: 0.2557 - val_acc: 0.9167\n",
      "Epoch 84/200\n",
      "96/96 [==============================] - 0s 333us/step - loss: 0.0646 - acc: 0.9687 - val_loss: 0.1865 - val_acc: 0.9167\n",
      "Epoch 85/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0715 - acc: 0.9583 - val_loss: 0.3614 - val_acc: 0.9167\n",
      "Epoch 86/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0671 - acc: 0.9687 - val_loss: 0.1910 - val_acc: 0.8750\n",
      "Epoch 87/200\n",
      "96/96 [==============================] - 0s 384us/step - loss: 0.0907 - acc: 0.9583 - val_loss: 0.2728 - val_acc: 0.9167\n",
      "Epoch 88/200\n",
      "96/96 [==============================] - 0s 426us/step - loss: 0.0394 - acc: 0.9687 - val_loss: 0.1877 - val_acc: 0.9167\n",
      "Epoch 89/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0350 - acc: 0.9792 - val_loss: 0.2793 - val_acc: 0.9167\n",
      "Epoch 90/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0291 - acc: 0.9896 - val_loss: 0.2137 - val_acc: 0.9167\n",
      "Epoch 91/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0249 - acc: 0.9896 - val_loss: 0.2251 - val_acc: 0.9167\n",
      "Epoch 92/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0400 - acc: 0.9687 - val_loss: 0.1888 - val_acc: 0.9583\n",
      "Epoch 93/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.0347 - acc: 0.9896 - val_loss: 0.3860 - val_acc: 0.9167\n",
      "Epoch 94/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0539 - acc: 0.9583 - val_loss: 0.3855 - val_acc: 0.9167\n",
      "Epoch 95/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0801 - acc: 0.9792 - val_loss: 0.1919 - val_acc: 0.9167\n",
      "Epoch 96/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0328 - acc: 0.9792 - val_loss: 0.2750 - val_acc: 0.9167\n",
      "Epoch 97/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0264 - acc: 0.9896 - val_loss: 0.1866 - val_acc: 0.9583\n",
      "Epoch 98/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0481 - acc: 0.9687 - val_loss: 0.2056 - val_acc: 0.9167\n",
      "Epoch 99/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.0221 - acc: 0.9896 - val_loss: 0.3098 - val_acc: 0.9167\n",
      "Epoch 100/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0388 - acc: 0.9792 - val_loss: 0.2406 - val_acc: 0.9167\n",
      "Epoch 101/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0316 - acc: 0.9896 - val_loss: 0.2244 - val_acc: 0.9167\n",
      "Epoch 102/200\n",
      "96/96 [==============================] - 0s 312us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.2963 - val_acc: 0.9167\n",
      "Epoch 103/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0215 - acc: 0.9896 - val_loss: 0.1957 - val_acc: 0.9583\n",
      "Epoch 104/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0475 - acc: 0.9687 - val_loss: 0.2458 - val_acc: 0.9167\n",
      "Epoch 105/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0311 - acc: 0.9896 - val_loss: 0.3002 - val_acc: 0.9167\n",
      "Epoch 106/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.2265 - val_acc: 0.9167\n",
      "Epoch 107/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0524 - acc: 0.9583 - val_loss: 0.4442 - val_acc: 0.8750\n",
      "Epoch 108/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.4002 - acc: 0.8854 - val_loss: 0.5150 - val_acc: 0.8333\n",
      "Epoch 109/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.2848 - acc: 0.8437 - val_loss: 0.2345 - val_acc: 0.8333\n",
      "Epoch 110/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.1594 - acc: 0.9375 - val_loss: 0.2982 - val_acc: 0.9167\n",
      "Epoch 111/200\n",
      "96/96 [==============================] - 0s 364us/step - loss: 0.0757 - acc: 0.9687 - val_loss: 0.1633 - val_acc: 0.9167\n",
      "Epoch 112/200\n",
      "96/96 [==============================] - 0s 457us/step - loss: 0.0560 - acc: 0.9792 - val_loss: 0.2318 - val_acc: 0.9167\n",
      "Epoch 113/200\n",
      "96/96 [==============================] - 0s 416us/step - loss: 0.0277 - acc: 0.9896 - val_loss: 0.1575 - val_acc: 0.9583\n",
      "Epoch 114/200\n",
      "96/96 [==============================] - 0s 426us/step - loss: 0.0645 - acc: 0.9687 - val_loss: 0.3299 - val_acc: 0.9167\n",
      "Epoch 115/200\n",
      "96/96 [==============================] - 0s 364us/step - loss: 0.0534 - acc: 0.9687 - val_loss: 0.1747 - val_acc: 0.8750\n",
      "Epoch 116/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0367 - acc: 0.9896 - val_loss: 0.3998 - val_acc: 0.9167\n",
      "Epoch 117/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0985 - acc: 0.9479 - val_loss: 0.2427 - val_acc: 0.9167\n",
      "Epoch 118/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0505 - acc: 0.9792 - val_loss: 0.2149 - val_acc: 0.9167\n",
      "Epoch 119/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0280 - acc: 0.9896 - val_loss: 0.2069 - val_acc: 0.9167\n",
      "Epoch 120/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0313 - acc: 0.9896 - val_loss: 0.2632 - val_acc: 0.9167\n",
      "Epoch 121/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0250 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9167\n",
      "Epoch 122/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0332 - acc: 0.9896 - val_loss: 0.3378 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0317 - acc: 0.9792 - val_loss: 0.2365 - val_acc: 0.9167\n",
      "Epoch 124/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0259 - acc: 0.9896 - val_loss: 0.1873 - val_acc: 0.9167\n",
      "Epoch 125/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0260 - acc: 0.9896 - val_loss: 0.3443 - val_acc: 0.9167\n",
      "Epoch 126/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.1196 - acc: 0.9583 - val_loss: 0.1794 - val_acc: 0.9583\n",
      "Epoch 127/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.1994 - acc: 0.9271 - val_loss: 0.4465 - val_acc: 0.9167\n",
      "Epoch 128/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0581 - acc: 0.9687 - val_loss: 0.1756 - val_acc: 0.9167\n",
      "Epoch 129/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 0.2497 - val_acc: 0.9167\n",
      "Epoch 130/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0317 - acc: 0.9896 - val_loss: 0.1805 - val_acc: 0.9167\n",
      "Epoch 131/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0339 - acc: 0.9792 - val_loss: 0.2939 - val_acc: 0.9167\n",
      "Epoch 132/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0229 - acc: 0.9896 - val_loss: 0.1749 - val_acc: 0.9583\n",
      "Epoch 133/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0243 - acc: 0.9896 - val_loss: 0.3400 - val_acc: 0.9167\n",
      "Epoch 134/200\n",
      "96/96 [==============================] - 0s 301us/step - loss: 0.0453 - acc: 0.9687 - val_loss: 0.2486 - val_acc: 0.9167\n",
      "Epoch 135/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0286 - acc: 0.9896 - val_loss: 0.2876 - val_acc: 0.9167\n",
      "Epoch 136/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0358 - acc: 0.9792 - val_loss: 0.1961 - val_acc: 0.9167\n",
      "Epoch 137/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0544 - acc: 0.9792 - val_loss: 0.4107 - val_acc: 0.9167\n",
      "Epoch 138/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0636 - acc: 0.9479 - val_loss: 0.2089 - val_acc: 0.9167\n",
      "Epoch 139/200\n",
      "96/96 [==============================] - 0s 395us/step - loss: 0.0686 - acc: 0.9687 - val_loss: 0.2042 - val_acc: 0.8750\n",
      "Epoch 140/200\n",
      "96/96 [==============================] - 0s 384us/step - loss: 0.0587 - acc: 0.9687 - val_loss: 0.2405 - val_acc: 0.9167\n",
      "Epoch 141/200\n",
      "96/96 [==============================] - 0s 416us/step - loss: 0.0220 - acc: 0.9896 - val_loss: 0.2125 - val_acc: 0.9167\n",
      "Epoch 142/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0431 - acc: 0.9792 - val_loss: 0.3720 - val_acc: 0.9167\n",
      "Epoch 143/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.1273 - acc: 0.9479 - val_loss: 0.2470 - val_acc: 0.9167\n",
      "Epoch 144/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0689 - acc: 0.9687 - val_loss: 0.2539 - val_acc: 0.9167\n",
      "Epoch 145/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.1943 - acc: 0.9375 - val_loss: 0.2382 - val_acc: 0.9167\n",
      "Epoch 146/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0869 - acc: 0.9687 - val_loss: 0.1663 - val_acc: 0.9167\n",
      "Epoch 147/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 0.2634 - val_acc: 0.9167\n",
      "Epoch 148/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0403 - acc: 0.9687 - val_loss: 0.1930 - val_acc: 0.9167\n",
      "Epoch 149/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0205 - acc: 0.9896 - val_loss: 0.3946 - val_acc: 0.9167\n",
      "Epoch 150/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0354 - acc: 0.9792 - val_loss: 0.1883 - val_acc: 0.9167\n",
      "Epoch 151/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0947 - acc: 0.9687 - val_loss: 0.8601 - val_acc: 0.7917\n",
      "Epoch 152/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.2437 - acc: 0.9271 - val_loss: 0.4745 - val_acc: 0.8333\n",
      "Epoch 153/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.1473 - acc: 0.9271 - val_loss: 0.4901 - val_acc: 0.8333\n",
      "Epoch 154/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0797 - acc: 0.9792 - val_loss: 0.1776 - val_acc: 0.9167\n",
      "Epoch 155/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0719 - acc: 0.9896 - val_loss: 0.2108 - val_acc: 0.9167\n",
      "Epoch 156/200\n",
      "96/96 [==============================] - 0s 301us/step - loss: 0.0338 - acc: 0.9792 - val_loss: 0.2333 - val_acc: 0.9167\n",
      "Epoch 157/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0299 - acc: 0.9896 - val_loss: 0.2199 - val_acc: 0.9167\n",
      "Epoch 158/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0344 - acc: 0.9792 - val_loss: 0.1858 - val_acc: 0.9167\n",
      "Epoch 159/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.0324 - acc: 0.9792 - val_loss: 0.3596 - val_acc: 0.9167\n",
      "Epoch 160/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0345 - acc: 0.9896 - val_loss: 0.1827 - val_acc: 0.9167\n",
      "Epoch 161/200\n",
      "96/96 [==============================] - 0s 332us/step - loss: 0.0312 - acc: 0.9896 - val_loss: 0.3656 - val_acc: 0.9167\n",
      "Epoch 162/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0597 - acc: 0.9687 - val_loss: 0.2160 - val_acc: 0.9167\n",
      "Epoch 163/200\n",
      "96/96 [==============================] - 0s 322us/step - loss: 0.1064 - acc: 0.9687 - val_loss: 0.2262 - val_acc: 0.9167\n",
      "Epoch 164/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0369 - acc: 0.9792 - val_loss: 0.2574 - val_acc: 0.9167\n",
      "Epoch 165/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0455 - acc: 0.9687 - val_loss: 0.2124 - val_acc: 0.9167\n",
      "Epoch 166/200\n",
      "96/96 [==============================] - 0s 416us/step - loss: 0.0250 - acc: 0.9896 - val_loss: 0.1996 - val_acc: 0.9167\n",
      "Epoch 167/200\n",
      "96/96 [==============================] - 0s 436us/step - loss: 0.0257 - acc: 0.9896 - val_loss: 0.2101 - val_acc: 0.9167\n",
      "Epoch 168/200\n",
      "96/96 [==============================] - 0s 395us/step - loss: 0.0278 - acc: 0.9792 - val_loss: 0.2607 - val_acc: 0.9167\n",
      "Epoch 169/200\n",
      "96/96 [==============================] - 0s 405us/step - loss: 0.0414 - acc: 0.9896 - val_loss: 0.3564 - val_acc: 0.9167\n",
      "Epoch 170/200\n",
      "96/96 [==============================] - 0s 405us/step - loss: 0.0338 - acc: 0.9896 - val_loss: 0.1896 - val_acc: 0.9583\n",
      "Epoch 171/200\n",
      "96/96 [==============================] - 0s 384us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.2986 - val_acc: 0.9167\n",
      "Epoch 172/200\n",
      "96/96 [==============================] - 0s 363us/step - loss: 0.0232 - acc: 0.9896 - val_loss: 0.1931 - val_acc: 0.9167\n",
      "Epoch 173/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0359 - acc: 0.9792 - val_loss: 0.3017 - val_acc: 0.9167\n",
      "Epoch 174/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0186 - acc: 0.9896 - val_loss: 0.2163 - val_acc: 0.9167\n",
      "Epoch 175/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0226 - acc: 0.9896 - val_loss: 0.3719 - val_acc: 0.9167\n",
      "Epoch 176/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0378 - acc: 0.9792 - val_loss: 0.2221 - val_acc: 0.9167\n",
      "Epoch 177/200\n",
      "96/96 [==============================] - 0s 436us/step - loss: 0.0281 - acc: 0.9896 - val_loss: 0.2107 - val_acc: 0.9167\n",
      "Epoch 178/200\n",
      "96/96 [==============================] - 0s 395us/step - loss: 0.0288 - acc: 0.9896 - val_loss: 0.3825 - val_acc: 0.9167\n",
      "Epoch 179/200\n",
      "96/96 [==============================] - 0s 457us/step - loss: 0.0330 - acc: 0.9792 - val_loss: 0.2800 - val_acc: 0.9167\n",
      "Epoch 180/200\n",
      "96/96 [==============================] - 0s 415us/step - loss: 0.0508 - acc: 0.9792 - val_loss: 0.2087 - val_acc: 0.8750\n",
      "Epoch 181/200\n",
      "96/96 [==============================] - 0s 634us/step - loss: 0.0460 - acc: 0.9687 - val_loss: 0.3607 - val_acc: 0.9167\n",
      "Epoch 182/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0713 - acc: 0.9687 - val_loss: 0.3212 - val_acc: 0.9167\n",
      "Epoch 183/200\n",
      "96/96 [==============================] - 0s 405us/step - loss: 0.0355 - acc: 0.9896 - val_loss: 0.2887 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0211 - acc: 0.9896 - val_loss: 0.1957 - val_acc: 0.9167\n",
      "Epoch 185/200\n",
      "96/96 [==============================] - 0s 405us/step - loss: 0.0312 - acc: 0.9896 - val_loss: 0.3461 - val_acc: 0.9167\n",
      "Epoch 186/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0426 - acc: 0.9792 - val_loss: 0.1956 - val_acc: 0.9167\n",
      "Epoch 187/200\n",
      "96/96 [==============================] - 0s 364us/step - loss: 0.0426 - acc: 0.9896 - val_loss: 0.3729 - val_acc: 0.9167\n",
      "Epoch 188/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0298 - acc: 0.9896 - val_loss: 0.2561 - val_acc: 0.9167\n",
      "Epoch 189/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0211 - acc: 0.9896 - val_loss: 0.2796 - val_acc: 0.9167\n",
      "Epoch 190/200\n",
      "96/96 [==============================] - 0s 384us/step - loss: 0.0278 - acc: 0.9896 - val_loss: 0.3492 - val_acc: 0.9167\n",
      "Epoch 191/200\n",
      "96/96 [==============================] - 0s 416us/step - loss: 0.0277 - acc: 0.9792 - val_loss: 0.2025 - val_acc: 0.9583\n",
      "Epoch 192/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0459 - acc: 0.9896 - val_loss: 0.2940 - val_acc: 0.9167\n",
      "Epoch 193/200\n",
      "96/96 [==============================] - 0s 395us/step - loss: 0.0236 - acc: 0.9896 - val_loss: 0.2173 - val_acc: 0.9167\n",
      "Epoch 194/200\n",
      "96/96 [==============================] - 0s 395us/step - loss: 0.0334 - acc: 0.9792 - val_loss: 0.2399 - val_acc: 0.9167\n",
      "Epoch 195/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0519 - acc: 0.9687 - val_loss: 0.3097 - val_acc: 0.9167\n",
      "Epoch 196/200\n",
      "96/96 [==============================] - 0s 364us/step - loss: 0.0169 - acc: 0.9896 - val_loss: 0.2281 - val_acc: 0.9167\n",
      "Epoch 197/200\n",
      "96/96 [==============================] - 0s 426us/step - loss: 0.0224 - acc: 0.9896 - val_loss: 0.4287 - val_acc: 0.9167\n",
      "Epoch 198/200\n",
      "96/96 [==============================] - 0s 374us/step - loss: 0.0483 - acc: 0.9687 - val_loss: 0.2183 - val_acc: 0.9167\n",
      "Epoch 199/200\n",
      "96/96 [==============================] - 0s 343us/step - loss: 0.0224 - acc: 0.9896 - val_loss: 0.3028 - val_acc: 0.9167\n",
      "Epoch 200/200\n",
      "96/96 [==============================] - 0s 353us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.2340 - val_acc: 0.9167\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=10,\n",
    "          epochs = 200,\n",
    "          verbose = 1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題4】House Pricesのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umini\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\umini\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"df_grlivearea_yearbuilt.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "X = df.loc[:,['GrLivArea', 'YearBuilt']]\n",
    "y = df.loc[:,'SalePrice']\n",
    "X = np.array(X)\n",
    "y = np.array(y)[:,np.newaxis]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)\n",
    "y_log = np.log(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_log, test_size = 0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(1, activation=None)(x) # identity_function\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossをmseに\n",
    "model.compile(loss='mse',\n",
    "              optimizer = tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 234 samples\n",
      "Epoch 1/50\n",
      "934/934 [==============================] - 0s 333us/step - loss: 39506.6172 - mean_squared_error: 39506.6172 - val_loss: 3197.7952 - val_mean_squared_error: 3197.7952\n",
      "Epoch 2/50\n",
      "934/934 [==============================] - 0s 76us/step - loss: 2153.3951 - mean_squared_error: 2153.3951 - val_loss: 548.6060 - val_mean_squared_error: 548.6060\n",
      "Epoch 3/50\n",
      "934/934 [==============================] - 0s 57us/step - loss: 145.9982 - mean_squared_error: 145.9982 - val_loss: 2.5183 - val_mean_squared_error: 2.5183\n",
      "Epoch 4/50\n",
      "934/934 [==============================] - 0s 79us/step - loss: 22.7052 - mean_squared_error: 22.7052 - val_loss: 15.6023 - val_mean_squared_error: 15.6023\n",
      "Epoch 5/50\n",
      "934/934 [==============================] - 0s 68us/step - loss: 4.5116 - mean_squared_error: 4.5116 - val_loss: 0.3678 - val_mean_squared_error: 0.3678\n",
      "Epoch 6/50\n",
      "934/934 [==============================] - 0s 59us/step - loss: 0.8847 - mean_squared_error: 0.8847 - val_loss: 0.3212 - val_mean_squared_error: 0.3212\n",
      "Epoch 7/50\n",
      "934/934 [==============================] - 0s 61us/step - loss: 0.4343 - mean_squared_error: 0.4343 - val_loss: 0.2417 - val_mean_squared_error: 0.2417\n",
      "Epoch 8/50\n",
      "934/934 [==============================] - 0s 63us/step - loss: 0.3400 - mean_squared_error: 0.3400 - val_loss: 0.1616 - val_mean_squared_error: 0.1616\n",
      "Epoch 9/50\n",
      "934/934 [==============================] - 0s 58us/step - loss: 0.3008 - mean_squared_error: 0.3008 - val_loss: 0.1654 - val_mean_squared_error: 0.1654\n",
      "Epoch 10/50\n",
      "934/934 [==============================] - 0s 61us/step - loss: 0.2759 - mean_squared_error: 0.2759 - val_loss: 0.1479 - val_mean_squared_error: 0.1479\n",
      "Epoch 11/50\n",
      "934/934 [==============================] - 0s 62us/step - loss: 0.2474 - mean_squared_error: 0.2474 - val_loss: 0.1341 - val_mean_squared_error: 0.1341\n",
      "Epoch 12/50\n",
      "934/934 [==============================] - 0s 56us/step - loss: 0.2290 - mean_squared_error: 0.2290 - val_loss: 0.1197 - val_mean_squared_error: 0.1197\n",
      "Epoch 13/50\n",
      "934/934 [==============================] - 0s 53us/step - loss: 0.2104 - mean_squared_error: 0.2104 - val_loss: 0.1130 - val_mean_squared_error: 0.1130\n",
      "Epoch 14/50\n",
      "934/934 [==============================] - 0s 59us/step - loss: 0.1964 - mean_squared_error: 0.1964 - val_loss: 0.1106 - val_mean_squared_error: 0.1106\n",
      "Epoch 15/50\n",
      "934/934 [==============================] - 0s 58us/step - loss: 0.1835 - mean_squared_error: 0.1835 - val_loss: 0.1069 - val_mean_squared_error: 0.1069\n",
      "Epoch 16/50\n",
      "934/934 [==============================] - 0s 53us/step - loss: 0.1732 - mean_squared_error: 0.1732 - val_loss: 0.1086 - val_mean_squared_error: 0.1086\n",
      "Epoch 17/50\n",
      "934/934 [==============================] - 0s 52us/step - loss: 0.1654 - mean_squared_error: 0.1654 - val_loss: 0.0956 - val_mean_squared_error: 0.0956\n",
      "Epoch 18/50\n",
      "934/934 [==============================] - 0s 53us/step - loss: 0.1541 - mean_squared_error: 0.1541 - val_loss: 0.0929 - val_mean_squared_error: 0.0929\n",
      "Epoch 19/50\n",
      "934/934 [==============================] - 0s 53us/step - loss: 0.1464 - mean_squared_error: 0.1464 - val_loss: 0.0890 - val_mean_squared_error: 0.0890\n",
      "Epoch 20/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.1401 - mean_squared_error: 0.1401 - val_loss: 0.0865 - val_mean_squared_error: 0.0865\n",
      "Epoch 21/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.1327 - mean_squared_error: 0.1327 - val_loss: 0.0849 - val_mean_squared_error: 0.0849\n",
      "Epoch 22/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.1280 - mean_squared_error: 0.1280 - val_loss: 0.0903 - val_mean_squared_error: 0.0903\n",
      "Epoch 23/50\n",
      "934/934 [==============================] - 0s 63us/step - loss: 0.1214 - mean_squared_error: 0.1214 - val_loss: 0.0775 - val_mean_squared_error: 0.0775\n",
      "Epoch 24/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.1170 - mean_squared_error: 0.1170 - val_loss: 0.0770 - val_mean_squared_error: 0.0770\n",
      "Epoch 25/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.1117 - mean_squared_error: 0.1117 - val_loss: 0.0771 - val_mean_squared_error: 0.0771\n",
      "Epoch 26/50\n",
      "934/934 [==============================] - 0s 57us/step - loss: 0.1071 - mean_squared_error: 0.1071 - val_loss: 0.0739 - val_mean_squared_error: 0.0739\n",
      "Epoch 27/50\n",
      "934/934 [==============================] - 0s 58us/step - loss: 0.1037 - mean_squared_error: 0.1037 - val_loss: 0.0716 - val_mean_squared_error: 0.0716\n",
      "Epoch 28/50\n",
      "934/934 [==============================] - 0s 52us/step - loss: 0.0994 - mean_squared_error: 0.0994 - val_loss: 0.0710 - val_mean_squared_error: 0.0710\n",
      "Epoch 29/50\n",
      "934/934 [==============================] - 0s 53us/step - loss: 0.0966 - mean_squared_error: 0.0966 - val_loss: 0.0694 - val_mean_squared_error: 0.0694\n",
      "Epoch 30/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.0948 - mean_squared_error: 0.0948 - val_loss: 0.0710 - val_mean_squared_error: 0.0710\n",
      "Epoch 31/50\n",
      "934/934 [==============================] - 0s 53us/step - loss: 0.0912 - mean_squared_error: 0.0912 - val_loss: 0.0681 - val_mean_squared_error: 0.0681\n",
      "Epoch 32/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.0886 - mean_squared_error: 0.0886 - val_loss: 0.0686 - val_mean_squared_error: 0.0686\n",
      "Epoch 33/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.0844 - mean_squared_error: 0.0844 - val_loss: 0.0658 - val_mean_squared_error: 0.0658\n",
      "Epoch 34/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.0831 - mean_squared_error: 0.0831 - val_loss: 0.0652 - val_mean_squared_error: 0.0652\n",
      "Epoch 35/50\n",
      "934/934 [==============================] - 0s 57us/step - loss: 0.0814 - mean_squared_error: 0.0814 - val_loss: 0.0704 - val_mean_squared_error: 0.0704\n",
      "Epoch 36/50\n",
      "934/934 [==============================] - 0s 57us/step - loss: 0.0812 - mean_squared_error: 0.0812 - val_loss: 0.0640 - val_mean_squared_error: 0.0640\n",
      "Epoch 37/50\n",
      "934/934 [==============================] - 0s 60us/step - loss: 0.0772 - mean_squared_error: 0.0772 - val_loss: 0.0627 - val_mean_squared_error: 0.0627\n",
      "Epoch 38/50\n",
      "934/934 [==============================] - 0s 58us/step - loss: 0.0758 - mean_squared_error: 0.0758 - val_loss: 0.0631 - val_mean_squared_error: 0.0631\n",
      "Epoch 39/50\n",
      "934/934 [==============================] - 0s 57us/step - loss: 0.0737 - mean_squared_error: 0.0737 - val_loss: 0.0622 - val_mean_squared_error: 0.0622\n",
      "Epoch 40/50\n",
      "934/934 [==============================] - 0s 53us/step - loss: 0.0727 - mean_squared_error: 0.0727 - val_loss: 0.0618 - val_mean_squared_error: 0.0618\n",
      "Epoch 41/50\n",
      "934/934 [==============================] - 0s 51us/step - loss: 0.0712 - mean_squared_error: 0.0712 - val_loss: 0.0664 - val_mean_squared_error: 0.0664\n",
      "Epoch 42/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.0705 - mean_squared_error: 0.0705 - val_loss: 0.0658 - val_mean_squared_error: 0.0658\n",
      "Epoch 43/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.0696 - mean_squared_error: 0.0696 - val_loss: 0.0599 - val_mean_squared_error: 0.0599\n",
      "Epoch 44/50\n",
      "934/934 [==============================] - 0s 53us/step - loss: 0.0688 - mean_squared_error: 0.0688 - val_loss: 0.0594 - val_mean_squared_error: 0.0594\n",
      "Epoch 45/50\n",
      "934/934 [==============================] - 0s 53us/step - loss: 0.0694 - mean_squared_error: 0.0694 - val_loss: 0.0594 - val_mean_squared_error: 0.0594\n",
      "Epoch 46/50\n",
      "934/934 [==============================] - 0s 59us/step - loss: 0.0667 - mean_squared_error: 0.0667 - val_loss: 0.0584 - val_mean_squared_error: 0.0584\n",
      "Epoch 47/50\n",
      "934/934 [==============================] - 0s 65us/step - loss: 0.0656 - mean_squared_error: 0.0656 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
      "Epoch 48/50\n",
      "934/934 [==============================] - 0s 60us/step - loss: 0.0641 - mean_squared_error: 0.0641 - val_loss: 0.0588 - val_mean_squared_error: 0.0588\n",
      "Epoch 49/50\n",
      "934/934 [==============================] - 0s 54us/step - loss: 0.0649 - mean_squared_error: 0.0649 - val_loss: 0.0573 - val_mean_squared_error: 0.0573\n",
      "Epoch 50/50\n",
      "934/934 [==============================] - 0s 57us/step - loss: 0.0631 - mean_squared_error: 0.0631 - val_loss: 0.0575 - val_mean_squared_error: 0.0575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b05bb1df28>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=50,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題5】MNISTのモデルを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "せっかくなのでconvolutionでやる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n",
    "print(y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28, 1)\n",
      "(12000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional apiで2層のconvlutionと2層の全結合層\n",
    "input_data = tf.keras.layers.Input(shape=(28, 28,1))\n",
    "conv1 = tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation=tf.nn.relu)(input_data)\n",
    "pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation=tf.nn.relu)(pool1)\n",
    "pool2 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv2)\n",
    "drop = tf.keras.layers.Dropout(rate=0.5)(pool2)\n",
    "flat = tf.keras.layers.Flatten()(drop)\n",
    "hidden1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)(flat)\n",
    "output = tf.keras.layers.Dense(10, activation=tf.nn.softmax)(hidden1)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.1040 - acc: 0.9719 - val_loss: 0.0671 - val_acc: 0.9848\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1059 - acc: 0.9716 - val_loss: 0.0745 - val_acc: 0.9810\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1030 - acc: 0.9727 - val_loss: 0.0645 - val_acc: 0.9828\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.1041 - acc: 0.9722 - val_loss: 0.0708 - val_acc: 0.9816\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1099 - acc: 0.9714 - val_loss: 0.0627 - val_acc: 0.9828\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1094 - acc: 0.9730 - val_loss: 0.0598 - val_acc: 0.9847\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1032 - acc: 0.9733 - val_loss: 0.0664 - val_acc: 0.9848\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.1142 - acc: 0.9713 - val_loss: 0.0608 - val_acc: 0.9848\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1055 - acc: 0.9734 - val_loss: 0.0578 - val_acc: 0.9851\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.1031 - acc: 0.9747 - val_loss: 0.0806 - val_acc: 0.9813\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.1080 - acc: 0.9739 - val_loss: 0.0674 - val_acc: 0.9824\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1081 - acc: 0.9741 - val_loss: 0.0717 - val_acc: 0.9850\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1071 - acc: 0.9741 - val_loss: 0.0737 - val_acc: 0.9824\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1005 - acc: 0.9756 - val_loss: 0.0679 - val_acc: 0.9839\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.1067 - acc: 0.9744 - val_loss: 0.0736 - val_acc: 0.9831\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1113 - acc: 0.9742 - val_loss: 0.0851 - val_acc: 0.9793\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1110 - acc: 0.9757 - val_loss: 0.0813 - val_acc: 0.9856\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1188 - acc: 0.9744 - val_loss: 0.1053 - val_acc: 0.9783\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1069 - acc: 0.9759 - val_loss: 0.0765 - val_acc: 0.9838\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1100 - acc: 0.9755 - val_loss: 0.0920 - val_acc: 0.9812\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1001 - acc: 0.9768 - val_loss: 0.0877 - val_acc: 0.9792\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1267 - acc: 0.9739 - val_loss: 0.0880 - val_acc: 0.9813\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1170 - acc: 0.9759 - val_loss: 0.0759 - val_acc: 0.9848\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.1187 - acc: 0.9759 - val_loss: 0.0983 - val_acc: 0.9772\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1180 - acc: 0.9751 - val_loss: 0.0764 - val_acc: 0.9837\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1118 - acc: 0.9766 - val_loss: 0.0772 - val_acc: 0.9847\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1248 - acc: 0.9766 - val_loss: 0.1117 - val_acc: 0.9764\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1361 - acc: 0.9755 - val_loss: 0.0947 - val_acc: 0.9831\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1421 - acc: 0.9741 - val_loss: 0.0954 - val_acc: 0.9783\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1434 - acc: 0.9740 - val_loss: 0.0922 - val_acc: 0.9836\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1348 - acc: 0.9757 - val_loss: 0.0890 - val_acc: 0.9818\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1453 - acc: 0.9753 - val_loss: 0.0790 - val_acc: 0.9843\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1469 - acc: 0.9752 - val_loss: 0.0995 - val_acc: 0.9824\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1601 - acc: 0.9730 - val_loss: 0.0917 - val_acc: 0.9838\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1410 - acc: 0.9747 - val_loss: 0.1031 - val_acc: 0.9840\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.1346 - acc: 0.9746 - val_loss: 0.1030 - val_acc: 0.9767\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1414 - acc: 0.9744 - val_loss: 0.1055 - val_acc: 0.9781\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1537 - acc: 0.9749 - val_loss: 0.0938 - val_acc: 0.9795\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1619 - acc: 0.9738 - val_loss: 0.1327 - val_acc: 0.9816\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1860 - acc: 0.9706 - val_loss: 0.1651 - val_acc: 0.9720\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.2188 - acc: 0.9644 - val_loss: 0.1571 - val_acc: 0.9673\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.2428 - acc: 0.9659 - val_loss: 0.1380 - val_acc: 0.9750\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.2621 - acc: 0.9660 - val_loss: 0.1747 - val_acc: 0.9640\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.3168 - acc: 0.9607 - val_loss: 0.2273 - val_acc: 0.9670\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.3199 - acc: 0.9677 - val_loss: 0.1885 - val_acc: 0.9816\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.3834 - acc: 0.9573 - val_loss: 0.1971 - val_acc: 0.9698\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.3592 - acc: 0.9551 - val_loss: 0.3328 - val_acc: 0.9492\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.3976 - acc: 0.9481 - val_loss: 0.2433 - val_acc: 0.9666\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.3947 - acc: 0.9485 - val_loss: 0.2563 - val_acc: 0.9398\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.4183 - acc: 0.9432 - val_loss: 0.2633 - val_acc: 0.9575\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.3991 - acc: 0.9543 - val_loss: 0.2200 - val_acc: 0.9728\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.4416 - acc: 0.9557 - val_loss: 0.2815 - val_acc: 0.9591\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.4881 - acc: 0.9496 - val_loss: 0.2655 - val_acc: 0.9681\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.5666 - acc: 0.9396 - val_loss: 0.3600 - val_acc: 0.9511\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.5624 - acc: 0.9453 - val_loss: 0.3028 - val_acc: 0.9627\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.5031 - acc: 0.9502 - val_loss: 0.2464 - val_acc: 0.9715\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.5000 - acc: 0.9441 - val_loss: 0.2844 - val_acc: 0.9509\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.4333 - acc: 0.9524 - val_loss: 0.2748 - val_acc: 0.9666\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.5851 - acc: 0.9506 - val_loss: 0.3706 - val_acc: 0.9654\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.5506 - acc: 0.9577 - val_loss: 0.3731 - val_acc: 0.9726\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.5467 - acc: 0.9600 - val_loss: 0.3266 - val_acc: 0.9743\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.5363 - acc: 0.9614 - val_loss: 0.4420 - val_acc: 0.9681\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.6876 - acc: 0.9516 - val_loss: 0.3095 - val_acc: 0.9744\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.7296 - acc: 0.9457 - val_loss: 0.3621 - val_acc: 0.9681\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.6873 - acc: 0.9482 - val_loss: 0.3444 - val_acc: 0.9716\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.6188 - acc: 0.9548 - val_loss: 0.3463 - val_acc: 0.9681\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.6051 - acc: 0.9534 - val_loss: 0.3351 - val_acc: 0.9686\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.6449 - acc: 0.9468 - val_loss: 0.3574 - val_acc: 0.9676\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.6707 - acc: 0.9468 - val_loss: 0.3472 - val_acc: 0.9696\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.7853 - acc: 0.9287 - val_loss: 0.5851 - val_acc: 0.9434\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.7126 - acc: 0.9446 - val_loss: 0.3197 - val_acc: 0.9713\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.5726 - acc: 0.9562 - val_loss: 0.3668 - val_acc: 0.9699\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.6389 - acc: 0.9559 - val_loss: 0.7124 - val_acc: 0.9522\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.7969 - acc: 0.9487 - val_loss: 0.3790 - val_acc: 0.9742\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.6805 - acc: 0.9565 - val_loss: 0.4822 - val_acc: 0.9694\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.8392 - acc: 0.9466 - val_loss: 0.4916 - val_acc: 0.9678\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.6589 - acc: 0.9580 - val_loss: 0.3783 - val_acc: 0.9742\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.7455 - acc: 0.9503 - val_loss: 0.3664 - val_acc: 0.9758\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.6397 - acc: 0.9580 - val_loss: 0.3321 - val_acc: 0.9768\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.5977 - acc: 0.9607 - val_loss: 0.5593 - val_acc: 0.9612\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.8020 - acc: 0.9467 - val_loss: 0.5303 - val_acc: 0.9618\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.8642 - acc: 0.9421 - val_loss: 0.4424 - val_acc: 0.9700\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.8220 - acc: 0.9468 - val_loss: 0.4443 - val_acc: 0.9710\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.7517 - acc: 0.9524 - val_loss: 0.4895 - val_acc: 0.9692\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.6891 - acc: 0.9566 - val_loss: 0.3881 - val_acc: 0.9756\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.7239 - acc: 0.9544 - val_loss: 0.4346 - val_acc: 0.9714\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.7018 - acc: 0.9555 - val_loss: 0.4207 - val_acc: 0.9725\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.7610 - acc: 0.9519 - val_loss: 0.3775 - val_acc: 0.9755\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.6765 - acc: 0.9567 - val_loss: 0.4325 - val_acc: 0.9718\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 1.0007 - acc: 0.9365 - val_loss: 0.6097 - val_acc: 0.9602\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.9502 - acc: 0.9400 - val_loss: 0.5484 - val_acc: 0.9652\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.9431 - acc: 0.9404 - val_loss: 0.5074 - val_acc: 0.9675\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.8329 - acc: 0.9471 - val_loss: 0.4559 - val_acc: 0.9697\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.7320 - acc: 0.9538 - val_loss: 0.6074 - val_acc: 0.9605\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 1.3139 - acc: 0.9177 - val_loss: 0.9762 - val_acc: 0.9389\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.8511 - acc: 0.9467 - val_loss: 0.5110 - val_acc: 0.9682\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.9061 - acc: 0.9432 - val_loss: 0.5853 - val_acc: 0.9634\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 1.1883 - acc: 0.9261 - val_loss: 0.6545 - val_acc: 0.9593\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.8392 - acc: 0.9477 - val_loss: 0.4331 - val_acc: 0.9729\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.7673 - acc: 0.9522 - val_loss: 0.4795 - val_acc: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b07b44fac8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,\n",
    "          batch_size=50,\n",
    "          epochs=100,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
