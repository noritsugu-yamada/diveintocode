{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyファイルの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from utils.split import scratch_train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "# %run __.pyでjupyter上で実行\n",
    "%run hello.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "RESULT : 102.4\n"
     ]
    }
   ],
   "source": [
    "# argparserを利用\n",
    "%run hello_argparse.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.6\n",
      "1.2\n",
      "2.4\n",
      "4.8\n",
      "9.6\n",
      "RESULT : 9.6\n"
     ]
    }
   ],
   "source": [
    "# 引数を指定\n",
    "%run hello_argparse.py --display --alpha 0.3 --text \"Hello, argparse!\" --num_iters 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 変更点\n",
    "scratch train_test_split\n",
    "\n",
    "random対応できました\n",
    "\n",
    "さらにスッキリ書くことが出来ました\n",
    "\n",
    "pyfile参照してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上層にあるscratch_train_test_splitファイルの読み込み\n",
    "sys.path.append('../ml-scratch/utils')\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n",
      "(120,)\n",
      "(30,)\n",
      "0.8\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "(120, 4)\n",
      "(30, 4)\n",
      "(120,)\n",
      "(30,)\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# scratchとscikitlearnを比較する\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size = 0.8)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(len(X_train)/len(X))\n",
    "print('-----------------------------')\n",
    "print('-----------------------------')\n",
    "# sklearn_train_test_split\n",
    "sk_X_train, sk_X_test, sk_y_train, sk_y_test = train_test_split(X, y, test_size = 0.2)# train_sizeを揃える\n",
    "print(sk_X_train.shape)\n",
    "print(sk_X_test.shape)\n",
    "print(sk_y_train.shape)\n",
    "print(sk_y_test.shape)\n",
    "print(len(sk_X_train)/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類パイプラインの作成\n",
    "\n",
    "行ったこと\n",
    "Logistic_Regression, Support_Vector_Machine, Decision_Treeをそれぞれ異なる.py_fileとした(modelを切り替える)\n",
    "file内部ではargparseを使って関数に渡す引数をまとめて格納する\n",
    "dataをcsv化してpathを通すことにより3つのdataを切り替えることができる.\n",
    "jupyter上で動作を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iris DataFrame化\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target_names[iris.target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#virgicolorとvirginica (setosaを除く)\n",
    "df_vergicolor_and_virginica = df[df['target'] != 'setosa']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris dataをcsv_fileに書き出す(1度のみ実行)\n",
    " \n",
    "#df_vergicolor_and_virginica.to_csv('df_vergicolor_and_virginica.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple1 をfileに書き出す(1度のみ実行)\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0= [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]\n",
    "\n",
    "df_simple1 = pd.DataFrame(X, columns=['f0', 'f1'])\n",
    "df_simple1['y'] = y\n",
    "\n",
    "#df_simple1.to_csv('df_simple1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_data2もcsvに(1度だけ実行)\n",
    "\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "       \n",
    "       \n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "       \n",
    "df = pd.DataFrame(X, columns=['X1', 'X2'])\n",
    "df['target'] = y\n",
    "\n",
    "#df.to_csv('df_simple2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "['virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'versicolor'\n",
      " 'virginica' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'virginica' 'versicolor' 'versicolor' 'virginica' 'virginica' 'virginica'\n",
      " 'versicolor' 'virginica' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'virginica' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'virginica' 'versicolor' 'versicolor'] ['virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'versicolor'\n",
      " 'virginica' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'virginica' 'versicolor' 'versicolor' 'virginica' 'virginica' 'virginica'\n",
      " 'versicolor' 'virginica' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'virginica' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'virginica' 'versicolor' 'versicolor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umini\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# iris_dataset Logistic_Regression\n",
    "%run ../ml-scratch/utils/logistic_regression_clsifier.py --file_path  \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_vergicolor_and_virginica.csv\" --penalty \"l2\" --test_size=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "['virginica' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'virginica' 'virginica' 'versicolor' 'virginica' 'versicolor'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'virginica' 'virginica'\n",
      " 'versicolor' 'versicolor' 'virginica' 'versicolor' 'virginica'] ['virginica' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'virginica' 'virginica' 'versicolor' 'virginica' 'versicolor'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'virginica' 'virginica'\n",
      " 'versicolor' 'versicolor' 'virginica' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# iris SVM\n",
    "%run ../ml-scratch/utils/support_vector_machine.py --file_path \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_vergicolor_and_virginica.csv\" --C 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "['virginica' 'virginica' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'versicolor' 'versicolor' 'virginica' 'versicolor' 'versicolor'\n",
      " 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'versicolor'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'virginica'] ['virginica' 'virginica' 'versicolor' 'versicolor' 'versicolor'\n",
      " 'versicolor' 'versicolor' 'virginica' 'versicolor' 'versicolor'\n",
      " 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'versicolor'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# iris decision_tree_classifier \n",
    "%run ../ml-scratch/utils/decision_tree.py --file_path \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_vergicolor_and_virginica.csv\" --max_depth 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[ 1 -1  1  1  1 -1  1  1  1  1  1 -1  1  1 -1 -1 -1  1  1 -1  1 -1 -1  1\n",
      " -1  1 -1 -1  1  1 -1  1 -1  1  1  1 -1  1  1 -1  1 -1  1  1  1 -1  1 -1\n",
      "  1  1 -1 -1 -1  1 -1 -1 -1  1 -1  1  1 -1  1 -1 -1 -1  1  1 -1  1 -1 -1\n",
      " -1  1  1 -1 -1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1  1 -1 -1  1  1  1\n",
      " -1  1  1 -1  1  1  1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1  1  1  1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1 -1 -1  1 -1 -1  1  1  1 -1  1 -1 -1 -1  1 -1 -1 -1\n",
      "  1 -1 -1 -1 -1 -1] [ 1 -1  1  1  1 -1  1  1  1  1  1 -1  1  1 -1 -1 -1  1  1 -1  1 -1 -1  1\n",
      " -1  1 -1 -1  1  1 -1  1 -1  1  1  1 -1  1  1 -1  1 -1  1  1  1 -1  1 -1\n",
      "  1  1 -1 -1 -1  1 -1 -1 -1  1 -1  1  1 -1  1 -1 -1 -1  1  1 -1  1 -1 -1\n",
      " -1  1  1 -1 -1  1 -1 -1 -1  1  1  1 -1 -1 -1 -1  1  1  1 -1 -1  1  1  1\n",
      " -1  1  1 -1  1  1  1 -1 -1 -1 -1 -1 -1  1  1  1 -1 -1  1  1  1  1 -1 -1\n",
      "  1  1 -1 -1  1  1  1 -1 -1  1 -1 -1  1  1  1 -1  1 -1 -1 -1  1 -1 -1 -1\n",
      "  1 -1 -1 -1 -1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umini\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# simple1 LogisticRegression\n",
    "%run ../ml-scratch/utils/logistic_regression_clsifier.py --file_path  \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_simple1.csv\" --penalty \"l2\" --test_size=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9133333333333333\n",
      "[ 1 -1 -1  1  1 -1 -1 -1  1 -1 -1  1  1  1  1 -1  1  1  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  1  1 -1 -1  1 -1 -1  1 -1  1  1  1 -1  1 -1 -1 -1  1  1  1  1\n",
      " -1 -1  1  1  1 -1  1  1 -1  1  1  1 -1 -1 -1 -1 -1  1  1  1 -1  1  1  1\n",
      " -1 -1  1  1 -1  1  1 -1 -1  1  1  1  1  1  1  1  1 -1 -1  1  1  1  1 -1\n",
      " -1 -1  1  1  1  1 -1  1  1  1  1 -1  1 -1  1  1 -1  1  1 -1  1 -1  1 -1\n",
      "  1 -1 -1  1  1  1  1  1  1 -1  1 -1  1  1  1  1  1  1  1 -1 -1  1  1 -1\n",
      "  1  1  1  1 -1  1] [ 1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1  1  1 -1  1  1  1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1  1 -1 -1  1 -1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1  1  1 -1  1\n",
      " -1 -1  1  1  1 -1  1  1 -1  1  1  1 -1 -1 -1 -1 -1  1  1  1 -1  1  1  1\n",
      " -1 -1  1  1 -1  1  1 -1 -1  1  1  1  1  1  1  1  1 -1 -1  1  1  1 -1 -1\n",
      " -1 -1  1 -1  1  1 -1  1  1  1 -1 -1  1 -1  1  1 -1 -1  1 -1 -1 -1  1 -1\n",
      "  1 -1 -1  1 -1  1  1  1  1 -1  1 -1  1  1  1  1  1  1  1 -1 -1  1  1 -1\n",
      "  1  1  1  1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "# simple1 SVM\n",
    "%run ../ml-scratch/utils/support_vector_machine.py --file_path \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_simple1.csv\" --C 2.0 --test_size  0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[-1 -1 -1 -1 -1  1 -1 -1 -1  1 -1  1  1 -1  1  1  1  1 -1 -1 -1 -1  1 -1\n",
      " -1  1 -1  1 -1  1 -1  1 -1  1  1  1 -1  1 -1 -1  1 -1  1 -1  1 -1  1 -1\n",
      " -1 -1 -1  1 -1  1  1 -1  1  1  1 -1 -1  1 -1 -1  1  1  1 -1 -1  1  1  1\n",
      "  1  1 -1 -1 -1  1  1  1 -1  1 -1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1 -1  1 -1] [-1 -1 -1 -1 -1  1 -1 -1 -1  1 -1  1  1 -1  1  1  1  1 -1 -1 -1 -1  1 -1\n",
      " -1  1 -1  1 -1  1 -1  1 -1  1  1  1 -1  1 -1 -1  1 -1  1 -1  1 -1  1 -1\n",
      " -1 -1 -1  1 -1  1  1 -1  1  1  1 -1 -1  1 -1 -1  1  1  1 -1 -1  1  1  1\n",
      "  1  1 -1 -1 -1  1  1  1 -1  1 -1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
      "  1 -1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "# simple1 decision_tree_classifier \n",
    "%run ../ml-scratch/utils/decision_tree.py --file_path \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_simple1.csv\" --max_depth 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "[0 1 1 0 1 0 1 1 0 1 1 1] [0 1 0 0 1 0 1 1 0 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umini\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# simple2 LogisticRegression\n",
    "%run ../ml-scratch/utils/logistic_regression_clsifier.py --file_path  \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_simple2.csv\" --penalty \"l2\" --test_size=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "[0 1 0 0 1 1 0 0 0 0 0 0] [0 1 1 1 1 1 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# simple2 SVM\n",
    "%run ../ml-scratch/utils/support_vector_machine.py --file_path \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_simple2.csv\" --C 2.0 --test_size  0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[1 0 0 1 1 0 0 0] [1 0 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# simple2 decision_tree_classifier \n",
    "%run ../ml-scratch/utils/decision_tree.py --file_path \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_simple2.csv\" --max_depth 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰パイプラインの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session4のtrainfaile読み込み\n",
    "df = pd.read_csv(\"C:/Users/umini/git-test/diveintocode-ml/week4/train.csv\")\n",
    "# GrLivArea', 'YearBuilt','SalePriceを抜き出す\n",
    "df_grlivearea_yearbuilt = df[['GrLivArea', 'YearBuilt','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_fileに書き込む(1度だけ)\n",
    "\n",
    "#df_grlivearea_yearbuilt.to_csv(\"df_grlivearea_yearbuilt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.6611679936695176\n",
      "mse 1929337612.4286394\n"
     ]
    }
   ],
   "source": [
    "# House price LinearRegression\n",
    "%run ../ml-scratch/utils/linear_regression.py --file_path  \"C:/Users/umini/git-test/diveintocode-ml/ml-scratch/utils/df_grlivearea_yearbuilt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
