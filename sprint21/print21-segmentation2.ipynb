{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】コードレビュー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1\n",
    "#### clean-workflow-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(m, dim, acti, bn, res, do=0):\n",
    "    n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
    "    n = BatchNormalization()(n) if bn else n\n",
    "    n = Dropout(do)(n) if do else n\n",
    "    n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
    "    n = BatchNormalization()(n) if bn else n\n",
    "    return Concatenate()([m, n]) if res else n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv_blockは同じレベルでの畳み込みをまとめている\n",
    "\n",
    "mはinputまたは入力レイヤー, dimは出力するチャンネル数, actiは活性化関数, bnはバッチノーマライゼーションするかどうか,\n",
    "resはResidualNetならTrue,doはdropoutの割合\n",
    "\n",
    "3×3の畳み込み→バッチノーマライゼーション(bn=Trueの時)→dropout(doが入力されたとき)を2セット行い、\n",
    "\n",
    "res=Trueなら入力レイヤーであるmと結合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
    "    if depth > 0:\n",
    "        n = conv_block(m, dim, acti, bn, res)\n",
    "        m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
    "        # depthが0になるまでlevel_blockを呼び出す\n",
    "        m = level_block(m, int(inc * dim), depth - 1,\n",
    "                        inc, acti, do, bn, mp, up, res)\n",
    "        if up:\n",
    "            m = UpSampling2D()(m)\n",
    "            m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
    "        else:\n",
    "            m = Conv2DTranspose(dim, 3, strides=2,\n",
    "                                activation=acti, padding='same')(m)\n",
    "        n = Concatenate()([n, m])\n",
    "        m = conv_block(n, dim, acti, bn, res)\n",
    "    else:\n",
    "        m = conv_block(m, dim, acti, bn, res, do)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "level_blockは収縮パスと拡張パスを行いU-netの根幹をなしている\n",
    "\n",
    "エンコーダーは初めにconvblockで畳み込みを行いmaxpoolingで特徴を2倍にする.この処理を再帰的に行いdepthが0になるまで行う.\n",
    "\n",
    "デコーダーは\n",
    "up=Trueならupsamplingを行い,Falseならtransposed convolutionを行い、スキップ接続を結合して、畳み込みを行う."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet(params):\n",
    "\n",
    "    img_shape = params['input_dim']\n",
    "    out_ch = 1\n",
    "    start_ch = 8\n",
    "    depth = 3\n",
    "    inc_rate = 2.\n",
    "    activation = 'relu'\n",
    "    dropout = 0.5\n",
    "    batchnorm = False\n",
    "    maxpool = True\n",
    "    upconv = True\n",
    "    residual = False\n",
    "\n",
    "    i = Input(shape=img_shape)\n",
    "    o = level_block(i, start_ch, depth, inc_rate, activation,\n",
    "                    dropout, batchnorm, maxpool, upconv, residual)\n",
    "    o = Conv2D(out_ch, 1)(o)\n",
    "    # Sigmoid activation is used because model is trained with binary_crossentropy.\n",
    "    o =  Activation('sigmoid')(o)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet関数はmodelを生成している\n",
    "\n",
    "i はinput, oはlevel_blockを使いエンコーダーとデコーダーを実行\n",
    "oはoutputで最後にsigmoid(2値分類)を行う\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2 \n",
    "#### 03-models_pretrained_and_more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "# Base model - encoder\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNetをダウンロードして転移学習する\n",
    "\n",
    "encoderのbasemodelをresnetに指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoderに使用するレイヤーはResNetのMaxPooling前のレイヤーとする\n",
    "\n",
    "encoderは5層になっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decoder_block_function\n",
    "\n",
    "upsamplingの後の畳み込みを行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Center block and decorder block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "ecoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "centerからdecoderにかけて\n",
    "\n",
    "基本的にUpsampling後にconcatしてdecoder_functionを使用する\n",
    "\n",
    "centerだけUpsamplingする前にconcatしている.\n",
    "\n",
    "outputではlossがロバストヒンジロス以外はバイナリクロスエントロピーのためにsigmoidしている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】コードの書き換え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詳細は03-models_pretrained_and_more-vgg16.ipynbにて\n",
    "\n",
    "変更したのが\n",
    "\n",
    "import をVGGにし、\n",
    "\n",
    "base_modelをVGGにし、\n",
    "\n",
    "関数名をunet-vgg16に変更し、使用したレイヤーをVGG16のmaxpooling前の\n",
    "\n",
    "'block2_conv2', shape: (None, 112, 112, 128)\n",
    "\n",
    "'block3_conv3', shape: (None, 56, 56, 256)\n",
    "\n",
    "'block4_conv3', shape: (None, 28, 28, 512)\n",
    "\n",
    "'block5_conv3', shape: (None, 14, 14, 512)\n",
    "\n",
    "4層にした.decorderの名称も合うように変更した"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【問題3】学習・推定\n",
    "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochを20,batch_size16の設定で\n",
    "\n",
    "ResNetのIOUはBest IoU: 0.6910 at threshold: 0.860であり,\n",
    "\n",
    "VGG16のIOUはBest IoU: 0.6668 at threshold: 0.840であり\n",
    "\n",
    "ResNetの方が精度が高く、分類精度が高いほどセグメンテーション精度も高い可能性が示唆\n",
    "された"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
