{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "#from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/sample_submission.csv')\n",
    "depth = pd.read_csv('./input/depths.csv')\n",
    "\n",
    "train_src = './input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('./input/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('./input/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbe487adc88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3VuMXdWd5/HfPzbGxhhsgynsKoMd7oTEQ2KliYJGndAoJGk1eYhyUasHRYx4SU+nL1KHzDxE89aRWp1OS51kUEiHmURJZ+hojFDUTIYmGo2SQAyE+zWOr/hKbAPGxBjWPNQ5m18dzt/rVJ1TruNT34+EWLXZZ++11t61snLWv/4rSikCAAAAkHvHXFcAAAAAGHZMmgEAAIAKJs0AAABABZNmAAAAoIJJMwAAAFDBpBkAAACoYNIMAAAAVMzKpDkiboiIZyLi+Yi4dTbuAQAYHMZtADixGPTmJhGxQNKzkq6XtFPSLyV9tpTy5EBvBAAYCMZtAKhbOAvXfL+k50spWyQpIn4g6UZJ6eC7ePHismzZslmoCgDMrpdfflmvvfZazHU9+jStcTsi2EoWwKnsQCll1XQ/NBuT5nFJO+znnZJ+70QfWLZsmW688cZZqAoAzK5NmzbNdRUGYdrjNgCcwrbN5EOzMWnuSUTcIukWSVq6dOlcVQMA0AMfswFgPpqNPwTcJWmt/TzROjZFKeW2UsrGUsrGJUuWzEI1AAA9qo7bPmaf1JoBwJCYjUnzLyVdEhHrI2KRpM9IumsW7gMAGAzGbQCoGHh4RinleET8qaR7JC2Q9O1SyhODvg8AYDAYtwGgblZimkspP5b049m4NgBg8Bi3AeDE2BEQAAAAqGDSDAAAAFQwaQYAAAAqmDQDAAAAFUyaAQAAgAomzQAAAEAFk2YAAACggkkzAAAAUMGkGQAAAKhg0gwAAABUMGkGAAAAKpg0AwAAABVMmgEAAIAKJs0AAABABZNmAAAAoIJJMwAAAFDBpBkAAACoYNIMAAAAVDBpBgAAACqYNAMAAAAVTJoBAACACibNAAAAQAWTZgAAAKCCSTMAAABQwaQZAAAAqGDSDAAAAFQwaQYAAAAqmDQDAAAAFUyaAQAAgAomzQAAAEAFk2YAAACggkkzAAAAUMGkGQAAAKhg0gwAAABUMGkGAAAAKpg0AwAAABVMmgEAAIAKJs0AAABABZNmAAAAoIJJMwAAAFDBpBkAAACoYNIMAAAAVDBpBgAAACqYNAMAAAAVTJoBAACACibNAAAAQAWTZgAAAKCCSTMAAABQwaQZAAAAqGDSDAAAAFQwaQYAAAAqZjxpjoi1EXFfRDwZEU9ExBdax1dGxE8i4rnWv1cMrroAgJlgzAaA/vTzTfNxSX9VSrlS0jWSPh8RV0q6VdK9pZRLJN3b+hkAMLcYswGgDzOeNJdSdpdSHmqVX5b0lKRxSTdKuqN12h2SPtFvJQEA/WHMBoD+DCSmOSLWSbpa0v2Sxkopu1v/aY+ksUHcAwAwGIzZADB9fU+aI+JMSf8i6c9LKS/5fyulFEkl+dwtEbE5IjYfPXq032oAAHowiDH7JFQTAIZOX5PmiDhNk4Pv90opP2od3hsRq1v/fbWkfd0+W0q5rZSysZSyccmSJf1UAwDQg0GN2SentgAwXPrJnhGSbpf0VCnl7+w/3SXpplb5JkmbZl49AMAgMGYDQH8W9vHZD0r6E0mPRcSvWsf+s6S/kfTDiLhZ0jZJn+qvigCAAWDMBoA+zHjSXEr5f5Ii+c/XzfS6AIDBY8wGgP6wIyAAAABQwaQZAAAAqGDSDAAAAFQwaQYAAAAqmDQDAAAAFUyaAQAAgAomzQAAAEAFk2YAAACggkkzAAAAUMGkGQAAAKhg0gwAAABUMGkGAAAAKpg0AwAAABVMmgEAAIAKJs0AAABABZNmAAAAoIJJMwAAAFDBpBkAAACoYNIMAAAAVDBpBgAAACqYNAMAAAAVTJoBAACACibNAAAAQAWTZgAAAKCCSTMAAABQwaQZAAAAqGDSDAAAAFQwaQYAAAAqmDQDAAAAFUyaAQAAgAomzQAAAEAFk2YAAACggkkzAAAAUMGkGQAAAKhg0gwAAABUMGkGAAAAKpg0AwAAABVMmgEAAIAKJs0AAABABZNmAAAAoIJJMwAAAFDBpBkAAACoYNIMAAAAVDBpBgAAACqYNAMAAAAVTJoBAACACibNAAAAQAWTZgAAAKCCSTMAAABQwaQZAAAAqGDSDAAAAFQwaQYAAAAq+p40R8SCiHg4Iu5u/bw+Iu6PiOcj4p8jYlH/1QQADAJjNgDMzCC+af6CpKfs569I+mop5WJJByXdPIB7AAAGgzEbAGagr0lzRExI+rikb7V+DkkflnRn65Q7JH2in3sAAAaDMRsAZq7fb5r/XtJfS3qz9fM5kg6VUo63ft4pabzbByPilojYHBGbjx492mc1AAA9GMiYPfvVBIDhM+NJc0T8oaR9pZQHZ/L5UsptpZSNpZSNS5YsmWk1AAA9GOSYPeCqAcApYWEfn/2gpD+KiI9JWizpLElfk7Q8Iha2vrmYkLSr/2oCAPrEmA0AfZjxN82llC+VUiZKKeskfUbSv5VS/ljSfZI+2TrtJkmb+q4lAKAvjNkA0J/ZyNP8RUl/GRHPazJe7vZZuAcAYDAYswGgB/2EZzRKKT+V9NNWeYuk9w/iugCAwWPMBoDpY0dAAAAAoIJJMwAAAFDBpBkAAACoYNIMAAAAVDBpBgAAACqYNAMAAAAVTJoBAACACibNAAAAQAWTZgAAAKCCSTMAAABQwaQZAAAAqGDSDAAAAFQwaQYAAAAqmDQDAAAAFUyaAQAAgAomzQAAAEAFk2YAAACggkkzAAAAUMGkGQAAAKhg0gwAAABUMGkGAAAAKpg0AwAAABVMmgEAAIAKJs0AAABABZNmAAAAoIJJMwAAAFDBpBkAAACoYNIMAAAAVDBpBgAAACqYNAMAAAAVTJoBAACACibNAAAAQAWTZgAAAKCCSTMAAABQwaQZAAAAqGDSDAAAAFQwaQYAAAAqmDQDAAAAFUyaAQAAgAomzQAAAEAFk2YAAACggkkzAAAAUMGkGQAAAKhg0gwAAABUMGkGAAAAKpg0AwAAABVMmgEAAIAKJs0AAABABZNmAAAAoIJJMwAAAFDBpBkAAACo6GvSHBHLI+LOiHg6Ip6KiA9ExMqI+ElEPNf694pBVRYAMHOM2QAwc/1+0/w1Sf9aSrlc0gZJT0m6VdK9pZRLJN3b+hkAMPcYswFghmY8aY6IsyX9e0m3S1Ip5Vgp5ZCkGyXd0TrtDkmf6LeSAID+MGYDQH/6+aZ5vaT9kv4pIh6OiG9FxFJJY6WU3a1z9kga67eSAIC+MWYDQB/6mTQvlPReSd8opVwt6Yg6lvVKKUVS6fbhiLglIjZHxOajR4/2UQ0AQA8GNmbPek0BYAj1M2neKWlnKeX+1s93anJA3hsRqyWp9e993T5cSrmtlLKxlLJxyZIlfVQDANCDgY3ZJ6W2ADBkZjxpLqXskbQjIi5rHbpO0pOS7pJ0U+vYTZI29VVDAEDfGLMBoD8L+/z8f5L0vYhYJGmLpM9pciL+w4i4WdI2SZ/q8x4AgMFgzAaAGepr0lxK+ZWkbkt11/VzXQDA4DFmA8DMsSMgAAAAUMGkGQAAAKhg0gwAAABUMGkGAAAAKpg0AwAAABX9ppwDgKHx5ptvNuV3vOOt7wQioilPbnr39vNd9lkAwPzFN80AAABABZNmAAAAoILwDACntCwkI+PhFgsXdh8Cjx8/3vP9PdwDADC6+KYZAAAAqGDSDAAAAFQQngHglJBlwMhCMrLMGL3wa3rZ79suk10DAOYHvmkGAAAAKpg0AwAAABWEZwA4JfSSpcJDJRYsWDCtz2bhHP7ZN954Y0b1AgCc+vimGQAAAKhg0gwAAABUEJ4B4JSWhVV41oss80a2MUq3MAxpashH+5pkzwCA+YFvmgEAAIAKJs0AAABABeEZAE4JWYhFL7JwC7/O66+/3pSzDU1ee+21t10zuzYAYLTwTTMAAABQwaQZAAAAqCA8A8BQybJhOA+ZyDY08bAJD73w4x6G4ff1sodkvPrqq2+7pl8bADC6+KYZAAAAqGDSDAAAAFQQngFgzk03JMNDLLLNRTys4tChQ12Pe3iGh1l4GIaHfJx33nlNefXq1ZKkxx57rFp3AMCpj2+aAQAAgAomzQAAAEAF4RmngH42dZjLew+q3tnSvS+t93Mvv34v1+wllMCvk/HrZxkdBlVPDzE4fvx4188uXDh1OMjamd3P6+T38Ov68SwDRnbO7373u6718bCKw4cPN+WjR492veaqVaua8pVXXtmU16xZ05QnJiaa8oUXXtiUzz777KZ82mmnSZIeeuihrvUCAIwWvmkGAAAAKpg0AwAAABWEZ5wCTnZIxqDu3c9nsw0rsnN8+d31EiaRbXCRfbYzjKHbZ3u5jodkZCEMzvvB+zYLt1i0aFH1Xn5+ZzhGL2ExWZtdFm6RZcPw7BYvvfRSU168eHFT9lCKCy64oCl7WEU7fEKSli9f3pTXr1/flF955ZWmfOTIkabsYR6PPvpoU969e/fb6rZ//34BAEYf3zQDAAAAFUyaAQAAgArCM3BSZBtQuGy5PgsHcFkIRC9ZNbJQkOx8Dzfw+2YZLbwtzsMkPANEFj6RhW14GILXOdvEw8snygrSSxYPl10rO+5l33zEbdiwoSlfe+21TXnFihVN2cMqPFTCQyz8+MMPP9yU9+3b17UOp59+eteyh7wsWbJEUm8hQACAUx+jPQAAAFDBpBkAAACoIDwDJ0Uvm3e4LNShl/CJ6W5K0kt9so1CsiwWvVzfQzL8mlk4Rya7r4d5eP39+id6Lt42r2sWnuKhC36+bzKSbThy+eWXN+WPf/zjXY8//fTTTfmee+5pytu3b2/Kx44da8pLly5tyuecc4668dCW8fHxrvX3DBsewtG+V7bpCgBgtPBNMwAAAFDBpBkAAACoIDwDQ2O64RPZBiKD2gwmu362Wcd0s030khkju04vG6lkYSoekuDndIYZZBkwvK5+zosvvtj1usuWLWvKV199dVO+/vrrm/IVV1zRlJ944omm/N3vfrcpe6YLz5jhoRR+rzPPPLMpe9t8wxTPMOLt8nAZL3u72v3YS2YYAMCpj2+aAQAAgAomzQAAAEAFk2YAAACggphmnBTTTTOXxexm53s8qseY9hJvmsXoZvfy+F6/flbn6V4/q5vH5XaLre2sW5YKzeOBPeVce4e7tjPOOKMpe3zw+eef35QnJiaa8gUXXNCUzzrrrKa8du3apjw2NtaUn3322absscu7d+9uyt5+r7enfvM2ZLssetn7y3f789hlT423d+/epnzw4MGm3I6H9noBAEYX3zQDAAAAFUyaAQAAgArCM+aBLCSgF1koQj/XyVKZZef78rsvoWc73vVSZz/fl+6z9G0vv/xyU/ZQBa+Dpy/zsl/Td6zzEACvg9d58eLFTXnlypVNecWKFU3Z06x5iIX3lfNwiYsuuqgpe6iFJJ133nld7+394m3wlHO//vWvm/LPfvazprxjx46mvGfPnq718/7yNHP+DPwZe194Px44cKAp+/PwlHNefz/uz9WfgYedtHcZ3LVrV9d2AABGC980AwAAABVMmgEAAICKvsIzIuIvJP1HSUXSY5I+J2m1pB9IOkfSg5L+pJRyLL0IqvoJr5B62yHPQyCyzw4qPMMzIvhyutchy3zgPAuCf7aXzBseJuFlr6cv0Z977rlN2cMePIRhfHy8KXuYhF/Tjy9fvrwpt5f6O++1atWqprx06dKmnO3ql/Whh1R4GMXOnTub8iOPPCLnWSw8W8Urr7zStfzqq682ZQ8Z8fp533l2Dw+l8DAMD6vwe3k/+vleT2+/n+/9e9VVV3U97vX3kAwP1Wj36XPPPadTBWM2AMzcjL9pjohxSX8maWMp5SpJCyR9RtJXJH21lHKxpIOSbh5ERQEAM8eYDQD96Tc8Y6GkJRGxUNIZknZL+rCkO1v//Q5Jn+jzHgCAwWDMBoAZmnF4RillV0T8raTtko5K+t+aXNo7VEppr7/vlDSeXGKK9hKuL9378niWfSE7p6OuXT/rS8VZeEIv5/Qiq1sW8uD9cKLr+Of9M15vP8dDEfy4L4N7O7MwhizjRFa3bDOObAMOXxJftGhR1896SIOXPdODL7P7Zh29ZJ/wjS88TMLfOQ8Z6GXjEu9nb7tncfBsDJs3b27KvomGh0Ls37+/6/X9GXlmCOfP2tsrTe0vb0N23LOKeNuyzBXeBg+x8FANf+d8U5X3ve99TfnCCy/s2h7/ffD3yd9F73f/rId5ZP3bLvs7MMwGPWYDwHzTT3jGCkk3SlovaY2kpZJumMbnb4mIzRGx2f+HCAAweIMcs2epigAw1PoJz/gDSb8ppewvpbwu6UeSPihpeWvpT5ImJHVNYlpKua2UsrGUstH/uAYAMCsGNmafnOoCwHDpJ3vGdknXRMQZmlzqu07SZkn3SfqkJv8a+yZJm3q5WDvswJffe9kQIwtjyDbE6HbPXst+TV+W9jr40q9/1s/Prum8vSf6Jv7w4cNdj3s9fFk/O8dDDrJwCM8uMDY21pR9Wd6XwT2kwTNFeDiEh1X4dTxUwOvgZX+u3kfeXl8695ABD13w8z1jhB//7W9/25Q9+4Q/S7/+wYMHm3IWgpNlkvDj3g/ZM8pCdPzd6mVzks53MesLr6uHT/jn/Tl5XT08w/vUrVu3rim/+93vbsqXXnpp13p7Pf25ej96iEUW5pJtMJNle2k/j36z25xEAx2zAWC+mfE3zaWU+zX5xyMPaTJ10Tsk3Sbpi5L+MiKe12QKo9sHUE8AQB8YswGgP33laS6lfFnSlzsOb5H0/n6uCwAYPMZsAJi5vibNg/Lmm282y7y+dOxLv7407cuuvnTqn82WTLMQCz8/u2YWAuDnZNkgvC1ZSIkfz5a3OzMcZJsweGiEl30zDs9GsHr16qbsYRieTcLb5nX1EAVf7s42xPDrbN26tSl7n/pnPbOCl32pP8sEkvHnkWXM8Lb4++cx+N4ufy+9D31J3z/rm5X4++f94PX0+nj4hx/PNmrxPvfrZxuvSFPfu2yDGe8Xr0cW2uJhFe95z3ua8kc+8pGm7O+l96+/K3v27GnK/h54//YSNpFtouO/f9nvq58DABh9bKMNAAAAVDBpBgAAACqGIjyjlDJl2bbNl5pdtpTd7S/bpanL9Vlohy9T+2c9nMNDADwbhC/TeriEb6DhWSI8RMKPe3iFL917eIVnmOi8X5bJwNvmWQR82fyJJ55oyr7072ESnqnD+92fR5Z1IMuAkZX9GThvi/eRl/098NAZr1uWtSQLV/A+8T70Ont4gm/Qkb1DWciOn++/F94nfr6X/f3IsnZ4X/nvQ2c2C7+3l7MNb7yv/R4bNmxoyhs3vpWtzLNk+Lv185//vCnv2LGjKXvoRfaeZVlInD9jv6ZnGPHj3q5um+784he/6HofAMBo4ZtmAAAAoIJJMwAAAFAxFOEZx44d0wsvvCBp6lKoZzLw475MffbZZzdlXyr3ZWpfdj3jjDOasodYeCiFH/csCH6OL917lgFf1vXlel9C9tAGX+r3sAJfrt6+fXtT9kwB0tRsEr407Uvtfo4vm3ufOm+/t8dDQbycLYP7Erov7/vyuLc5CznwcAVvi2dW8LI/Y38GHqaT7UKZhXb4Nf1eWZ2z/slCA/ydzjJ4ZNlFPEQiC7/xPsw26+gM5/A2eCiFhxT5u3LRRRc15SwDi9fvgQceaMr79u1ryt7vWciE19XL2XP1c/z6/my8H/2495G/f+33KQsjAwCMFr5pBgAAACqYNAMAAAAV4cvFc+Wyyy4rX//61yVNDXXwUIJscwkvZ5sQZGECXvYl9xdffLEp+/J4lh3BQyay0AP/bLbBin/W+8GXtzvb6Ev5nZk1ut3Dy14nD+3w5WY/7u3Jzs8yeHjZl769nX6OX8efcS+brXgohV8/e9ezLBOeFcTv5e9iVgcPBfEwCT8/25TEz/c+92edhQR5OINvWJOFHE1MTDRlD7vovJ/LMqf479PevXubsm9Ekm3+46FVWeYKv5e/637NLAuO96PX0++bhRn5cT+/3Q+bNm3S/v37u79EIyoi5v5/OABg5h4spWysnzYV3zQDAAAAFUyaAQAAgIqhyZ6xa9cuSXn4hJd96duXXb3sy91ZRgRfZval3Gzp15fEfYk7W8b2pXKvc/aX/P6X+b5EnbW382fPQJBl7vB+8TZ7KIy32evhYQ/eZi9nG8N4HXyZPQtPyfor27TFQ2q2bNmibvw63tfdNtY5UX28Tzx7SxbO4SEl3leejcWPv+td72rKvrGNv3N+PMsg4+VeMkPs3LlTzkOW/HfF+8L7zvs3y8rh75nLsqX4Z72PsvfJ378sU4n/Hns9vb/8+n5N78f2fYchxA0AMPv4phkAAACoYNIMAAAAVAxFeMaRI0eajQ58qdWXkX1Z15ds/XzfjMGXVLNNPHxZ1cse2uBLtn5OO5xEmrqU63XOsmo4X8bPwhx8Cblz8wa/rrczCxvw873evszux30TDc+I4Mv1XvbrZNk2snARr1sWkuHPw5/32NhYU/bQBX8eft/zzz+/KWcb1XgdPJQi2xzEM1R4aI4/C7++183r4M/e+9/DJfzd8rAKD53oJUTH6+/hN531c/4++Wf8Wv4ss7CVbGMYD4/yOvh1ss+67Dk5/53xrCX+e+Zjjz8DfxcBAKOPb5oBAACACibNAAAAQMVQhGdIby29+nKsL8v70mm3z0lTs0dk53j4gB/3pdZss4tsI4Tsr+t9uT4L//Bleb/m4cOHu17Tl+ulqaERfl3/fBZ64f2bZSZwvmyeba6xZs2appxleMg+633hz8D77qyzzupaH2+jX99loTZZSFAWapL1jz+ngwcPNuXdu3d3vWYWSuH3ytriYQV+jh/3Z+qhLFn2Ej/e2Z4sS4aHK/i1PNOHy7Kf+DX9PfDzPeOJf9afq9ehl4wZfv3x8fGm7H3hv2PdwnSy8C8AwGhhtAcAAAAqmDQDAAAAFUMRnvHGG2802QB8qdWXTnsJpfBytqztS7a+xJtlevAldF9y9+O+bOyf9SXtrC1+fpYlwpd/felamhoa4pkMLr300qbsYRIe3uDne4YA7yO/vsuegfepL+97O709WSYHD4Hwa3oIzvbt27tex0N5/L7e3uwZZO3ysA2vjx/3dyLLjOH8uD8Xf3ezfvB3xevvsuwo2UYnfk1paoYOr5+XXZa9xn9vvN89ZMfr5L9PWdiQ94X3V7bhjT9Lr6e32Z+f198/632SPVcAwGjim2YAAACggkkzAAAAUDEU4RnHjh3Ttm3bpnV+my+vetmX+v2v37MND7K/5Pfla1+697KHM/iS89q1a5uyb3bh4RK+/JyFYXjoxIn+Uj/ri2wJ2pfsPcNDtqGE96P3l4cH9BJi0RkG0Ob96Pf1OmdZI7wfPatGFu6ThaZ4Pf2cLGNGtrmM39frmYVS+DvdS9YKL3vd/LjXx++bhZp0bsBz3nnnNeVeNmjxZ+BZXjycw8/PMoZkITL+PLL2OA/D8Lo5/6y/f1lmGX9X/L0EAIw+vmkGAAAAKpg0AwAAABVDEZ5RSnnbxgrS1OVbX4L25dIsfMI3IfDlel+C9eO+/Oybkvi9/Pp+PAvtyLIXZBus+BK1Z4nIsnl03iPLCOHHva5ZyIH3qZez7CRe72y5u5eNRTxjgZc9zCALLcgyj/gzzpbTs6V7b5eHGHi7fHMPv1e2oY6H3Xh9sncla7v3T5Y9wtvloQ3Z+Z2ZUrL3wMNH/PN79+5tyv6769fNsnV4O72cvd/Z8/DsFr2EXni/+H392WS/0+06sLkJAMwPjPYAAABABZNmAAAAoGIowjNWrlypT3/605KmLon7sqcv8WbhEF728ARfTvbr+Dm+zJ5tYuLL5l5P5+dk2SP8uNfHwwqyz3YuoWcbbfhytPeLyzZw6GUjj6zefh0/x5fWs+X3rA5+vvd7ln3Bn3e2yU0WIuL8uG+U4fz6vqmKt8tDhbJNejxkwJ+dhyF45gbvWz+ehRP59b1v/V337CjS1FASz4aRhbn4PTxbjN/P+yXLuuLvgbfHQ6i8Pvv372/K2eZF/vw8JMPbcuDAga518Ov4xivt/iWLBgDMD3zTDAAAAFQwaQYAAAAqhiI848iRI3rggQckTV2+zjbByDbf8GX57HiWDSLbpCLLXuDH/bO+XO/L21koRJbZIgtH6dzIIQulyMInsnq7zhCQbrINZnyZPcuO4MvZfr73XRaSkWVLyZ63L6f7Nb1uHibg5/hSf7aZhi/1+2Y23odZuIiHKoyPjzdlD0nI+iQLFfKQFQ+98Dp4hgnvN2+LlD+nw4cPN+WtW7c2ZQ+TyMJxvE+9bVkmG+8jz87hvL88xCTbCMfb5aEt/ly9j9zq1au7ng8AGH180wwAAABUMGkGAAAAKoYiPEN6aynVl5GzbAq9LP36sm7nsnNbtpmGyzJ1ZOETHpKRbb6R3auXzUM6Mz34Z/w8X7735ehs041esnt42c/JlsGzDUr8nGwDDQ+98ONeZw8T8FAEr9s555zTlC+44IKmnG124ce9zt7P2TPONsHIsoV4xhYPbfD2elhIL33uoQr+Pni7PLOFhyf4pj6ddRobG2vKHoZy7bXXNmUPXfD3zN8/L3u/e1/s2bOnKXu4xTvf+c6u7fH2e9v8+n6O19Mznvg44e9NtrFLuw7PPPOMAACjj2+aAQAAgAomzQAAAEDFUIRnlFKaZegs9MJlx7Olcl/KdVlmgmyzC7+mL/36srn/1b0v5faSGSPL/uFL1J1/sZ8t0/tScxYO4VkKakvQnfXONpXxsAoPLchCUny53vsxy3Li9fE+8uV0X373/vXMEh7m4fX0vvZn7HXI3pUs44dn8MiyVWSbj2SyTC5ZZgg//sILLzRlD8l47LHHptzD+8vfCd9wZc2aNU35ySef7HqOZ8bw9mcbsXiIxcTERNfr+PPwMBLv66x/PZzCz/ey841R/Drt33UPJwEAjC6+aQYAAAAqmDQ3ZuJEAAAKrUlEQVQDAAAAFUMRniG9tdzqmQmyJehs2Txbuvdlf+fX8WV5/0t+r4OHOWThFlmogutlYxQvZ3/JL01dgs/u58vsWQhLtgGMH/clfr+O95f3tT8PD1fI+Gf9vsuWLWvKnsXh8ssvb8oeZuD38uwIvjlG9m75Un+2UU0WppNlAvG6eVhIlvXCw0X8+h5O4+9clpnl2Wefbcrbt2/vWp+dO3d2rU/nef5ueRseeeSRpuzP79ChQ03Zfxf9OlnWmSx8KdsYJgvxyUKL/N3Kxga/poeFeJ909hcAYLTxTTMAAABQwaQZAAAAqBiK8IyFCxc2fzHvS6q+xJ1lmfCleF+m9pAEX0bNltN9edyX3z0LgJe9Pr7knG024su9LgsTcFkGCCnP1uFL4t7mbKMN7yOvq4cKOH9OvrSeba6RbXri5WxTD7+OZyrwDU0884H3g4evuGxTHM+84X3t52eb5Xifex38fA+x6CU0J+vPLNzFM0N4X61fv74pZyESnaE/2WZBfm8PHfLfDz8/yzDSS6Yc7ws/3+udvYtZuJb/zvj75/X3cK1sk572O+pZQwAAo4tvmgEAAIAKJs0AAABAxVCEZ0REswTqy6hZ6EW2tO7Lzv4X79kGIB6G4MdXrVrVlH1jg61bt3a9ZhZikYVI+PFsSd/b3ktoQCdfas6Wvn3pP8tWkWXS8OVrl2Xk8DCJLCTD65llUMh4nb2v/T3wa3r9PZTAsyP4NbP2On9v/N3KMmZkG+R4aEqWScP7xDN++HU+9KEPNWXfMMQzivh70snDGPz3zJ+xZ8k4fPhwU/Zn723w31F/l73eXj9vs1/Tj3tIhveL/255qI0/G3/Gfjz7ffD3uH1OZ8gUAGA08U0zAAAAUMGkGQAAAKgYivCMUkrXbAC+1OpL97487Euq2RK6L7X6NX2JN9u8wT/rfLna6+bt8Hr2knEh27TFz/HsC9LU9vgyuIc9eJ38fA/P8PZ4+/18b0OWMcRDILKl7ywLics2anHexmwzG+8Tv1eWVSPbtMafjWfq8HALz+bhdVixYkXX62SboXjbvf5+zRdeeKEpe3jGhg0bmvL4+HhT9v5fu3ZtU/b2+uYvnXXNMq1cccUVTdnfj2xjEb+f/756SIaHRPnvVhbakWX5yEI7/F3xfvdrZpsmeR3a19+yZYsAAKOv+k1zRHw7IvZFxON2bGVE/CQinmv9e0XreETEP0TE8xHxaES8dzYrDwB4O8ZtABi8XsIzviPpho5jt0q6t5RyiaR7Wz9L0kclXdL65xZJ3xhMNQEA0/AdMW4DwEBVwzNKKf83ItZ1HL5R0u+3yndI+qmkL7aO//cyuQb7i4hYHhGrSym7e62QLyP78qqHEvgSr4cSZFkTfDnZQxW6/SW8NHW526/jGQj8fF9+zpaBs6wazq+ThX90fjbboOWVV17peo6HTPg9ss0i/Hl4OcvusW3btqa8ffv2pnzxxRd3vVcWPtG50UZblpXBn3GWSaOXLBbeLn/evolHFj7hz89DODzrii/7e9aHbPOXXbt2NWUPA/BMFWNjY035nnvu6Vq37F3PMnV0/ux95++ghzRk75Yfz7KZ+DmewcT7/dxzz23K/q4cOHCgKXvIh79DWbiFZ77w8BR/Nv4s/Zx2KIg/i2FxssdtAJgPZvqHgGM2oO6R1P5f7XFJO+y8na1jbxMRt0TE5ojY7P+DDACYFX2N2z5mz241AWA49Z09o/XtRD2R7ts/d1spZWMpZaN/qwMAmF0zGbd9zJ6lagHAUJtp9oy97eW7iFgtaV/r+C5Ja+28idaxE9q/f/+Bb37zm9sknSvpQO38ETJv2vvQQw9J86i9LSelvR4+cLJ5eEOrPB+fcfdULMNnkOP2AUmM2aNvvrVXmn9tnq/tvXAmH57ppPkuSTdJ+pvWvzfZ8T+NiB9I+j1Jh3uJiyulrJKkiNg8n77FoL2jbb61V5p/bW61d91c16NHAxu3GbPnh/nWXmn+tZn2Tk910hwR39fkH4+cGxE7JX1Zk4PuDyPiZk1+2/Cp1uk/lvQxSc9LelXS52ZaMQDAzDBuA8Dg9ZI947PJf7quy7lF0uf7rRQAYOYYtwFg8IZtG+3b5roCJxntHW3zrb3S/GvzfGtvp/nWfto7+uZbm2nvNES2jTEAAACAScP2TTMAAAAwdIZi0hwRN0TEMxHxfETcWv/EqSUi1kbEfRHxZEQ8ERFfaB1fGRE/iYjnWv9eMdd1HaSIWBARD0fE3a2f10fE/a3n/M8Rsah2jVNJaye1OyPi6Yh4KiI+MMrPOCL+ovU+Px4R34+IxaP2jCPi2xGxLyIet2Ndn2lM+odW2x+NiPfOXc1n16iP2RLj9nwYtxmzGbOnO2bP+aQ5IhZI+kdJH5V0paTPRsSVc1urgTsu6a9KKVdKukbS51ttvFXSvaWUSyTd2/p5lHxB0lP281ckfbWUcrGkg5JunpNazZ6vSfrXUsrlkjZosu0j+YwjYlzSn0naWEq5StICSZ/R6D3j70i6oeNY9kw/KumS1j+3SPrGSarjSTVPxmyJcbtt1H6nHWP26D3f72g2x+xSypz+I+kDku6xn78k6UtzXa9ZbvMmSddLekbS6tax1ZKemeu6DbCNE62X88OS7pYUmkwovrDbcz/V/5F0tqTfqPV3AnZ8JJ+x3tp6eaUms/DcLekjo/iMJa2T9HjtmUr6b5I+2+28UfpnPo7ZrXYybo/I73SrLYzZjNnTHrPn/JtmvfUg23a2jo2kiFgn6WpJ90saK29tIrBH0tgcVWs2/L2kv5b0ZuvncyQdKqUcb/08as95vaT9kv6ptbT5rYhYqhF9xqWUXZL+VtJ2SbslHZb0oEb7Gbdlz3S+jGXzpZ0Nxu2R/J1mzGbMnvZYNgyT5nkjIs6U9C+S/ryU8pL/tzL5f3NGIpVJRPyhpH2llAfnui4n0UJJ75X0jVLK1ZKOqGNZb8Se8QpJN2ryf3jWaHIr6c4lsZE3Ss8U3TFujyzGbMbsaRuGSfMuSWvt54nWsZESEadpcuD9XinlR63DeyNideu/r5a0b67qN2AflPRHEbFV0g80udT3NUnLI6K9oc6oPeedknaWUu5v/XynJgfkUX3GfyDpN6WU/aWU1yX9SJPPfZSfcVv2TOfFWKb5007G7dEetxmzGbOnPZYNw6T5l5Iuaf0F5yJNBqbfNcd1GqiICEm3S3qqlPJ39p/uknRTq3yTJmPmTnmllC+VUiZKKes0+Tz/rZTyx5Luk/TJ1mkj015JKqXskbQjIi5rHbpO0pMa0WesySW+ayLijNb73W7vyD5jkz3TuyT9h9ZfZF8j6bAtCY6SkR+zJcZtjfi4zZjNmK2ZjNlzHbDdCr7+mKRnJf1a0n+Z6/rMQvuu1eRywKOSftX652OajBe7V9Jzkv6PpJVzXddZaPvvS7q7VX6npAckPS/pf0o6fa7rN+C2/jtJm1vP+X9JWjHKz1jSf5X0tKTHJf0PSaeP2jOW9H1Nxv+9rslvpm7Onqkm/2jqH1vj2GOa/Cv1OW/DLPXLSI/ZrTYybpfRHrcZsxmzpztmsyMgAAAAUDEM4RkAAADAUGPSDAAAAFQwaQYAAAAqmDQDAAAAFUyaAQAAgAomzQAAAEAFk2YAAACggkkzAAAAUPH/AV9HVGg9JH79AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(2, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "# np.repeat(3, 4) array([3, 3, 3, 3])\n",
    "# np.expand_dims(x, axis=0) np.newaxisみたいな使い方　axis=-1 はshapeの最後に1を追加\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "# np.asarryは引数がndarrayの時にidを元の配列と同じにする\n",
    "\n",
    "# map(関数, 配列)配列全てに関数を適用\n",
    "# lambda 引数:返り値\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default vgg16 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - VGG16:\n",
    "\n",
    "In VGG16, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 4 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'block2_conv2', shape: (None, 112, 112, 128)\n",
    "- 'block3_conv3', shape: (None, 56, 56, 256)\n",
    "- 'block4_conv3', shape: (None, 28, 28, 512)\n",
    "- 'block5_conv3', shape: (None, 14, 14, 512\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "base_model = VGG16(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg16(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    #'block2_conv2', shape: (None, 112, 112, 128)\n",
    "    #'block3_conv3', shape: (None, 56, 56, 256)\n",
    "    #'block4_conv3', shape: (None, 28, 28, 512)\n",
    "    #'block5_conv3', shape: (None, 14, 14, 512\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block2_conv2').output\n",
    "    encoder2 = base_model.get_layer('block3_conv3').output\n",
    "    encoder3 = base_model.get_layer('block4_conv3').output\n",
    "    encoder4 = base_model.get_layer('block5_conv3').output\n",
    "    #encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder4, 'center', num_filters=512)\n",
    "    concat4 = concatenate([center, encoder4], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=512)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=256)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=128)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    #decoder1 = decoder_block(\n",
    "        #concat2, 'decoder1', num_filters=64)\n",
    "    #concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 14, 14, 512)  2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 14, 14, 512)  100352      center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           center_activation[0][0]          \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 512)  2048        decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 512)  100352      decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 512)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 1024) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 256)  2359552     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 256)  1024        decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 256)  200704      decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 256)  0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 512)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 128)  589952      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 128)  512         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 128)  401408      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 128 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 256 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 256 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 73760       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,231,105\n",
      "Trainable params: 27,228,225\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg16(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 14, 14, 512)  100352      center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 512)  0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 14, 14, 256)  1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 14, 14, 256)  1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 14, 14, 256)  50176       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 14, 14, 256)  0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 14, 14, 512)  1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 14, 14, 512)  100352      center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 14, 14, 512)  0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 512)  0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           add_1[0][0]                      \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 512)  100352      decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 14, 14, 512)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 256)  1179904     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 256)  50176       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 14, 14, 256)  0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 512)  1180160     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 512)  100352      decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 14, 14, 512)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 512)  0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 512)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 28, 28, 1024) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 256)  2359552     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 256)  200704      decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28, 28, 256)  0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 128)  295040      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 128)  512         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 128)  100352      decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 28, 28, 128)  0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 256)  295168      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 256)  200704      decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 28, 28, 256)  0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 256)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 512)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 128)  589952      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 128)  512         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 128)  401408      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 56, 56, 128)  0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 64)   73792       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 128)  73856       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 128)  512         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 128)  401408      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 56, 56, 128)  0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 56, 56, 128)  0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 128 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 112, 112, 256 0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 256 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 73760       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 224, 224, 32) 0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 36,319,665\n",
      "Trainable params: 36,312,465\n",
      "Non-trainable params: 7,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/20\n",
      "3196/3196 [==============================] - 294s 92ms/step - loss: 0.8726 - my_iou_metric: 0.1654 - val_loss: 1.9943 - val_my_iou_metric: 0.1678\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.16779, saving model to unet_vgg16.h5\n",
      "Epoch 2/20\n",
      "3196/3196 [==============================] - 269s 84ms/step - loss: 0.7535 - my_iou_metric: 0.2870 - val_loss: 1.0018 - val_my_iou_metric: 0.2845\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.16779 to 0.28445, saving model to unet_vgg16.h5\n",
      "Epoch 3/20\n",
      "3196/3196 [==============================] - 269s 84ms/step - loss: 0.6780 - my_iou_metric: 0.3804 - val_loss: 0.7177 - val_my_iou_metric: 0.4808\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.28445 to 0.48085, saving model to unet_vgg16.h5\n",
      "Epoch 4/20\n",
      "3196/3196 [==============================] - 269s 84ms/step - loss: 0.6682 - my_iou_metric: 0.3834 - val_loss: 0.8011 - val_my_iou_metric: 0.3425\n",
      "\n",
      "Epoch 00004: val_my_iou_metric did not improve from 0.48085\n",
      "Epoch 5/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.6076 - my_iou_metric: 0.4458 - val_loss: 0.5982 - val_my_iou_metric: 0.4947\n",
      "\n",
      "Epoch 00005: val_my_iou_metric improved from 0.48085 to 0.49465, saving model to unet_vgg16.h5\n",
      "Epoch 6/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.5752 - my_iou_metric: 0.4667 - val_loss: 0.6597 - val_my_iou_metric: 0.5828\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.49465 to 0.58284, saving model to unet_vgg16.h5\n",
      "Epoch 7/20\n",
      "3196/3196 [==============================] - 269s 84ms/step - loss: 0.5516 - my_iou_metric: 0.4809 - val_loss: 0.6136 - val_my_iou_metric: 0.5211\n",
      "\n",
      "Epoch 00007: val_my_iou_metric did not improve from 0.58284\n",
      "Epoch 8/20\n",
      "3196/3196 [==============================] - 269s 84ms/step - loss: 0.5265 - my_iou_metric: 0.4968 - val_loss: 0.4671 - val_my_iou_metric: 0.5755\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.58284\n",
      "Epoch 9/20\n",
      "3196/3196 [==============================] - 269s 84ms/step - loss: 0.5128 - my_iou_metric: 0.4912 - val_loss: 0.6943 - val_my_iou_metric: 0.5399\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.58284\n",
      "Epoch 10/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.4783 - my_iou_metric: 0.5214 - val_loss: 0.5119 - val_my_iou_metric: 0.5838\n",
      "\n",
      "Epoch 00010: val_my_iou_metric improved from 0.58284 to 0.58383, saving model to unet_vgg16.h5\n",
      "Epoch 11/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.4740 - my_iou_metric: 0.5156 - val_loss: 0.4717 - val_my_iou_metric: 0.5510\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.58383\n",
      "Epoch 12/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.4367 - my_iou_metric: 0.5389 - val_loss: 0.4262 - val_my_iou_metric: 0.5317\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.58383\n",
      "Epoch 13/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.4213 - my_iou_metric: 0.5485 - val_loss: 0.4149 - val_my_iou_metric: 0.5672\n",
      "\n",
      "Epoch 00013: val_my_iou_metric did not improve from 0.58383\n",
      "Epoch 14/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.4244 - my_iou_metric: 0.5346 - val_loss: 0.6956 - val_my_iou_metric: 0.5376\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.58383\n",
      "Epoch 15/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.4058 - my_iou_metric: 0.5677 - val_loss: 0.5138 - val_my_iou_metric: 0.5534\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.58383\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 16/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.3638 - my_iou_metric: 0.5794 - val_loss: 0.3827 - val_my_iou_metric: 0.6162\n",
      "\n",
      "Epoch 00016: val_my_iou_metric improved from 0.58383 to 0.61617, saving model to unet_vgg16.h5\n",
      "Epoch 17/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.3431 - my_iou_metric: 0.5843 - val_loss: 0.3530 - val_my_iou_metric: 0.6209\n",
      "\n",
      "Epoch 00017: val_my_iou_metric improved from 0.61617 to 0.62090, saving model to unet_vgg16.h5\n",
      "Epoch 18/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.3325 - my_iou_metric: 0.5972 - val_loss: 0.3695 - val_my_iou_metric: 0.6659\n",
      "\n",
      "Epoch 00018: val_my_iou_metric improved from 0.62090 to 0.66592, saving model to unet_vgg16.h5\n",
      "Epoch 19/20\n",
      "3196/3196 [==============================] - 269s 84ms/step - loss: 0.3175 - my_iou_metric: 0.6166 - val_loss: 0.3796 - val_my_iou_metric: 0.5861\n",
      "\n",
      "Epoch 00019: val_my_iou_metric did not improve from 0.66592\n",
      "Epoch 20/20\n",
      "3196/3196 [==============================] - 268s 84ms/step - loss: 0.3173 - my_iou_metric: 0.6076 - val_loss: 0.3660 - val_my_iou_metric: 0.5833\n",
      "\n",
      "Epoch 00020: val_my_iou_metric did not improve from 0.66592\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg16(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 20  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref> cannot be interpreted as a Tensor. (Tensor Tensor(\"block1_conv1/kernel:0\", shape=(3, 3, 3, 64), dtype=float32_ref) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 300\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3490\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3568\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3569\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3570\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"block1_conv1/kernel:0\", shape=(3, 3, 3, 64), dtype=float32_ref) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-73a3c4fc4336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mjson_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apple_orange_model.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apple_orange_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \"\"\"\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 307\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    308\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref> cannot be interpreted as a Tensor. (Tensor Tensor(\"block1_conv1/kernel:0\", shape=(3, 3, 3, 64), dtype=float32_ref) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "# 学習結果の保存(Keras)\n",
    "### save model and weights\n",
    "json_string = model.to_json()\n",
    "open('apple_orange_model.json', 'w').write(json_string)\n",
    "model.save_weights('apple_orange_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:47<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.6668 at threshold: 0.840\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.600348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.049166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.501493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.564117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.610572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.641294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.666791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.600348\n",
       "std     0.204939   0.049166\n",
       "min     0.200000   0.501493\n",
       "25%     0.370000   0.564117\n",
       "50%     0.540000   0.610572\n",
       "75%     0.710000   0.641294\n",
       "max     0.880000   0.666791"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd93296f98>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
