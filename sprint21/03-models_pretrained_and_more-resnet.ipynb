{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/sample_submission.csv')\n",
    "depth = pd.read_csv('./input/depths.csv')\n",
    "\n",
    "train_src = './input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('./input/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('./input/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc02ff02f98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "# np.repeat(3, 4) array([3, 3, 3, 3])\n",
    "# np.expand_dims(x, axis=0) np.newaxisみたいな使い方　axis=-1 はshapeの最後に1を追加\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "# np.asarryは引数がndarrayの時にidを元の配列と同じにする\n",
    "\n",
    "# map(関数, 配列)配列全てに関数を適用\n",
    "# lambda 引数:返り値\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      " 5709824/94653016 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94658560/94653016 [==============================] - 1s 0us/step\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,978,353\n",
      "Trainable params: 48,919,953\n",
      "Non-trainable params: 58,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/20\n",
      "3196/3196 [==============================] - 261s 82ms/step - loss: 0.7725 - my_iou_metric: 0.2414 - val_loss: 0.8004 - val_my_iou_metric: 0.4393\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.43930, saving model to unet_resnet.h5\n",
      "Epoch 2/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.5771 - my_iou_metric: 0.3994 - val_loss: 0.8252 - val_my_iou_metric: 0.5136\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.43930 to 0.51356, saving model to unet_resnet.h5\n",
      "Epoch 3/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.5384 - my_iou_metric: 0.4673 - val_loss: 0.8526 - val_my_iou_metric: 0.3245\n",
      "\n",
      "Epoch 00003: val_my_iou_metric did not improve from 0.51356\n",
      "Epoch 4/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.4594 - my_iou_metric: 0.5340 - val_loss: 0.4864 - val_my_iou_metric: 0.5913\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.51356 to 0.59129, saving model to unet_resnet.h5\n",
      "Epoch 5/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.4478 - my_iou_metric: 0.5642 - val_loss: 0.7291 - val_my_iou_metric: 0.4050\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.59129\n",
      "Epoch 6/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.4270 - my_iou_metric: 0.5693 - val_loss: 0.4657 - val_my_iou_metric: 0.6160\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.59129 to 0.61604, saving model to unet_resnet.h5\n",
      "Epoch 7/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.3954 - my_iou_metric: 0.6167 - val_loss: 0.3718 - val_my_iou_metric: 0.6714\n",
      "\n",
      "Epoch 00007: val_my_iou_metric improved from 0.61604 to 0.67139, saving model to unet_resnet.h5\n",
      "Epoch 8/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.3926 - my_iou_metric: 0.6254 - val_loss: 0.3548 - val_my_iou_metric: 0.6735\n",
      "\n",
      "Epoch 00008: val_my_iou_metric improved from 0.67139 to 0.67351, saving model to unet_resnet.h5\n",
      "Epoch 9/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.3511 - my_iou_metric: 0.6432 - val_loss: 0.5955 - val_my_iou_metric: 0.6725\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.67351\n",
      "Epoch 10/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.3949 - my_iou_metric: 0.6069 - val_loss: 1.0342 - val_my_iou_metric: 0.2715\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.67351\n",
      "Epoch 11/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.3770 - my_iou_metric: 0.6303 - val_loss: 0.4028 - val_my_iou_metric: 0.5845\n",
      "\n",
      "Epoch 00011: val_my_iou_metric did not improve from 0.67351\n",
      "Epoch 12/20\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.3455 - my_iou_metric: 0.6445 - val_loss: 0.3985 - val_my_iou_metric: 0.6596\n",
      "\n",
      "Epoch 00012: val_my_iou_metric did not improve from 0.67351\n",
      "Epoch 13/20\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.3337 - my_iou_metric: 0.6589 - val_loss: 0.3554 - val_my_iou_metric: 0.7230\n",
      "\n",
      "Epoch 00013: val_my_iou_metric improved from 0.67351 to 0.72301, saving model to unet_resnet.h5\n",
      "Epoch 14/20\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.3017 - my_iou_metric: 0.6809 - val_loss: 0.4227 - val_my_iou_metric: 0.6348\n",
      "\n",
      "Epoch 00014: val_my_iou_metric did not improve from 0.72301\n",
      "Epoch 15/20\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.3275 - my_iou_metric: 0.6653 - val_loss: 0.4502 - val_my_iou_metric: 0.6689\n",
      "\n",
      "Epoch 00015: val_my_iou_metric did not improve from 0.72301\n",
      "Epoch 16/20\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.3266 - my_iou_metric: 0.6556 - val_loss: 0.6139 - val_my_iou_metric: 0.5854\n",
      "\n",
      "Epoch 00016: val_my_iou_metric did not improve from 0.72301\n",
      "Epoch 17/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.2933 - my_iou_metric: 0.6876 - val_loss: 0.3324 - val_my_iou_metric: 0.6823\n",
      "\n",
      "Epoch 00017: val_my_iou_metric did not improve from 0.72301\n",
      "Epoch 18/20\n",
      "3196/3196 [==============================] - 240s 75ms/step - loss: 0.3024 - my_iou_metric: 0.6814 - val_loss: 0.3370 - val_my_iou_metric: 0.6723\n",
      "\n",
      "Epoch 00018: val_my_iou_metric did not improve from 0.72301\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 19/20\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.2413 - my_iou_metric: 0.7158 - val_loss: 0.4107 - val_my_iou_metric: 0.6699\n",
      "\n",
      "Epoch 00019: val_my_iou_metric did not improve from 0.72301\n",
      "Epoch 20/20\n",
      "3196/3196 [==============================] - 239s 75ms/step - loss: 0.2271 - my_iou_metric: 0.7017 - val_loss: 0.4027 - val_my_iou_metric: 0.6400\n",
      "\n",
      "Epoch 00020: val_my_iou_metric did not improve from 0.72301\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 20  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:48<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.6910 at threshold: 0.860\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.660558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.019259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.625746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.642724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.668657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.673197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.691045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.660558\n",
       "std     0.204939   0.019259\n",
       "min     0.200000   0.625746\n",
       "25%     0.370000   0.642724\n",
       "50%     0.540000   0.668657\n",
       "75%     0.710000   0.673197\n",
       "max     0.880000   0.691045"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf343a6320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xl41NXB9vH7ZCchC0mAEEJIgIR9D5uKiKKC4tbWBbRqVXBDq1ZbbZ8+tX26unSxYutWAQXEvbggLgUXQEjYIewhkJAAIQsJCdlmzvtHom+kAgEm+c1Mvp/r4oL5zZmZexCS28OZc4y1VgAAAAC+W4DTAQAAAABvRmEGAAAAToDCDAAAAJwAhRkAAAA4AQozAAAAcAIUZgAAAOAEKMwAAADACVCYAQAAgBOgMAMAAAAnQGEGAAAATiDI6QDHio+PtykpKU7HAAAAgJ9bvXr1IWttx5ON87rCnJKSoqysLKdjAAAAwM8ZY/Y0ZxxLMgAAAIAToDADAAAAJ0BhBgAAAE7A69Ywf5e6ujrl5+erurra6ShnLCwsTElJSQoODnY6CgAAAJrBJwpzfn6+IiMjlZKSImOM03FOm7VWxcXFys/PV2pqqtNxAAAA0Aw+sSSjurpacXFxPl2WJckYo7i4OL+YKQcAAGgrfKIwS/L5svw1f3kfAAAAbYXPFGannXXWWU5HAAAAgAMozM20fPlypyMAAADAARTmZmrfvr2khg/uPfTQQxowYIAGDhyoBQsWSJKWLl2qyZMnfzN+xowZmjVrlhNRAQAA4EE+sUtGU79+d7OyC8o9+pz9EqP0q8v6N2vsW2+9pXXr1mn9+vU6dOiQRowYoXPPPdejeQAAAOA9mGE+RV9++aWmTJmiwMBAde7cWePGjVNmZqbTsQAAANBCfG6Gubkzwa0tKChIbrf7m9tsHQcAAOAfmGE+RWPHjtWCBQvkcrlUVFSkzz//XCNHjlT37t2VnZ2tmpoalZWV6dNPP3U6KgAAADzA52aYnXbVVVdpxYoVGjx4sIwxeuyxx5SQkCBJuuaaazRgwAClpqZq6NChDicFAACAJxhrrdMZviUjI8NmZWV969qWLVvUt29fhxJ5nr+9HwAAAF9kjFltrc042TiWZAAAAAAnQGEGAAAAToDCDAAAAJyAz3zoz1orY4zTMc6Yt60ZBwAAbUtVbb0OlteosrZeVbUuHampV1WNq+F2Tb0qa12qqq1XZU3jz7Wub13/emxtvVtTRibrJxf1VmCA73e0E/GJwhwWFqbi4mLFxcX5dGm21qq4uFhhYWFORwEAAG1QncutC578TIWHT3xeRICRIkKDFBESpPDQQEWEBCkiNFCdI8MUHh+kiJBAFVfW6pmlu7S5oFxPXTdU0eHBrfQuWp9PFOakpCTl5+erqKjI6ShnLCwsTElJSU7HAAAAbdCynYdUeLhaM8b30oCu0YoIDfz/xTik4dfhIYEKDQpo1iTl3JV79OjCzbp85pd6/sYMpXeObIV30fp8ojAHBwcrNTXV6RgAAAA+7b0NhYoMC9I9F/RSaFDgGT/f9aO6q3fnSN3xyhpdNXOZnrxmiCYOSPBAUu/SrA/9GWMmGmO2GWN2GmMePs6Ya4wx2caYzcaYeU2u/8kYs6nxx7WeCg4AAIDmq6l3afHm/bqoX4JHyvLXMlJi9d4956hX50jd8cpq/fnj7XK7/eszWyctzMaYQEkzJU2S1E/SFGNMv2PGpEl6RNLZ1tr+ku5rvH6ppGGShkgaJelBY0yUR98BAAAATuqL7YdUUV2vyYO7ePy5E6LDtGD6aF09PElPfbpD01/OUnl1ncdfxynNmWEeKWmntTbHWlsr6VVJVxwzZpqkmdbaUkmy1h5svN5P0ufW2nprbaWkDZImeiY6AAAAmuvdDQWKCQ/WOb3iW+T5w4ID9dgPBuk3V/TX0m1FunLmMu0qOtIir9XamlOYu0rKa3I7v/FaU+mS0o0xy4wxXxljvi7F6yVNNMaEG2PiJY2X1O1MQwMAAKD5qutc+iT7gCYNSFBwYMsdw2GM0Y1jUvTKbaNUVlWnK59epk+3HGix12stnvodC5KUJuk8SVMkPW+MibHWfiTpA0nLJc2XtEKS69gHG2OmG2OyjDFZ/rATBgAAgDdZsvWgKmtdmjwosVVeb3SPOL17zznqHh+u2+Zk6e+f7vDpdc3NKcz79O1Z4aTGa03lS1pora2z1u6WtF0NBVrW2t9Za4dYay+UZBrv+xZr7XPW2gxrbUbHjh1P530AAADgON7bUKj49iEalRrbaq/ZNaad3rjjLF05pKue/Hi77pq7Rkdq6lvt9T2pOYU5U1KaMSbVGBMi6TpJC48Z844aZpfVuPQiXVKOMSbQGBPXeH2QpEGSPvJQdgAAAJxEZU29Pt16QJMGdFFQCy7H+C5hwYH68zWD9T+X9tVH2fv1vWeWKfdQZatm8IST/q5Za+slzZC0WNIWSa9ZazcbY35jjLm8cdhiScXGmGxJSyQ9ZK0tlhQs6YvG689JuqHx+QAAANAKPtlyQNV1bl02uHWWYxzLGKPbxvbQnFtG6WBFjS5/+kt9tt23luAaa71rPUlGRobNyspyOgYAAIBfmDYnSxvzD2v5w+crIODkp/e1pLySKk2bk6XtByr00MV9dMe4Hs06UbClGGNWW2szTjaudeflAQAA0GoOH63TZ9uKdMnALo6XZUnqFhuut+46S5MGdtGfPtyqGfPXqqrW+xcfUJgBAAD81MfZB1TrcuuyFjis5HSFhwTp6SlD9bOJffTBxkJ975nlyiupcjrWCVGYAQAA/NR7GwqU1KGdhnSLcTrKtxhjdOd5PfXSzSNUeLhaG/cddjrSCQU5HQAAAACeV1pZqy93HNKtY1MdXSd8Iuf17qTPHxqv6PBgp6OcEDPMAAAAfujDzftV77a6rJUOKzld3l6WJQozAACAX3pvQ4FS4yPUPzHK6Sg+j8IMAADgZ4oqarRiV7EmD+ritcsxfAmFGQAAwM98uKlQbitN9vLlGL6CwgwAAOBn3l1fqLRO7dU7IdLpKH6BwgwAAOBH9h+uVuaeEseOwvZHFGYAAAA/8v7GQlkrTR7kPYeV+DoKMwAAgB95b0OB+nWJUo+O7Z2O4jcozAAAAH4ir6RKa/eWabIXHYXtDyjMAAAAfuL9jYWS5PWHlfgaCjMAAICfeG9DgQZ3i1G32HCno/gVCjMAAIAf2H2oUpv2lesyPuzncRRmAAAAP/De+gJJ0iUDKcyeRmEGAADwA+9tKNSIlA5KjGnndBS/Q2EGAADwcTsOVGjbgQqOwm4hFGYAAAAf9+6GQgUYadLABKej+CUKMwAAgA+z1uq99QUalRqnTpFhTsfxSxRmAAAAH5ZdWK6cQ5W6bDDLMVoKhRkAAMCHvbehUIEBRhMHsByjpVCYAQAAfJS1Vu9tKNDZveIVGxHidBy/RWEGAADwUevzDyuv5CiHlbQwCjMAAICPem99gUICA3RRf5ZjtCQKMwAAgA9yu63e31ioc9PjFd0u2Ok4fo3CDAAA4INW7y1V4eFqDitpBRRmAAAAH/Te+gKFBgVoQr/OTkfxexRmAAAAH+NyW32wab/O79NJ7UODnI7j9yjMAAAAPmbl7mIVVdSwHKOVUJgBAAB8zLvrCxUeEqjz+3RyOkqbQGEGAADwIXUutz7cVKgJfTurXUig03HaBAozAACAD1m+q1ilVXWazGElrYbCDAAA4EPeW1+gyNAgjevd0ekobQaFGQAAwEfU1Lv04eb9urB/Z4UGsRyjtVCYAQAAfMQX2w+porpelw1md4zWRGEGAADwEe9tKFBMeLDO6RXvdJQ2hcIMAADgA6rrXPo4+4Am9k9QcCAVrjXxuw0AAOADlmw9qMpaF4eVOIDCDAAA4APe3VCg+PYhGt0j1ukobQ6FGQAAwMutzCnWok379b1hSQpiOUar43ccAADAix2pqdeDb6xXtw7h+vEFaU7HaZOCnA4AAACA4/v9B1uUX3pUr90+RhGhVDcnMMMMAADgpZZuO6h5K/dq+tgeGpHC2mWnUJgBAAC80OGqOv3szQ1K79xe91+Y7nScNo15fQAAAC/0q4WbVHykVi/cOEJhwRyD7SRmmAEAALzMoo2FemddgWac30sDk6KdjtPmUZgBAAC8SFFFjX7xziYN7Bqtu8f3cjoORGEGAADwGtZa/fztjTpSU68/XzOYI7C9BP8VAAAAvMRba/bp4+wDeuii3krrHOl0HDSiMAMAAHiBgrKjenThZo1MidUt56Q6HQdNUJgBAAAcZq3VT9/YIJe1evzqQQoMME5HQhMUZgAAAIe98tUefbnzkH5+SV91j4twOg6OQWEGAABwUO6hSv3+g606N72jrh+V7HQcfAcKMwAAgENcbqsHX1+v4ECjx74/SMawFMMbcdIfAACAQ174IkdZe0r1l2sHKyE6zOk4OA5mmAEAABywbX+Fnvxouyb2T9CVQ7o6HQcnQGEGAABoZXUutx54bZ0iw4L0u6sGsBTDyzWrMBtjJhpjthljdhpjHj7OmGuMMdnGmM3GmHlNrj/WeG2LMeYpw58IAADQxv39Pzu1uaBcv//eQMW1D3U6Dk7ipGuYjTGBkmZKulBSvqRMY8xCa212kzFpkh6RdLa1ttQY06nx+lmSzpY0qHHol5LGSVrqyTcBAADgK9bnlWnmkp363tCuurh/gtNx0AzNmWEeKWmntTbHWlsr6VVJVxwzZpqkmdbaUkmy1h5svG4lhUkKkRQqKVjSAU8EBwAA8DXVdS795PX16tg+VL+6vL/TcdBMzSnMXSXlNbmd33itqXRJ6caYZcaYr4wxEyXJWrtC0hJJhY0/Fltrt5x5bAAAAN/zxOJt2nnwiB77wSBFtwt2Og6ayVPbygVJSpN0nqQkSZ8bYwZKipfUt/GaJH1sjBlrrf2i6YONMdMlTZek5GQ27AYAAP5nZU6xXly2WzeMTta56R2djoNT0JwZ5n2SujW5ndR4ral8SQuttXXW2t2StquhQF8l6Str7RFr7RFJiySNOfYFrLXPWWszrLUZHTvyBwgAAPiXIzX1evCN9UqODdcjk/o6HQenqDmFOVNSmjEm1RgTIuk6SQuPGfOOGmaXZYyJV8MSjRxJeyWNM8YEGWOC1fCBP5ZkAACANuX3H2xRfulRPXH1YEWEcm6crzlpYbbW1kuaIWmxGsrua9bazcaY3xhjLm8ctlhSsTEmWw1rlh+y1hZLekPSLkkbJa2XtN5a+24LvA8AAACv9J+tBzRv5V5NH9tDI1JinY6D02CstU5n+JaMjAyblZXldAwAAIAzsqe4Un/9ZIfeWbdPaZ3aa+GMcxQWHOh0LDRhjFltrc042Tj+TQAAAMCDCg8f1d//s1OvZeYpKNBo+rk9dOe4npRlH0ZhBgAA8IDiIzV6ZukuvfzVHllrNXVUsmaM76VOUWFOR8MZojADAACcgcNH6/TCFzl68cvdqq5z6fvDknTvBWnqFhvudDR4CIUZAADgNFTV1uulZbl69rNdKq+u16WDuuj+Cenq1am909HgYRRmAACAU1Bd59K8lXv1zNKdOnSkVhf06aQHLkpX/8Rop6OhhVCYAQAAmqHe5dYbq/P11Kc7VHC4WmN6xOnZH/bW8O4dnI6GFkZhBgAAOAG32+rdDQX6y8fblVtcpSHdYvT41YN1dq94p6OhlVCYAQAAvoO1Vh9nH9CfP96urfsr1CchUi/cmKEL+naSMcbpeGhFFGYAANCmlVbWKre4UnuKq7T7UKX2FFcqt7hKucWVKquqU2p8hJ6aMlSTB3ZRQABFuS2iMAMAAL9mrVVpVZ1yiyuVe6ixDDcpxoeP1n0z1hgpMbqdUuMjdOnALhrevYMuH5yooMAAB98BnEZhBgAAfmX3oUq9tSZfucVV2lNcqd2HKlVRXf/N/QFG6tqhnVLiInT54ER1jwtXSlyEUuIj1C22nUKDOJEP30ZhBgAAfmNDfplu/NcqVVTXK6lDO3WPi9BVQ2MaC3G4usdFqFuHcIUEMWOM5qMwAwAAv7Bqd4lumZWpmPBgLbz7HCXHcdIePIPCDAAAfN7SbQd1xyur1TWmnebeNloJ0WFOR4IfoTADAACftmhjoe59da3SOkVqzq0jFd8+1OlI8DMUZgAA4LPeXJ2vh95YryHdYvTSj0Yqul2w05HghyjMAADAJ728Ile//Pdmnd0rTs/9MEMRodQatAz+ZAEAAJ/zj6W79KcPt2pC3856eupQhQWzFRxaDoUZAAD4DGutnvhom2Yu2aUrhiTqiasHK5hDRdDCKMwAAMAnuN1Wv3kvW7OW52rKyGT99soBCuSoarQCCjMAAPB69S63Hn5ro95Yna9pY1P180v6yhjKMloHhRkAAHi12nq37luwVh9s3K/7J6Tr3gt6UZbRqijMAADAax2tdenOuau1dFuR/ufSvrptbA+nI6ENojADAACvVFFdp1tnZykzt0R/+N5ATRmZ7HQktFEUZgAA4HVKK2t180urtLmgXH+7bqguH5zodCS0YRRmAADgVQ5WVOuHL6zS7uJK/fOG4ZrQr7PTkdDGUZgBAIDXyC+t0g0vrNTBihq9dPMInd0r3ulIAIUZAAB4hz3FlZry3Fc6UlOvl28dpeHdOzgdCZBEYQYAAF6gsqZet83OUlWdS/Onj1b/xGinIwHf4CxJAADgKGutfvrmBu0qOqKZU4dRluF1KMwAAMBRL365W+9vKNRDF/dhzTK8EoUZAAA4ZmVOsf6waKsu7t9Zd4zjUBJ4JwozAABwxIHyat09b626x4briasHc9w1vBYf+gMAAK2utt6tu+auUVVtveZNG6XIsGCnIwHHRWEGAACt7nfvZ2v1nlI9PXWo0jtHOh0HOCGWZAAAgFb19tp8zV6xR7edk6rJgzjyGt6PwgwAAFrNlsJyPfLWRo1MjdXPJvVxOg7QLBRmAADQKg4frdMdr6xWdLtgPT11qIIDqSHwDaxhBgAALc7ttnpgwTrtKz2qBbePVqfIMKcjAc3G/9oBAIAWN3PJTn269aB+ObmfhnePdToOcEqYYQYAwEe53VZVdS5V1dTrSE29qmpdqvz659p6VdU0/lzrari/pl6VtS5V1darsqbhZ0m6cUyKJg/q0mL7IC/ddlB//mS7rhraVTeO6d4irwG0JAozAAA+5qucYt0zf62KKmqa/ZigAKOI0CBFhAQqIjRI4Y2/PlBerXvmr9Ws5bn65eR+GtItxqNZ80qq9ONX16l350j9/qqBHE4Cn0RhBgDAh6zYVaxbZmUqMSZM149KVkRIkMJDAxt+bizDXxfjr0txeEiQQoK+exWmy231xuo8Pb54u66cuUxXDe2qn07srS7R7c44a3WdS3fOXS23tXr2h8PVLiTwjJ8TcAKFGQAAH7F85yHdMjtT3TqEa9600eoYGXrGzxkYYHTtiGRdOihRzyzZqRe+3K1Fmwo1/dyeumNcD4WHnF5VsNbql+9s0qZ95Xrxpgx1j4s446yAU/jQHwAAPmBZY1lOjg3X/OmeKctNtQ8N0k8n9tGnD4zThL6d9dSnOzT+iaV6c3W+3G57ys83f1WeXl+dr3vP76UL+nb2aFagtVGYAQDwcl/uOKRbZmWqe2yE5k8brfj2ni3LTXWLDdfTU4fpjTvGKCEqTD95fb2ufGaZMnNLmv0c6/LK9OjCzRqX3lE/npDeYlmB1kJhBgDAi32xo0i3zs5UanyE5k0bpbgWLMtNZaTE6u27ztZfrh2sg+U1uvqfK3T33DXKK6k64eOKj9TozldWq1NUqP523RAFBvAhP/g+1jADAOClPt9epNvmZKlHfITmTRut2IiQVn39gACjq4Ym6eL+CXru8xz987Nd+njLAd16TqruOq+nIsOCvzW+3uXWPfPXqqSyVm/eeZZiwls3L9BSmGEGAMALfdZYlnt2bK/5DpTlpsJDgnTfhHQtefA8TR7YRf9Yukvjn1iq+av2ytVkffMTH23X8l3F+u2VAzSga7RjeQFPozADAHASbrfVW2vytSG/rFVeb8m2g5o2J0u9OrbXvNtGqYODZbmpLtHt9Odrh+idu89W97gIPfLWRl361BdavvOQPtxUqH9+tktTRyXr6oxuTkcFPMpYe+qffG1JGRkZNisry+kYAABIkkoqa3X/gnX6bHuRJOmifp31k4t6q3dCZIu83pKtB3X7y6uV1rm95t42ymuXNVhr9f7GQv3hg63aV3ZUQQFG/btG67XbRys0iP2W4RuMMauttRknHUdhBgDgu63eU6IZ89aquLJWv7ikr8qP1um5z3N0pLZeVwxO1H0T0pUS77n9hf+z9YDueHmN0hPa65VbvbcsN1Vd59KLX+7WZ9uL9Ndrhygx5swPPAFaC4UZAIDTZK3V81/k6LEPt6lrh3aaOXXYN2tyy6pq9eznOZq1LFe1LreuyUjSPeennXFR/HTLAd3xymr1SYjSK7eOUnR48MkfBOCMUJgBADgNh6vq9JPX1+uTLQc0aUCC/vSDQYoK++/yerCiWs8s2aV5K/dKRrphVHfdNb7nae2R/En2Ad05d7X6donSy7eOUnQ7yjLQGijMAACcovV5Zbp73hodKK/Wzy/pq5vPSpExJ95HeF/ZUT31yQ69sSZfoUEB+tHZKZo+tmezZ4g/2rxfd89bo35dojSHsgy0KgozAADNZK3VnBV79Nv3s9UpMkxPTx2qockdTuk5coqO6C+f7NC76wsUFRak28f11M1npSgi9PhHHizevF93z12jAV2jNefWkd85kw2g5VCYAQBohorqOj385ka9v7FQF/TppCevGXxGH7bbUliuJz/ark+2HFB8+xDdeV4vXT8qWWHB39454sNN+zVj3hoNTIrW7Fsoy4ATKMwAAJxEdkG57pq7WnmlR/XQxb01fWwPBXjoKOc1e0v15EfbtGxnsbpEh+neC9L0g+FJCg4M0KKNhbpn/loNaizLx56YB6B1UJgBADgOa61ezczTrxZuVofwYD09dZhGpMS2yGst33VITyzepjV7y9Q9LlyTB3XRPz/L0ZBuMZr1oxGUZcBBzS3MzTrpzxgz0RizzRiz0xjz8HHGXGOMyTbGbDbGzGu8Nt4Ys67Jj2pjzJWn9lYAAG3N4ao6rdhVrMzcElVU13n0uStr6vXAa+v1yFsbNSo1Vh/cO7bFyrIkndUzXm/eeZb+dXOGwkOCNHPJLg3tFsPMMuBDTjrDbIwJlLRd0oWS8iVlSppirc1uMiZN0muSzrfWlhpjOllrDx7zPLGSdkpKstZWHe/1mGEGgLbDWquCw9XKLijX5oLDyi4oV3ZhufJLj35rXEpcuPolRql/YrT6dYlS/8QodYwMPekOFsfafqBCd81do5yiI7pvQrruHt9LgR5agtEcbrdVZm6JBiXFqF0Ip+EBTmvuDPPxP7r7/42UtNNam9P4xK9KukJSdpMx0yTNtNaWStKxZbnRDyQtOlFZBgD4r3qXW7uKKpVdeLixIDeU47KqhhlkY6TU+AgN6Raj60d1V98ukXJb+83YzQXl+mDj/m+eL759iPo1KdD9EqOUEhdx3AL85up8/c87mxQRGqRXbh2ls3rFt8r7biogwGhUj7hWf10AZ6Y5hbmrpLwmt/MljTpmTLokGWOWSQqU9Ki19sNjxlwn6c+nmRMA4EMqa+q1dX+FsgsOK7uwoexu3V+h2nq3JCkkKEB9EiI1aUCC+nWJUr/EaPVJiPzOLdjO79P5m1+XV9dpa2HFN7PRmwvK9eKuHNW5Gv61NDwkUH0SIr81G50SF6Hff7BFC7LyNCo1Vn+fMlSdosJa5zcCgF9oTmFu7vOkSTpPUpKkz40xA621ZZJkjOkiaaCkxd/1YGPMdEnTJSk5OdlDkQAArclaq893HNI/lu7Uyt0l+nrFX3S7YPVPjNJNY7p/U2R7xEcoKLBZH6P5lqiwYI1MjdXI1P+/5ri23q0dByu+NWv977UFeuWrvd967IzxvXTfhLTTel0AbVtzCvM+Sd2a3E5qvNZUvqSV1to6SbuNMdvVUKAzG++/RtLbjff/F2vtc5KekxrWMDc/PgDAaS631Yeb9usfn+3Upn3l6hIdpnvG99LApBj1S4xSYnTYKa81PhUhQQHqnxit/onRurrxmtttlV96VNmFh7V1f4VGpsQ6sgQDgH9oTmHOlJRmjElVQ1G+TtLUY8a8I2mKpJeMMfFqWKKR0+T+KZIeOfO4AABvUVvv1ttr8/XsZznKOVSpHvEReuz7g3Tl0K4KCXJ2FjcgwCg5LlzJceGaOKCLo1kA+L6TFmZrbb0xZoYallMESvqXtXazMeY3krKstQsb77vIGJMtySXpIWttsSQZY1LUMEP9Wcu8BQBAa6qqrde8lXv1whe7tb+8WgO6RumZ64fp4v4JrbrjBAC0Fg4uAQAft3znIb2zbp/6J0YrI6WD+iREtUhxLauq1ezlezRr+W6VVtVpdI9Y3XVeL41Ni2/RJRcA0FI8ua0cAMBLLdt5SD+alSkj6bWsfElSZGiQhnXvoJGpscro3kGDu8UoLPj09/w9UF6tF77I0byVe1VZ69KEvp111/ieGpbcwUPvAgC8G4UZAHxUVm6JbpudpZS4cL06fYyqauuVlVuqVbklysot0eOLt0mSQgIDNCgpWhkpsRqZ2kHDk2MVHX7yE+ZyD1Xq2c936c3V++SyVpcN6qI7z+ul3gmRLf3WAMCrsCQDAHzQ+rwyXf/CSnWMDNWC20erU+R/7ytcWlmrrD2lysot0arcEm3MP6x6t5UxUu/OkcpI6aARKQ1btHWJbvfN47ILyvWPz3bp/Q0FCgoM0DUZSbr93J7qFhvemm8RAFpcc5dkUJgBwMdsKSzXdc99pciwIL12+xglxrQ7+YMkHa11aV1e2TcFes2eUlXWuiRJXWPaaWRqrMqqarVkW5HahwbphtHddcs5Kd9ZxgHAH7CGGQD80M6DR/TDF1eqXXCg5t02utllWZLahQRqTM84jenZcDRzvcutrfsrtGp3ibL2lOiLHYckWT10cW/dMLq7otudfNkGALQFFGYA8BF7iit1/QtfSZLmThul5LgzWyIRFBigAV2jNaBrtG45J1Vf/4s1O3LyAAAgAElEQVQjO14AwLdRmAHABxSUHdXU51eqpt6tV6ePVs+O7T3+GhRlAPhuzh7FBAA4qYPl1Zr6/FcqP1qnl28ZpT4JUU5HAoA2hRlmAPBixUdqdP0LK3WwokYv3zpSA5OinY4EAG0OM8wA4KUOV9Xphy+u0t6SKr1wU4aGd491OhIAtEkUZgDwQkdq6nXTS6u042CFnv3hcJ3VM97pSADQZrEkAwC8zNFal26ZlamN+w7rmeuH6bzenZyOBABtGjPMAOBFqutcmv5yljJzS/SXa4fo4v4JTkcCgDaPwgwAXqLO5daMeWv0xY5D+tP3B+nywYlORwIAiMIMAF7B5ba6b8E6fbLloP7viv66JqOb05EAAI0ozADgMLfb6qdvbND7Gwr1i0v66odjUpyOBABogsIMAA6y1uqX/96kN9fk64EL0zXt3B5ORwIAHIPCDAAOsdbqt+9v0dyVe3XneT11z/m9nI4EAPgOFGYAcMjLX+3Ri1/u1s1npeinF/eWMcbpSACA70BhBgAH7Cs7qj8u2qpz0zvqV5f1oywDgBejMANAK7PW6n/e3ihJ+v1VAyjLAODlKMwA0MoWri/Qkm1FevCi3krqEO50HADASVCYAaAVlVbW6jfvZmtwtxjddFaK03EAAM0Q5HQAAGhLfvv+Fh0+Wqe53x+owACWYgCAL2CGGQBayRc7ivTmmnzdMa6n+iREOR0HANBMFGYAaAVVtfX6+dsb1SM+QjPYbxkAfApLMgCgFfzl4+3KKzmqBdNHKyw40Ok4AIBTwAwzALSwDfllevHL3Zo6KlmjesQ5HQcAcIoozADQgupcbv3szY2Kbx+qhyf1cToOAOA0sCQDAFrQ81/kaEthuZ794XBFhQU7HQcAcBqYYQaAFrL7UKX++skOTRqQoIv7JzgdBwBwmijMANAC3G6rh9/coNCgAP368v5OxwEAnAEKMwC0gNey8rRyd4l+cUlfdYoKczoOAOAMUJgBwMMOllfrdx9s0egesbp2RDen4wAAzhCFGQA87FcLN6um3q0/fG+QjOH4awDwdRRmAPCgDzft16JN+3XfhDSlxkc4HQcA4AEUZgDwkMNH6/S//96kvl2iNG1sD6fjAAA8hMIMAB7ypw+36tCRGv3p+wMVHMiXVwDwF3xFBwAPWLW7RPNW7tWt56RqUFKM03EAAB5EYQaAM1Rd59LDb21QUod2uv/CdKfjAAA8jKOxAeAMzVyyUzlFlZpzy0iFh/BlFQD8DTPMAHAGtu4v1z+W7tL3hnXVuekdnY4DAGgBFGYAOE0ut9XP3tyo6HbB+uWl/ZyOAwBoIRRmADhNs5fnan1emf73sn7qEBHidBwAQAuhMAPAacgrqdITH23T+N4ddfngRKfjAABaEIUZAE6RtVa/eGeTJOm3Vw3k+GsA8HMUZgA4RYs27dfn24v004t7q2tMO6fjAABaGIUZAE5Bncutxz7cqt6dI/XDMSlOxwEAtAIKMwCcgvmr9iq3uEo/m9RbgQEsxQCAtoDCDADNdKSmXn/7ZIdGpcZqfO9OTscBALQSjqQCgGZ6/vMcFVfW6sVL+vJBPwBoQ5hhBoBmOFhRree/yNGlA7toSLcYp+MAAFoRhRkAmuGpT3eott6tBy/u7XQUAEArozADwEnkFB3R/FV5mjIyWanxEU7HAQC0MgozAJzEEx9tU2hQgO69IM3pKAAAB1CYAeAE1u4t1Qcb92va2B7qGBnqdBwAgAMozABwHNZa/WHRVsW3D9G0c3s4HQcA4BAKMwAcx5JtB7Vqd4l+fEGa2oeyCycAtFUUZgD4Di631Z8WbVNKXLiuG5nsdBwAgIOaVZiNMRONMduMMTuNMQ8fZ8w1xphsY8xmY8y8JteTjTEfGWO2NN6f4pnoANBy3lyTr20HKvTQxX0UHMjcAgC0ZSf9N0ZjTKCkmZIulJQvKdMYs9Bam91kTJqkRySdba0tNcY0PTN2jqTfWWs/Nsa0l+T26DsAAA+rrnPpLx9v1+BuMbpkYILTcQAADmvOtMlISTuttTnW2lpJr0q64pgx0yTNtNaWSpK19qAkGWP6SQqy1n7ceP2ItbbKY+kBoAXMWp6rwsPVemRSH47ABgA0qzB3lZTX5HZ+47Wm0iWlG2OWGWO+MsZMbHK9zBjzljFmrTHm8cYZawDwSmVVtXpmyU6d36eTRveIczoOAMALeGphXpCkNEnnSZoi6XljTEzj9bGSHpQ0QlIPSTcf+2BjzHRjTJYxJquoqMhDkQDg1D2zdJcqaur104kcgQ0AaNCcwrxPUrcmt5MarzWVL2mhtbbOWrtb0nY1FOh8Sesal3PUS3pH0rBjX8Ba+5y1NsNam9GxY8fTeR8AcMb2lR3VrOW5+v6wJPVJiHI6DgDASzSnMGdKSjPGpBpjQiRdJ2nhMWPeUcPssowx8WpYipHT+NgYY8zXLfh8SdkCAC/05EfbJEkPXJjucBIAgDc5aWFunBmeIWmxpC2SXrPWbjbG/MYYc3njsMWSio0x2ZKWSHrIWltsrXWpYTnGp8aYjZKMpOdb4o0AwJnILijX22v36UdnpSgxpp3TcQAAXsRYa53O8C0ZGRk2KyvL6RgA2pibX1qltXvL9PlD4xUdHux0HABAKzDGrLbWZpxsHLvxA2jzlu86pKXbinT3+J6UZQDAf6EwA2jT3G6rPy7aqsToMN04JsXpOAAAL0RhBtCmfbCpUBvyD+uBi3orLJht4gEA/43CDKDNqq136/HF29QnIVJXDT32PCYAABpQmAG0WfNX7dWe4ir9bFIfBQZwBDYA4LtRmAG0SRXVdXrq0x0a3SNW56VzYBIA4PiCnA4AAE54/ovdKq6s1b8m9ZUxzC4DAI6PGWYAbc7Bimq98EWOLh3URYO7xTgdBwDg5SjMANqcv32yQ7X1bj10UW+nowAAfACFGUCbklN0RK9m5mnqqGSlxEc4HQcA4AMozADalMcXb1NYUIDuvSDN6SgAAB9BYQbQZnySfUCLNu3X9HN7Kr59qNNxAAA+gsIMoE3ILijXva+u1cCu0Zp+bg+n4wAAfAiFGYDfO1herdtmZyoqLFgv3JShdiEcgQ0AaD72YQbg147WujRtTpZKq+r0+h1j1DkqzOlIAAAfQ2EG4LfcbqufvL5OG/Yd1rM3DNeArtFORwIA+CCWZADwW3/+eLs+2Lhfj0zqo4v6JzgdBwDgoyjMAPzSW2vy9fSSnbo2o5umjeVDfgCA00dhBuB3MnNL9PCbGzWmR5z+78oBMsY4HQkA4MMozAD8yt7iKt3+8moldWinf9wwTCFBfJkDAJwZvpMA8BuHj9bpltmZcrmtXrx5hGLCQ5yOBADwAxRmAH6hzuXWjHlrtKe4Uv+8YbhS4yOcjgQA8BNsKwfA51lr9ejCzfpixyE99oNBGtMzzulIAAA/wgwzAJ/30rJczV25V7eP66FrMro5HQcA4GcozAB82n+2HtBv38/WRf0662cX93E6DgDAD1GYAfisrfvLdc+8terbJUp/vW6IAgLYPg4A4HkUZgA+6WBFtW6dlaX2YUF68aYRCg/hIxkAgJbBdxgAPqe6zqXpc1arpLJWr98xRgnRYU5HAgD4MQozAJ/idls9+Pp6rc8v0z+uH64BXaOdjgQA8HMsyQDgU/766Q69t6FQP5vYRxMHJDgdBwDQBlCYAfiMd9bu01Of7tA1GUm6/dweTscBALQRFGYAPiErt0Q/fWODRqXG6rdXDpQx7IgBAGgdrGEG4LXcbqu1eWX6YGOhXs/KU2JMmP55w3CFBPH/+gCA1kNhBuBVGkpyqd7fsF+LNhWq8HC1QgIDNDYtXr+c3E8dIkKcjggAaGMozAAc53Zbrd5bqvc3FOrDTfu1v7yhJJ+b3lEPXdxbE/p1VlRYsNMxAQBtFIUZgCPcbqusPaX6YGOhFm0q1IHyGoUEBWhcekc9PLCPLujbSZGUZACAF6AwA2g1LrdVZm6JPtjYMJN8sKJGoUEBOq93R10ysIvO70NJBgB4HwozgBblclut2t1YkjfvV1FFjcKCAzS+dydNaizJ7UP5UgQA8F58lwLQYrbtr9BtczKVV3JUYcEBOr9PJ10ysIvG9+6kCEoyAMBH8B0LQItYmVOs2+ZkKTwkUE9PHarz+3RSeAhfcgAAvofvXgA8btHGQv14wTp169BOc24dpa4x7ZyOBADAaaMwA/Col1fk6n8XbtbQbjF68aYR7JsMAPB5FGYAHmGt1ZMfbdfTS3ZqQt9O+vuUYWoXEuh0LAAAzhiFGcAZq3e59fO3N+q1rHxdN6KbfnvlAAUFcnw1AMA/UJgBnJGjtS7NmLdGn249qHsvSNP9E9JkjHE6FgAAHkNhBnDaSiprdevsTK3PK9NvrxygG0Z3dzoSAAAeR2EGcFrySqp000urlF96VM9cP1wTByQ4HQkAgBZBYQZwyrYUluumf61SdZ1Lr9w6SiNTY52OBABAi6EwAzglK3YVa/qcLEWEBun1O85S74RIpyMBANCiKMwAmu39DYW6f8E6JceFa84tI5XIgSQAgDaAwgygWWYt261fv5et4ckd9MJNGYoJ50ASAEDbQGEGcELWWj2+eJueWbpLF/brrL9PGaqwYA4kAQC0HRRmAMdV53Lrkbc26o3V+ZoyMln/d0V/DiQBALQ5FGYA36mqtl53zV2jpduKdN+ENP34Ag4kAQC0TRRmAP+ltt6tG19cpTV7S/X7qwZq6qhkpyMBAOAYCjOA//K3T7cra0+p/nbdEF0xpKvTcQAAcBSLEQF8y6rdJXpm6S5dm9GNsgwAgCjMAJoor65r2Gc5Nlz/e1k/p+MAAOAVWJIB4BuP/nuz9pdX6/U7xigilC8PAABIzDADaPTu+gK9tXaf7jm/l4Yld3A6DgAAXqNZhdkYM9EYs80Ys9MY8/BxxlxjjMk2xmw2xsxrct1ljFnX+GOhp4ID8JyCsqP6xdsbNaRbjGaM7+V0HAAAvMpJ/83VGBMoaaakCyXlS8o0xiy01mY3GZMm6RFJZ1trS40xnZo8xVFr7RAP5wbgIW631U9eW696t9Vfrx3CwSQAAByjOd8ZR0raaa3NsdbWSnpV0hXHjJkmaaa1tlSSrLUHPRsTQEt54cscrcgp1qOX9VdKfITTcQAA8DrNKcxdJeU1uZ3feK2pdEnpxphlxpivjDETm9wXZozJarx+5Xe9gDFmeuOYrKKiolN6AwBOX3ZBuR5fvE0X9++sqzOSnI4DAIBX8tTH4IMkpUk6T1KSpM+NMQOttWWSultr9xljekj6jzFmo7V2V9MHW2ufk/ScJGVkZFgPZQJwAtV1Lt23YK06hIfoD98bxLHXAAAcR3NmmPdJ6tbkdlLjtabyJS201tZZa3dL2q6GAi1r7b7Gn3MkLZU09AwzA/CAPy7aqu0HjujxqwcrNiLE6TgAAHit5hTmTElpxphUY0yIpOskHbvbxTtqmF2WMSZeDUs0cowxHYwxoU2uny0pWwAc9dn2Is1anqubz0rRuPSOTscBAMCrnXRJhrW23hgzQ9JiSYGS/mWt3WyM+Y2kLGvtwsb7LjLGZEtySXrIWltsjDlL0rPGGLcayvkfm+6uAaD1lVTW6sHX1yu9c3s9PKmP03EAAPB6xlrvWjKckZFhs7KynI4B+CVrre54ZbWWbC3SO3efrX6JUU5HAgDAMcaY1dbajJONY8NVoA15PStfizcf0IMXp1OWAQBoJgoz0EbkHqrUo+9u1pgecbrtnB5OxwEAwGdQmIE2oN7l1n0L1ikowOjJawYrIIAt5AAAaC5P7cMMwIs9vWSn1uWV6e9Thioxpp3TcQAA8CnMMAN+bs3eUv39Pzt11dCuumxwotNxAADwORRmwI8dqanX/QvWKSEqTL++or/TcQAA8EksyQD82P+9m629JVVaMH2MosKCnY4DAIBPYoYZ8FMfbtqvBVl5unNcT41MjXU6DgAAPovCDPihA+XVevitDRrYNVr3TUh3Og4AAD6Nwgz4Gbfb6sHX16u6zqW/XDtEIUH8NQcA4EzwnRTwM7NX5OqLHYf0i0v7qVen9k7HAQDA51GYAT+SXVCuPyzaqvP7dNINo5KdjgMAgF+gMAN+oqq2XvfMX6PodsF6/AeDZAyn+QEA4AlsKwf4id+8m62cQ5V65dZRimsf6nQcAAD8BjPMgB94d32BXs1s2ELu7F7xTscBAMCvUJgBH5dXUqWfv7VRQ5NjdP+FbCEHAICnUZgBH1bncuveV9dKkp66bqiCA/krDQCAp7GGGfBhf/1ku9buLdPfpwxVt9hwp+MAAOCXmI4CfNTynYf0zNJdujajmy4bnOh0HAAA/BaFGfBBxUdqdN+CdeoRH6FfXd7P6TgAAPg1lmQAPsZaq4fe2KCyo3Wa9aORCg/hrzEAAC2JGWbAx7y0LFf/2XpQv7ikr/olRjkdBwAAv0dhBnzIpn2H9cdFWzWhb2fdOKa703EAAGgTKMyAj6isqde989cqNiKEo68BAGhFLH4EfMSvFm7W7uJKzZ82Wh0iQpyOAwBAm8EMM+AD/r1un95Yna97xvfS6B5xTscBAKBNoTADXm5PcaV+8fYmZXTvoHsvSHM6DgAAbQ6FGfBitfVu3Tt/rQKM9NfrhiiIo68BAGh1rGEGvNiTH2/T+vzD+sf1w5TUgaOvAQBwAtNVgJf6fHuRnv0sR1NHJWvSwC5OxwEAoM2iMANeqKiiRg+8tl7pndvrfydz9DUAAE5iSQbgZdxuq5+8vl4V1XWae9sohQUHOh0JAIA2jRlmwMu8+OVufb69SL+c3E+9EyKdjgMAQJtHYQa8yIb8Mj22eKsm9k/Q9aOSnY4DAABEYQa8xpGaet0zf606tg/VH78/kKOvAQDwEqxhBrxATb1L9y9Yp7ySKi24fYxiwjn6GgAAb0FhBhxWXl2n6XOy9FVOiR69rJ9GpMQ6HQkAADRBYQYcdLC8Wje9lKmdByv012uH6MqhXZ2OBAAAjkFhBhyyq+iIbnxxlcqqavWvm0dobFpHpyMBAIDvQGEGHLB2b6lumZWpwACjV6eP0cCkaKcjAQCA46AwA63sP1sP6K65a9Q5Kkxzbhmp7nERTkcCAAAnQGEGWtFrWXl65K2N6tclSi/9aITi24c6HQkAAJwEhRloBdZaPbN0lx5fvE1j0+L1zxuGKyKUv34AAPgCvmMDLczltvr1u5s1Z8UeXTkkUY/9YLBCgjgzCAAAX0FhBlpQdZ1LD7y2Th9s3K/bz+2hn03so4AATvADAMCXUJiBFnL4aMOBJCt3l+h/Lu2r28b2cDoSAAA4DRRmoAXsP1ytm19apV1FR/TUlKG6fHCi05EAAMBpojADHrbzYIVu+lemyqpq9dLNI3VOWrzTkQAAwBmgMAMetHpPqW6dnamggAAtuH2MBnTlQBIAAHwdhRnwkE+yD2jG/DXqEt1Os380Uslx4U5HAgAAHkBhBjxgQeZe/fztTRqQGKV/3TxCcRxIAgCA36Awo03KK6nSy1/tUVZuiewZPpfLbbUh/7DGpXfUM9cP40ASAAD8DN/Z0WZYa/XlzkOavTxXn249qABjNLx7B4V64BCR28f10IMX9VZwIAeSAADgbyjM8HtHaur11pp8zV6eq11FlYqLCNHd5/XS9aOT1SW6ndPxAACAl6Mww2/tPlSp2ctz9ebqfFXU1GtQUrSevHqwLh3URWHBgU7HAwAAPoLCDL/idlt9tr1Is5bn6rPtRQoONLpkYBfddFaKhnaLkTEcSw0AAE4NhRl+oby6Tq9n5evlFbnKLa5Sx8hQ3TchTVNHJqtTVJjT8QAAgA+jMMOn7ThQodkrcvXWmn2qqnVpWHKM7r8wXZMGdFGIBz7MBwAAQGGGz3G5rT7dckCzV+Rq2c5ihQQGaPLgLrr5rBQNSopxOh4AAPAzzSrMxpiJkv4mKVDSC9baP37HmGskPSrJSlpvrZ3a5L4oSdmS3rHWzvBAbrRBZVW1ei0rT3NW7FF+6VElRIXpwYvSdd3IZMVzUAgAAGghJy3MxphASTMlXSgpX1KmMWahtTa7yZg0SY9IOttaW2qM6XTM0/yfpM89Fxttydb95Zq9PFdvr92n6jq3RqbG6pFJfXVR/87sewwAAFpcc2aYR0raaa3NkSRjzKuSrlDDjPHXpkmaaa0tlSRr7cGv7zDGDJfUWdKHkjI8lBt+rt7l1sfZBzRrea5W7i5RaFCArhraVTeOSVG/xCin4wEAgDakOYW5q6S8JrfzJY06Zky6JBljlqlh2caj1toPjTEBkp6UdIOkCcd7AWPMdEnTJSk5ObnZ4eF/SiprNX/VXs39ao8KDlera0w7PTypj67N6KYOESFOxwMAAG2Qpz70FyQpTdJ5kpIkfW6MGaiGovyBtTb/RPvfWmufk/ScJGVkZFgPZYIP2bTvsGYtz9XC9QWqrXfr7F5xevTy/rqgb2cFBrB3MgAAcE5zCvM+Sd2a3E5qvNZUvqSV1to6SbuNMdvVUKDHSBprjLlLUntJIcaYI9bah888OnxdncutRZv2a/byXK3eU6rwkEBdk5Gkm8akKK1zpNPxAAAAJDWvMGdKSjPGpKqhKF8naeoxY96RNEXSS8aYeDUs0cix1l7/9QBjzM2SMijLKKqo0byVezV35R4drKhR97hw/XJyP/1geJKi2wU7HQ8AAOBbTlqYrbX1xpgZkharYX3yv6y1m40xv5GUZa1d2HjfRcaYbEkuSQ9Za4tbMjh8z6EjNfrd+1v03oYC1bmsxqV31J++n6Jx6R0VwLILAADgpYy13rVkOCMjw2ZlZTkdAx5WU+/S1OdXatO+w5oyMlk3jumuHh3bOx0LAAC0YcaY1dbak+7ixkl/aHHWWv3q35u1ek+pZk4dpksHdXE6EgAAQLNx6gNa3Mtf7dGrmXmaMb4XZRkAAPgcCjNa1Ipdxfr1u9ma0LeTHrgw3ek4AAAAp4zCjBaTV1Klu+auVmp8hP5y7RA+2AcAAHwShRktoqq2XtPmZMnltnr+xgxFhrFdHAAA8E186A8eZ63Vg6+v1/YDFXrpRyOVGh/hdCQAAIDTxgwzPG7mkp36YON+PTypj8ald3Q6DgAAwBmhMMOjPs4+oCc+2q4rhyRq2tgeTscBAAA4YxRmeMyOAxW6f8E6DewarT9+f5CM4UN+AADA91GY4RGHq+o0bU6WwoID9dyNwxUWHOh0JAAAAI+gMOOM1bvcmjF/jfaVHdU/bximLtHtnI4EAADgMeySgTP2pw+36ov/196dB0lZ33kcf38HGJBLjgFELhEBxYAIJCYmWdRowqohXkRdU6tbronm2lpNds0mZaVM7YFmN6na6O7qlpVoDhViCDFGY7nibSLD4YECHugMoAzIIXLP/PaPeTQjgZ4eYPqZnn6/qrrofubp6c98feqZj888/fTK9cw+fyLTjhqQdxxJkqRDyiPMOij3LKrn1sde49KPjeLCD4/MO44kSdIhZ2HWAVtat4lr73mOjx49gO+cPSHvOJIkSe3CwqwDsm7LDr54x0IG9e7OzZdMpVsXNyVJktQ5eQ6z2mznnkau/GktW7bv4ZdXncyAXtV5R5IkSWo3Fma1SUqJ6+a9wKI3NnHTX01hwpF9844kSZLUrvw7utrk9qde566FdXzttGM4a9LQvONIkiS1OwuzivbkK+u5/t5lnH7cYP7+9HF5x5EkSSoJC7OKUvf2Nr7ys0WMrunFDy6cTFWVH3stSZIqg4VZrdq+q5Erbl9IY1Pi1r+eRp8e3fKOJEmSVDK+6U+t+tXi1bz05jvcdtk0Rtf0yjuOJElSSXmEWa2aU1vHuCG9OXX84LyjSJIklZyFWQW9vG4ri9/YxAVThxPhecuSJKnyWJhV0NzaerpUBeecOCzvKJIkSbmwMGu/GpsSv1pcz6njBzG4T4+840iSJOXCwqz9enRlA29t2ckFU4fnHUWSJCk3Fmbt19yF9fTv2Y3Tjh2SdxRJkqTcWJi1T5u27eLBZW/xucnDqO7qZiJJkiqXTUj7NH/pGnY1NjFrmqdjSJKkymZh1j7Nra1nwtC+HH/k4XlHkSRJypWFWX9m+Zvv8Gz9Zt/sJ0mShIVZ+zBnYR3dunjtZUmSJLAway+7G5uYt2Q1px07mAG9qvOOI0mSlDsLsz5gwfIG1m/dxaypI/KOIkmS1CFYmPUBc2vrqOndnenjB+UdRZIkqUOwMOt9G7bu5KEX13HuiUfSrYubhiRJEliY1cK8JWvY05S4wNMxJEmS3mdh1vvm1tYzafjhjD+iT95RJEmSOgwLswB4fvVmXly7hVlee1mSJOkDLMwCmo8uV3epYuYJXntZkiSpJQuz2LWniV8vWc0Zxw/h8J7d8o4jSZLUoViYxUMvvsXGbbs9HUOSJGkfLMxibm09Q/p255NjvfayJEnS3izMFW7dOztYsKKB86YMp0tV5B1HkiSpw7EwV7h5i1fT2JS4wNMxJEmS9snCXMFSSsxZWM+Ukf0YM6h33nEkSZI6JAtzBVtav5mV67Yya5qf7CdJkrQ/FuYKNre2jh7dqjhr0tC8o0iSJHVYFuYKtWN3I/OXrGHG8UfQt4fXXpYkSdofC3OFenDZW2zZscfTMSRJklphYa5Qc2rrGdbvMD529MC8o0iSJHVoFuYKtHbzdh5b2cD5U4ZR5bWXJUmSCrIwV6B7Fq0mJTjfay9LkiS1ysJcYVJKzK2t5yOjBzBqYK+840iSJHV4FuYKs+iNjby2/l1meXRZkiSpKBbmCjNnYT09q7tw5kSvvSxJklQMC3MF2bZrD/c+u5YzJw6lV/eueceRJEkqCxbmCvLAC2+ydeceLvB0DEmSpKIVVZgjYkZELI+IlyPi2v2s8/mIWBYRL0TEz7NloyJiUUQsyZZfeSjDq23mLKxn5ICenDR6QN5RJEmSykarf5ePiC7ATcAZQD3wTETMTykta7HOWOBbwLxXTf0AAA12SURBVMdTShsjYnD2pbXAx1JKOyOiN/B89tw1h/wnUUH1G7fx5CsbuPqMcUR47WVJkqRiFXOE+SPAyymlV1NKu4A7gc/ttc4VwE0ppY0AKaV12b+7Uko7s3W6F/l6age/rF1NBJw3ZVjeUSRJkspKMQV2GFDX4nF9tqylccC4iHgiIp6OiBnvfSEiRkTEs9n3mO3R5dJrakrMXVTHyWMGMrx/z7zjSJIklZVDdcS3KzAWOAW4GLg1IvoBpJTqUkqTgGOASyNiyN5PjogvRsTCiFjY0NBwiCLpPX9c9TZ1b2/3zX6SJEkHoJjCvBoY0eLx8GxZS/XA/JTS7pTSa8AKmgv0+7Ijy88Dn9z7BVJKt6SUpqWUpg0aNKgt+VWEOQvr6dO9KzOO99rLkiRJbVVMYX4GGBsRoyOiGrgImL/XOvNoPrpMRNTQfIrGqxExPCIOy5b3Bz4BLD9E2VWErTv3cN9zazn7hKEcVt0l7ziSJEllp9XCnFLaA3wVeAB4Ebg7pfRCRFwfETOz1R4ANkTEMuBh4JsppQ3AccAfImIp8Ajw/ZTSc+3xg2jf7ntuLdt3N3o6hiRJ0gEq6uPeUkr3Affttey6FvcTcHV2a7nOg8Ckg4+pAzV3YT1H1/Riysj+eUeRJEkqS34+cifT2JR4tn4TC5Y38MiKBpbUbeKbnxnvtZclSZIOkIW5E1i/dSePrmhgwfIGHlvZwMZtu4mAySP6cc0Z47j8E6PzjihJklS2LMxlaE9jE0uzo8gLljfw3OrNANT0rubUYwczfdwg/mLsIPr3qs45qSRJUvmzMJeJdVt28MiKBhasaODxlevZvH03VQFTRvbnG58ex/Rxgzn+yL5UVXnqhSRJ0qFkYe6gdjc2sej1jc0leXkDy9ZuAWBwn+58esIQpo8fxCePGcThPbvlnFSSJKlzszB3MHVvb+OnT7/OXQvr2LRtN12qgqmj+vMPM8YzfdwgJgzt6xv4JEmSSsjC3AGklHjylQ38+MlVPPTiW0QEn54whJknHMnHx9bQt4dHkSVJkvJiYc7Ruzv3cM/i1dz+5CpWrtvKgF7VXHXKGC45aRRH9jss73iSJEnCwpyLVevf5fanXmdObR3v7NjDxGGH8/1ZJ3D2pKH06ObHV0uSJHUkFuYSaWpKPLqygZ88uYoFKxroEsFfThzKZScfxZSR/TwvWZIkqYOyMLezd3bsZm5tPXc89Tqvrn+Xmt7d+dppY7nkpJEM6dsj73iSJElqhYW5nby8biu3P7WKX9bW8+6uRiaP6McPL5zMmROHUt21Ku94kiRJKpKF+RBKKbFgRQO3Pf4aj61cT3WXKs6eNJRLTz6KE0b0yzueJEmSDoCF+RBZtmYL37t3GU+9uoEhfbtzzRnjuPikkdT07p53NEmSJB0EC/NBanhnJ//+++XctbCOww/rxnc/O4FLPjqKbl087UKSJKkzsDAfoB27G7ntide4+eFX2LG7kb85eTR/96mxflS1JElSJ2NhbqOUEvc99yb/+rsXqd+4ndOPG8w/nXkcRw/qnXc0SZIktQMLcxs8W7+J7927jGdWbeTYI/rw08tP4hNja/KOJUmSpHZkYS7Cm5t3cMMDL3HPotUM7FXNv5w7kQs/PIIuVX7YiCRJUmdnYS5g+65Gbnn0Vf77kVdobEp8afrRfOXUY+jbw/OUJUmSKoWFeR+amhLzl65h9v0vsXbzDs6ceATXzjiOkQN75h1NkiRJJWZh3kvt6xu5/t5lLK3bxIeG9eWHF07mpKMH5h1LkiRJObEwZ+o3bmP2/cv5zdI1DO7Tne/POoHzThxGlecpS5IkVTQLM7BrTxPn3vwkW7bv5uunHcOXpo+hV3dHI0mSJAszANVdq7jhgkmMG9KHYf0OyzuOJEmSOhALc+bU8YPzjiBJkqQOqCrvAJIkSVJHZmGWJEmSCrAwS5IkSQVYmCVJkqQCLMySJElSARZmSZIkqQALsyRJklSAhVmSJEkqwMIsSZIkFWBhliRJkgqwMEuSJEkFWJglSZKkAizMkiRJUgEWZkmSJKkAC7MkSZJUgIVZkiRJKsDCLEmSJBVgYZYkSZIKsDBLkiRJBViYJUmSpAIipZR3hg+IiAbg9ZxevgZYn9NrVwpnXBrOuf0549Jwzu3PGZeGcy6Nts55VEppUGsrdbjCnKeIWJhSmpZ3js7MGZeGc25/zrg0nHP7c8al4ZxLo73m7CkZkiRJUgEWZkmSJKkAC/MH3ZJ3gArgjEvDObc/Z1wazrn9OePScM6l0S5z9hxmSZIkqQCPMEuSJEkFVGRhjogZEbE8Il6OiGv38fWrI2JZRDwbEQ9FxKg8cpazImZ8ZUQ8FxFLIuLxiJiQR85y19qcW6x3fkSkiPAd2m1UxLZ8WUQ0ZNvykoj42zxylrtituWI+Hy2b34hIn5e6ozlroht+QcttuMVEbEpj5zlrog5j4yIhyNicdYzzswjZzkrYsajsv72bEQsiIjhB/2iKaWKugFdgFeAo4FqYCkwYa91TgV6ZvevAu7KO3c53Yqccd8W92cC9+edu9xuxcw5W68P8CjwNDAt79zldCtyW74M+FHeWcv5VuScxwKLgf7Z48F55y6nW7H7ixbrfw24Le/c5XYrclu+Bbgquz8BWJV37nK6FTnjOcCl2f3TgDsO9nUr8QjzR4CXU0qvppR2AXcCn2u5Qkrp4ZTStuzh08DB/59JZSlmxltaPOwFeDJ927U658z3gNnAjlKG6ySKnbEOTjFzvgK4KaW0ESCltK7EGctdW7fli4FflCRZ51LMnBPQN7t/OLCmhPk6g2JmPAH4v+z+w/v4eptVYmEeBtS1eFyfLdufy4HftWuizqeoGUfEVyLiFeAG4OslytaZtDrniJgCjEgp/baUwTqRYvcX52d/+psbESNKE61TKWbO44BxEfFERDwdETNKlq5zKPp3X3Ya4mj+VDhUvGLm/F3gCxFRD9xH89F8Fa+YGS8Fzsvunwv0iYiBB/OilViYixYRXwCmATfmnaUzSindlFIaA/wj8J2883Q2EVEF/AdwTd5ZOrnfAEellCYBDwI/yTlPZ9WV5tMyTqH56OetEdEv10Sd10XA3JRSY95BOqmLgR+nlIYDZwJ3ZPtrHTrfAKZHxGJgOrAaOKjtuRL/A60GWh4BGp4t+4CIOB34NjAzpbSzRNk6i6Jm3MKdwDntmqhzam3OfYAPAQsiYhXwUWC+b/xrk1a35ZTShhb7iP8FppYoW2dSzD6jHpifUtqdUnoNWEFzgVZx2rJfvghPxzhQxcz5cuBugJTSU0APoKYk6TqHYvbLa1JK56WUTqS5y5FSOqg3sVZiYX4GGBsRoyOimuYdw/yWK0TEicD/0FyWPU+u7YqZcctfdGcBK0uYr7MoOOeU0uaUUk1K6aiU0lE0n48/M6W0MJ+4ZamYbXloi4czgRdLmK+zaHXOwDyajy4TETU0n6LxailDlrliZkxEHAv0B54qcb7Oopg5vwF8CiAijqO5MDeUNGV5K2a/XNPiqP23gNsO9kUrrjCnlPYAXwUeoPkX290ppRci4vqImJmtdiPQG5iTXV7nz3Yq2r8iZ/zV7NJQS4CrgUtzilu2ipyzDkKRM/56ti0vpflc/MvySVu+ipzzA8CGiFhG85t4vplS2pBP4vLThv3FRcCdKbu8gNqmyDlfA1yR7TN+AVzmvItX5IxPAZZHxApgCPDPB/u6ftKfJEmSVEDFHWGWJEmS2sLCLEmSJBVgYZYkSZIKsDBLkiRJBViYJUmSpAIszJJUIhHRLyK+nN0/JSLubYfXuCwiftTG56zKrm289/LvRsQ3Dl06SSpPFmZJKp1+wJfb8oSI6NJOWSRJRbIwS1Lp/BswJvvAnhuB3hExNyJeioifRUTA+0d8Z0fEImBWRIyJiPsjojYiHss+jY2ImBURz0fE0oh4tMXrHJmtvzIibnhvYURcHBHPZc+Zva+AEfHtiFgREY8D49trEJJUTrrmHUCSKsi1wIdSSpMj4hTg18DxwBrgCeDjwOPZuhtSSlMAIuIh4MqU0sqIOAm4GTgNuA74TEppdUT0a/E6k4ETgZ00f9rVfwKNwGxgKrAR+H1EnJNSmvfekyJiKs2f9DaZ5t8Pi4DaQz8GSSovFmZJys8fU0r1ANlR56P4U2G+K1veGzgZmJMdgAbonv37BPDjiLgbuKfF930opbQ5e/4yYBQwEFiQUmrIlv8M+AtgXovnfRL4VUppW7bO/EP2k0pSGbMwS1J+dra438gH98nvZv9WAZtSSpP3fnJK6crsiPNZQG12hLi17ytJaiPPYZak0nkH6NOWJ6SUtgCvRcQsgGh2QnZ/TErpDyml64AGYESBb/VHYHpE1GRvJLwYeGSvdR4FzomIwyKiD/DZtmSVpM7Kow6SVCIppQ0R8UREPA9sB94q8qmXAP8VEd8BugF3AkuBGyNiLBDAQ9myPzsSnb322oi4Fng4W/+3KaVf77XOooi4K/s+64Bn2vozSlJnFCmlvDNIkiRJHZanZEiSJEkFWJglSZKkAizMkiRJUgEWZkmSJKkAC7MkSZJUgIVZkiRJKsDCLEmSJBVgYZYkSZIK+H8X+BEWVcsYpAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
