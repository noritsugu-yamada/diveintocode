{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題2】初期化方法のクラス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "    n_nodes1:\n",
    "    n_nodes2:\n",
    "    ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "        後の層のノード数\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2)[np.newaxis, :]\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xavier:\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        W_xavi = self.sigma * np.random.randn(n_nodes1, n_nodes2)/np.sqrt(n_nodes1)\n",
    "        \n",
    "        return W_xavi\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn (n_nodes2)[np.newaxis, :]\n",
    "    \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class He:\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        W_he = self.sigma * np.random.randn(n_nodes1, n_nodes2)/np.sqrt(n_nodes1)*np.sqrt(2)\n",
    "        \n",
    "        return W_he\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn (n_nodes2)[np.newaxis, :]\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題7】最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.h = 1e-7\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        self.h += layer.dW*layer.dW\n",
    "        layer.W -= self.lr*layer.dW/np.sqrt(self.h)\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題4】活性化関数のクラス化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題5】ReLUクラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \"\"\"\n",
    "    sigmoid関数の処理と導関数の算出\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, A):\n",
    "        self.A  = A\n",
    "        Z = 1/1+np.exp(-self.A)\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        Z = self.forward(self.A)\n",
    "        dout_sig = Z*(1-Z)*dout\n",
    "        \n",
    "        return dout_sig\n",
    "    \n",
    "class Tanh:\n",
    "    \"\"\"\n",
    "    tanh関数の処理と導関数の算出\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = (np.exp(self.A)-np.exp(-self.A)) / (np.exp(self.A)+np.exp(-self.A))\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        Z = self.forward(self.A)\n",
    "        dout_tanh = (1-Z**2)*dout\n",
    "        \n",
    "        return dout_tanh\n",
    "    \n",
    "class Relu:\n",
    "    \"\"\"\n",
    "    relu関数の処理と導関数の算出\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.where(self.A<=0, 0, self.A)\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout_relu = np.where(self.A<=0, 0, 1)*dout\n",
    "        \n",
    "        return dout_relu\n",
    "    \n",
    "class Softmax:\n",
    "    \"\"\"\n",
    "    relu関数の処理とsoftmax_with_cross_entropyの導関数の算出\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "    \n",
    "    def forward(self, A):\n",
    "        #if A.ndim == 2:\n",
    "           # A = A.T\n",
    "           # A = A - np.max(A, axis=0)\n",
    "           # y = np.exp(A) / np.sum(np.exp(A), axis=0)\n",
    "           # return y.T\n",
    "        A = A - np.max(A)\n",
    "        Z = np.exp(A) / np.sum(np.exp(A),axis=1, keepdims=True)\n",
    "        self.Z = Z\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    \n",
    "    def backward(self, y):\n",
    "        dout_soft_max = self.Z - y\n",
    "        \n",
    "        return dout_soft_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = self.initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        # XとWの内積をとり、biasを加える\n",
    "        self.Z = copy.deepcopy(X) # Xが更新されないように\n",
    "        A = np.dot(X, self.W) + self.B\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 勾配を算出する\n",
    "        self.dB = np.average(dA)\n",
    "        self.dW = np.dot(self.Z.T, dA)/dA.shape[0]\n",
    "        \n",
    "        dZ = np.dot(dA, self.W.T)\n",
    "        \n",
    "        self = self.optimizer.update(self)# FCクラスのself.W, self.B, self.dW, self.dBを用いて更新\n",
    "        \n",
    "        return dZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    \"\"\"\n",
    "    randomに生成したWと同じ配列の要素でdroput_ratioを以下のものをFalseとして格納\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_ratio=0.5):\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X, train_flag=True):\n",
    "        if train_flag:\n",
    "            self.mask = np.random.rand(*X.shape) > self.dropout_ratio # *X.shapeはXと同じshapeにするため\n",
    "            return X*self.mask\n",
    "        \n",
    "        else:\n",
    "            return X*(1-self.dropout_ratio)\n",
    "        \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def cross_entropy_error(self, y_pred, y):\n",
    "        cross_entropy_error = np.sum(-1*y*np.log(y_pred+1e-10),axis=1)\n",
    "        \n",
    "        return cross_entropy_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier:\n",
    "    \"\"\"\n",
    "    FCでインスタンスを作り、Activationで活性化関数を通したものをaddで追加指定いく\n",
    "    \"\"\"\n",
    "    def __init__(self, epoch, batch_size):\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.losses = []\n",
    "        self.val_losses=[]\n",
    "        self.layers = []\n",
    "        \n",
    "    def add(self, layer):\n",
    "        self.layers += [layer] # model.add(インスタンスで層を追加)\n",
    "    \n",
    "    def forward_layer(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "    def backward_layer(self, y):\n",
    "        for layer in reversed(self.layers):\n",
    "            y = layer.backward(y)\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \n",
    "        \n",
    "        for i in range(self.epoch):\n",
    "            print('-----------------')\n",
    "            print('epoch{}回目の学習'.format(i+1))\n",
    "            get_mini_batch = GetMiniBatch(X, y, self.batch_size, seed=10)\n",
    "            #if X_val is not None and y_val is not None:\n",
    "            \n",
    "            # minibatchのイテレーション\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                #イテレーションごとのフォワード\n",
    "                Z3 = self.forward_layer(mini_X_train) # 使わない\n",
    "\n",
    "                #イテレーションごとのバックワード\n",
    "                dX = self.backward_layer(mini_y_train)# 使わない\n",
    "                \n",
    "            loss = Loss()\n",
    "            Z3_train = self.forward_layer(X_train)\n",
    "            epoch_train_loss = np.sum(loss.cross_entropy_error(Z3_train, y_train))/len(y_train) # 最後の重みでエポックlossを算出\n",
    "            self.losses += [epoch_train_loss]\n",
    "            print('epoch_train_loss{}'.format(epoch_train_loss))\n",
    "            \n",
    "            if np.any(X_val):\n",
    "                val_loss = Loss()\n",
    "                Z3_val = self.forward_layer(X_val)\n",
    "                epoch_val_loss = np.sum(loss.cross_entropy_error(Z3_val, y_val))/len(y_val) # val_lossもtrain\n",
    "                self.val_losses += [epoch_val_loss] \n",
    "                print(('epoch_val_loss{}'.format(epoch_val_loss)))\n",
    "                \n",
    "                \n",
    "    def predict(self, X_test):\n",
    "        X = X_test\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        \n",
    "        y_pred = np.argmax(X, axis=1)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def accuracy(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        accuracy = np.sum(y_pred==y_test)/len(y_test)\n",
    "        \n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import copy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "epoch1回目の学習\n",
      "epoch_train_loss0.678969333576132\n",
      "epoch_val_loss0.689286531387925\n",
      "-----------------\n",
      "epoch2回目の学習\n",
      "epoch_train_loss0.5576906785577821\n",
      "epoch_val_loss0.5702645812074432\n",
      "-----------------\n",
      "epoch3回目の学習\n",
      "epoch_train_loss0.5042890570769111\n",
      "epoch_val_loss0.5177322624261252\n",
      "-----------------\n",
      "epoch4回目の学習\n",
      "epoch_train_loss0.47317402750217774\n",
      "epoch_val_loss0.48715649887755913\n",
      "-----------------\n",
      "epoch5回目の学習\n",
      "epoch_train_loss0.45169273414080247\n",
      "epoch_val_loss0.4661428139103053\n",
      "-----------------\n",
      "epoch6回目の学習\n",
      "epoch_train_loss0.4353758347801003\n",
      "epoch_val_loss0.4502894944591336\n",
      "-----------------\n",
      "epoch7回目の学習\n",
      "epoch_train_loss0.4222185564010224\n",
      "epoch_val_loss0.43756845392209165\n",
      "-----------------\n",
      "epoch8回目の学習\n",
      "epoch_train_loss0.4112045654981743\n",
      "epoch_val_loss0.4269371943145734\n",
      "-----------------\n",
      "epoch9回目の学習\n",
      "epoch_train_loss0.40172653824485344\n",
      "epoch_val_loss0.41779967433805487\n",
      "-----------------\n",
      "epoch10回目の学習\n",
      "epoch_train_loss0.39339795448677317\n",
      "epoch_val_loss0.4097906662753391\n",
      "-----------------\n",
      "epoch11回目の学習\n",
      "epoch_train_loss0.3859782060875811\n",
      "epoch_val_loss0.40265889907991337\n",
      "-----------------\n",
      "epoch12回目の学習\n",
      "epoch_train_loss0.3792946004115599\n",
      "epoch_val_loss0.39624525470950683\n",
      "-----------------\n",
      "epoch13回目の学習\n",
      "epoch_train_loss0.3731833339797025\n",
      "epoch_val_loss0.3903987834444105\n",
      "-----------------\n",
      "epoch14回目の学習\n",
      "epoch_train_loss0.36757830637138433\n",
      "epoch_val_loss0.38503856956208726\n",
      "-----------------\n",
      "epoch15回目の学習\n",
      "epoch_train_loss0.3624102116548061\n",
      "epoch_val_loss0.3800986758843627\n",
      "-----------------\n",
      "epoch16回目の学習\n",
      "epoch_train_loss0.3576154823882066\n",
      "epoch_val_loss0.3755125045281253\n",
      "-----------------\n",
      "epoch17回目の学習\n",
      "epoch_train_loss0.3531421034862967\n",
      "epoch_val_loss0.3712411183844488\n",
      "-----------------\n",
      "epoch18回目の学習\n",
      "epoch_train_loss0.34895903926167854\n",
      "epoch_val_loss0.3672519979177777\n",
      "-----------------\n",
      "epoch19回目の学習\n",
      "epoch_train_loss0.3450308054280384\n",
      "epoch_val_loss0.3635027292954028\n",
      "-----------------\n",
      "epoch20回目の学習\n",
      "epoch_train_loss0.3413213451528741\n",
      "epoch_val_loss0.3599684225980866\n",
      "-----------------\n",
      "epoch21回目の学習\n",
      "epoch_train_loss0.3378183571846464\n",
      "epoch_val_loss0.3566152861338935\n",
      "-----------------\n",
      "epoch22回目の学習\n",
      "epoch_train_loss0.3344892142790419\n",
      "epoch_val_loss0.35342883891531673\n",
      "-----------------\n",
      "epoch23回目の学習\n",
      "epoch_train_loss0.33132019554134623\n",
      "epoch_val_loss0.35039074231750383\n",
      "-----------------\n",
      "epoch24回目の学習\n",
      "epoch_train_loss0.3282919610578226\n",
      "epoch_val_loss0.3474933062568231\n",
      "-----------------\n",
      "epoch25回目の学習\n",
      "epoch_train_loss0.32539861604004494\n",
      "epoch_val_loss0.3447160371240541\n",
      "-----------------\n",
      "epoch26回目の学習\n",
      "epoch_train_loss0.32262141350584783\n",
      "epoch_val_loss0.34205216461786553\n",
      "-----------------\n",
      "epoch27回目の学習\n",
      "epoch_train_loss0.31995858165344465\n",
      "epoch_val_loss0.3394872334525312\n",
      "-----------------\n",
      "epoch28回目の学習\n",
      "epoch_train_loss0.31739559190240196\n",
      "epoch_val_loss0.33701633716274765\n",
      "-----------------\n",
      "epoch29回目の学習\n",
      "epoch_train_loss0.31492118748004055\n",
      "epoch_val_loss0.3346262228559787\n",
      "-----------------\n",
      "epoch30回目の学習\n",
      "epoch_train_loss0.3125290649623522\n",
      "epoch_val_loss0.3323232229386844\n",
      "-----------------\n",
      "epoch31回目の学習\n",
      "epoch_train_loss0.310218367968299\n",
      "epoch_val_loss0.33009532681095816\n",
      "-----------------\n",
      "epoch32回目の学習\n",
      "epoch_train_loss0.3079816817327327\n",
      "epoch_val_loss0.3279274045304958\n",
      "-----------------\n",
      "epoch33回目の学習\n",
      "epoch_train_loss0.30581173946553575\n",
      "epoch_val_loss0.32582484343833784\n",
      "-----------------\n",
      "epoch34回目の学習\n",
      "epoch_train_loss0.3037029266389411\n",
      "epoch_val_loss0.3237822064049102\n",
      "-----------------\n",
      "epoch35回目の学習\n",
      "epoch_train_loss0.301646408540566\n",
      "epoch_val_loss0.321794047161831\n",
      "-----------------\n",
      "epoch36回目の学習\n",
      "epoch_train_loss0.2996009885468534\n",
      "epoch_val_loss0.3198097917408761\n",
      "-----------------\n",
      "epoch37回目の学習\n",
      "epoch_train_loss0.29761570792666026\n",
      "epoch_val_loss0.31788219478216645\n",
      "-----------------\n",
      "epoch38回目の学習\n",
      "epoch_train_loss0.29566795951902347\n",
      "epoch_val_loss0.31599219529857436\n",
      "-----------------\n",
      "epoch39回目の学習\n",
      "epoch_train_loss0.2937667147727939\n",
      "epoch_val_loss0.31414955231976205\n",
      "-----------------\n",
      "epoch40回目の学習\n",
      "epoch_train_loss0.2919035625077389\n",
      "epoch_val_loss0.31235093998598445\n",
      "-----------------\n",
      "epoch41回目の学習\n",
      "epoch_train_loss0.2900781341845454\n",
      "epoch_val_loss0.3105852915364657\n",
      "-----------------\n",
      "epoch42回目の学習\n",
      "epoch_train_loss0.2882915911098994\n",
      "epoch_val_loss0.30886069668665267\n",
      "-----------------\n",
      "epoch43回目の学習\n",
      "epoch_train_loss0.2865396766447665\n",
      "epoch_val_loss0.30716712995357176\n",
      "-----------------\n",
      "epoch44回目の学習\n",
      "epoch_train_loss0.28482131996342974\n",
      "epoch_val_loss0.3055051444654236\n",
      "-----------------\n",
      "epoch45回目の学習\n",
      "epoch_train_loss0.2831347936628212\n",
      "epoch_val_loss0.3038747683774887\n",
      "-----------------\n",
      "epoch46回目の学習\n",
      "epoch_train_loss0.28148045773741304\n",
      "epoch_val_loss0.30227742729796886\n",
      "-----------------\n",
      "epoch47回目の学習\n",
      "epoch_train_loss0.27985771877825383\n",
      "epoch_val_loss0.3007132910198363\n",
      "-----------------\n",
      "epoch48回目の学習\n",
      "epoch_train_loss0.27826573809574\n",
      "epoch_val_loss0.29918106067031525\n",
      "-----------------\n",
      "epoch49回目の学習\n",
      "epoch_train_loss0.27670600295330305\n",
      "epoch_val_loss0.2976742287226051\n",
      "-----------------\n",
      "epoch50回目の学習\n",
      "epoch_train_loss0.2751763418322376\n",
      "epoch_val_loss0.2961971832414013\n",
      "-----------------\n",
      "epoch51回目の学習\n",
      "epoch_train_loss0.2736744580075608\n",
      "epoch_val_loss0.29474575050773366\n",
      "-----------------\n",
      "epoch52回目の学習\n",
      "epoch_train_loss0.2721972681644542\n",
      "epoch_val_loss0.29332273321794894\n",
      "-----------------\n",
      "epoch53回目の学習\n",
      "epoch_train_loss0.2707470625337902\n",
      "epoch_val_loss0.29192857887044793\n",
      "-----------------\n",
      "epoch54回目の学習\n",
      "epoch_train_loss0.26932007994083484\n",
      "epoch_val_loss0.29055830748348976\n",
      "-----------------\n",
      "epoch55回目の学習\n",
      "epoch_train_loss0.2679167755112786\n",
      "epoch_val_loss0.28921037874853955\n",
      "-----------------\n",
      "epoch56回目の学習\n",
      "epoch_train_loss0.26653562075370657\n",
      "epoch_val_loss0.28787953370438424\n",
      "-----------------\n",
      "epoch57回目の学習\n",
      "epoch_train_loss0.2651715246659066\n",
      "epoch_val_loss0.28656557820874473\n",
      "-----------------\n",
      "epoch58回目の学習\n",
      "epoch_train_loss0.2638278250709146\n",
      "epoch_val_loss0.2852715065321412\n",
      "-----------------\n",
      "epoch59回目の学習\n",
      "epoch_train_loss0.26250325619860754\n",
      "epoch_val_loss0.2839979319337641\n",
      "-----------------\n",
      "epoch60回目の学習\n",
      "epoch_train_loss0.26119887943166714\n",
      "epoch_val_loss0.28274402828123946\n",
      "-----------------\n",
      "epoch61回目の学習\n",
      "epoch_train_loss0.2599152365511607\n",
      "epoch_val_loss0.28150782912369404\n",
      "-----------------\n",
      "epoch62回目の学習\n",
      "epoch_train_loss0.2586491411774419\n",
      "epoch_val_loss0.28029173040513\n",
      "-----------------\n",
      "epoch63回目の学習\n",
      "epoch_train_loss0.25739910341086375\n",
      "epoch_val_loss0.27909214275349237\n",
      "-----------------\n",
      "epoch64回目の学習\n",
      "epoch_train_loss0.2561676519156843\n",
      "epoch_val_loss0.2779117593873961\n",
      "-----------------\n",
      "epoch65回目の学習\n",
      "epoch_train_loss0.2549527348966152\n",
      "epoch_val_loss0.27674640899153247\n",
      "-----------------\n",
      "epoch66回目の学習\n",
      "epoch_train_loss0.25375557232808743\n",
      "epoch_val_loss0.2755985059653849\n",
      "-----------------\n",
      "epoch67回目の学習\n",
      "epoch_train_loss0.2525754128442158\n",
      "epoch_val_loss0.2744674890606416\n",
      "-----------------\n",
      "epoch68回目の学習\n",
      "epoch_train_loss0.25141199253999064\n",
      "epoch_val_loss0.2733544857647939\n",
      "-----------------\n",
      "epoch69回目の学習\n",
      "epoch_train_loss0.2502653633710956\n",
      "epoch_val_loss0.2722577286965175\n",
      "-----------------\n",
      "epoch70回目の学習\n",
      "epoch_train_loss0.24913243306205898\n",
      "epoch_val_loss0.2711722145322557\n",
      "-----------------\n",
      "epoch71回目の学習\n",
      "epoch_train_loss0.24801405881517696\n",
      "epoch_val_loss0.2701037551117004\n",
      "-----------------\n",
      "epoch72回目の学習\n",
      "epoch_train_loss0.24691001002190108\n",
      "epoch_val_loss0.2690465242289095\n",
      "-----------------\n",
      "epoch73回目の学習\n",
      "epoch_train_loss0.24582160962819602\n",
      "epoch_val_loss0.2680099415501783\n",
      "-----------------\n",
      "epoch74回目の学習\n",
      "epoch_train_loss0.24474740896382055\n",
      "epoch_val_loss0.2669885898442609\n",
      "-----------------\n",
      "epoch75回目の学習\n",
      "epoch_train_loss0.2436885016007491\n",
      "epoch_val_loss0.26597697631720385\n",
      "-----------------\n",
      "epoch76回目の学習\n",
      "epoch_train_loss0.24264306344338915\n",
      "epoch_val_loss0.2649814685219679\n",
      "-----------------\n",
      "epoch77回目の学習\n",
      "epoch_train_loss0.24160981769726364\n",
      "epoch_val_loss0.26399517222651353\n",
      "-----------------\n",
      "epoch78回目の学習\n",
      "epoch_train_loss0.24058988717059143\n",
      "epoch_val_loss0.2630215811465738\n",
      "-----------------\n",
      "epoch79回目の学習\n",
      "epoch_train_loss0.23958393457554306\n",
      "epoch_val_loss0.2620676599874536\n",
      "-----------------\n",
      "epoch80回目の学習\n",
      "epoch_train_loss0.23859136938106523\n",
      "epoch_val_loss0.26112470211959565\n",
      "-----------------\n",
      "epoch81回目の学習\n",
      "epoch_train_loss0.23761060052155564\n",
      "epoch_val_loss0.26019366803605476\n",
      "-----------------\n",
      "epoch82回目の学習\n",
      "epoch_train_loss0.23664102934899792\n",
      "epoch_val_loss0.2592731324349409\n",
      "-----------------\n",
      "epoch83回目の学習\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_train_loss0.23568181017906545\n",
      "epoch_val_loss0.25836077913016164\n",
      "-----------------\n",
      "epoch84回目の学習\n",
      "epoch_train_loss0.23473399129443442\n",
      "epoch_val_loss0.25746072517688806\n",
      "-----------------\n",
      "epoch85回目の学習\n",
      "epoch_train_loss0.23379717245746215\n",
      "epoch_val_loss0.25657478235909503\n",
      "-----------------\n",
      "epoch86回目の学習\n",
      "epoch_train_loss0.23287332211899078\n",
      "epoch_val_loss0.2557000848606474\n",
      "-----------------\n",
      "epoch87回目の学習\n",
      "epoch_train_loss0.23196025953184493\n",
      "epoch_val_loss0.2548399764227345\n",
      "-----------------\n",
      "epoch88回目の学習\n",
      "epoch_train_loss0.23105847647468336\n",
      "epoch_val_loss0.2539896690299378\n",
      "-----------------\n",
      "epoch89回目の学習\n",
      "epoch_train_loss0.23016545858156742\n",
      "epoch_val_loss0.2531479200586187\n",
      "-----------------\n",
      "epoch90回目の学習\n",
      "epoch_train_loss0.22928282076067855\n",
      "epoch_val_loss0.252317881967536\n",
      "-----------------\n",
      "epoch91回目の学習\n",
      "epoch_train_loss0.22840917173799266\n",
      "epoch_val_loss0.25149283067870715\n",
      "-----------------\n",
      "epoch92回目の学習\n",
      "epoch_train_loss0.2275450873297576\n",
      "epoch_val_loss0.25067992720586546\n",
      "-----------------\n",
      "epoch93回目の学習\n",
      "epoch_train_loss0.22669075928302215\n",
      "epoch_val_loss0.24987733796454684\n",
      "-----------------\n",
      "epoch94回目の学習\n",
      "epoch_train_loss0.22584666200313966\n",
      "epoch_val_loss0.249084904467605\n",
      "-----------------\n",
      "epoch95回目の学習\n",
      "epoch_train_loss0.22501235705687508\n",
      "epoch_val_loss0.2483020879682885\n",
      "-----------------\n",
      "epoch96回目の学習\n",
      "epoch_train_loss0.22418674416556075\n",
      "epoch_val_loss0.24752672943175874\n",
      "-----------------\n",
      "epoch97回目の学習\n",
      "epoch_train_loss0.2233696085544134\n",
      "epoch_val_loss0.24675820678288743\n",
      "-----------------\n",
      "epoch98回目の学習\n",
      "epoch_train_loss0.22256046716239294\n",
      "epoch_val_loss0.24600045297505138\n",
      "-----------------\n",
      "epoch99回目の学習\n",
      "epoch_train_loss0.22176071701902053\n",
      "epoch_val_loss0.24525084194305963\n",
      "-----------------\n",
      "epoch100回目の学習\n",
      "epoch_train_loss0.2209689678912737\n",
      "epoch_val_loss0.24451054756899418\n"
     ]
    }
   ],
   "source": [
    "three_layers = ScratchDeepNeuralNetrowkClassifier(100, 100)\n",
    "three_layers.add(FC(784, 400, SimpleInitializer(sigma=0.01), AdaGrad(0.001)))\n",
    "three_layers.add(Dropout(0.2))\n",
    "three_layers.add(Relu())\n",
    "three_layers.add(FC(400, 200, SimpleInitializer(sigma=0.01), AdaGrad(0.001)))\n",
    "three_layers.add(Dropout(0.2))\n",
    "three_layers.add(Relu())\n",
    "three_layers.add(FC(200, 10, SimpleInitializer(sigma=0.01), AdaGrad(0.001)))\n",
    "three_layers.add(Softmax())\n",
    "\n",
    "three_layers.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題2】学習曲線のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(three_layers.losses, 'o', label='train_loss')\n",
    "plt.plot(three_layers.val_losses, '--', label='val_loss')\n",
    "plt.title('train_and_val_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('cross_entropy_error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_layers.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_layers.accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
